# ui_workflow.py
# åŸºäºå·¥ä½œæµçš„åˆåŒå®¡æŸ¥ç³»ç»ŸUIç•Œé¢

import os
import json
import time
import tempfile
import base64
import logging
from typing import Dict, List, Optional, Any, Tuple
import streamlit as st
from contract_workflow import ContractWorkflow
import requests
import urllib
import warnings
import urllib3

# ç¦ç”¨SSLè­¦å‘Šï¼ˆä»…åœ¨ç¦ç”¨SSLéªŒè¯æ—¶ä½¿ç”¨ï¼‰
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="åˆåŒå®¡æŸ¥ç³»ç»Ÿ - å·¥ä½œæµç‰ˆ",
    page_icon="ğŸ“„",
    layout="wide",
    initial_sidebar_state="expanded",
)
warnings.filterwarnings("ignore")
# é™ä½è§¦å‘ç©º label æç¤ºçš„æ¨¡å—æ—¥å¿—çº§åˆ«ï¼ˆåŒä¿é™©ï¼‰
logging.getLogger("streamlit.elements.lib.policies").setLevel(logging.ERROR)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown(
    """
<style>
    /* ä¸»å®¹å™¨æ ·å¼ */
    .main-container {
        padding: 1px 2px;
        background-color: #f8f9fa;
    }
    
    /* å‡å°‘é¡µé¢é¡¶éƒ¨ç©ºç™½ */
    .main .block-container {
        padding-top: 1rem;
        padding-bottom: 1rem;
    }
    
    /* å‡å°‘æ ‡é¢˜é—´è·å’Œè°ƒæ•´å¤§å° */
    h1, h2, h3 {
        margin-top: 0.5rem;
        margin-bottom: 0.5rem;
    }
    
    /* è°ƒæ•´ä¸»æ ‡é¢˜å¤§å° */
    h1 {
        font-size: 1.8rem !important;
        font-weight: 600 !important;
    }
    
    /* éšè—æˆ–è°ƒå°å³ä¸Šè§’çš„rerunæŒ‰é’® */
    .stApp > header {
        visibility: hidden;
    }
    
    /* éšè—Streamlitçš„èœå•æŒ‰é’® */
    .stApp > div[data-testid="stToolbar"] {
        visibility: hidden;
    }
    
    /* éšè—å³ä¸Šè§’çš„èœå• */
    .stApp > div[data-testid="stHeader"] {
        visibility: hidden;
    }
    
    /* å·¥ä½œæµæ­¥éª¤æ ·å¼ */
    .workflow-step {
        background-color: white;
        border-radius: 8px;
        padding: 20px;
        margin: 10px 0;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        border-left: 4px solid #007bff;
    }
    
    .workflow-step.completed {
        border-left-color: #28a745;
        background-color: #f8fff9;
    }
    
    .workflow-step.current {
        border-left-color: #ffc107;
        background-color: #fffdf0;
    }
    
    .workflow-step.error {
        border-left-color: #dc3545;
        background-color: #fff5f5;
    }
    
    /* é£é™©å¡ç‰‡æ ·å¼ */
    .risk-card {
        background-color: #fff;
        border-radius: 8px;
        padding: 16px;
        margin: 8px 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        transition: transform 0.2s ease;
    }
    
    .risk-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 8px rgba(0,0,0,0.15);
    }
    
    /* é£é™©ç­‰çº§æ ‡ç­¾æ ·å¼ */
    .risk-high {
        background-color: #f44336;
        color: white;
        padding: 4px 8px;
        border-radius: 4px;
        font-size: 12px;
        font-weight: bold;
    }
    
    .risk-medium {
        background-color: #ff9800;
        color: white;
        padding: 4px 8px;
        border-radius: 4px;
        font-size: 12px;
        font-weight: bold;
    }
    
    .risk-low {
        background-color: #4caf50;
        color: white;
        padding: 4px 8px;
        border-radius: 4px;
        font-size: 12px;
        font-weight: bold;
    }
    
    /* ç¡®ä¿æ–‡æœ¬åŒºåŸŸæœ‰æ»šåŠ¨æ¡ */
    textarea {
        overflow-y: auto !important;
    }
    
    /* åŒæ­¥æ»šåŠ¨å®¹å™¨æ ·å¼ */
    .sync-scroll-container {
        max-height: 780px;
        overflow-y: auto;
        overflow-x: hidden;
    }
    
</style>
""",
    unsafe_allow_html=True,
)


def initialize_session_state():
    """åˆå§‹åŒ–session state"""
    if "workflow_result" not in st.session_state:
        st.session_state.workflow_result = None
    if "processing_status" not in st.session_state:
        st.session_state.processing_status = (
            "idle"  # idle, processing, completed, error
        )
    if "file_name" not in st.session_state:
        st.session_state.file_name = None
    if "preview_content" not in st.session_state:
        st.session_state.preview_content = None
    if "loaded_from_history" not in st.session_state:
        st.session_state.loaded_from_history = False
    if "ocr_parse_result" not in st.session_state:
        # ç”¨äºå³ä¾§å¯¹ç…§é¢æ¿çš„åœ¨çº¿è§£æç»“æœç¼“å­˜
        st.session_state.ocr_parse_result = None


def load_latest_result_by_filename(file_name: str) -> Optional[Dict[str, Any]]:
    """æ ¹æ®æ–‡ä»¶ååŠ è½½è¯¥æ–‡ä»¶çš„æœ€æ–°åˆ†æç»“æœã€‚

    ä¼˜å…ˆåŒ¹é… result["original_file_name"] == file_nameï¼›
    å…¼å®¹æ—§ç»“æœï¼šè‹¥æ—  original_file_nameï¼Œåˆ™ç”¨ basename(result["file_path"]) æ¯”å¯¹ã€‚
    """
    results_dir = "contract_analysis_results"
    if not os.path.exists(results_dir):
        return None

    candidates: List[Dict[str, Any]] = []
    for fname in os.listdir(results_dir):
        if not fname.lower().endswith(".json"):
            continue
        fpath = os.path.join(results_dir, fname)
        try:
            with open(fpath, "r", encoding="utf-8") as f:
                data = json.load(f)
            # åŒ¹é…é€»è¾‘
            match = False
            ori = data.get("original_file_name")
            if ori and ori == file_name:
                match = True
            else:
                # å…¼å®¹æ—§æ•°æ®
                fp = data.get("file_path")
                if isinstance(fp, str) and os.path.basename(fp) == file_name:
                    match = True
            if match:
                # ä»¥ processing_time ä¸ºä¸»ï¼Œé€€åŒ–åˆ°æ–‡ä»¶åæ—¶é—´æˆ³æ’åº
                ts = data.get("processing_time")
                candidates.append(
                    {
                        "_ts": float(ts) if isinstance(ts, (int, float)) else 0.0,
                        "_path": fpath,
                        "data": data,
                    }
                )
        except Exception:
            continue

    if not candidates:
        return None

    # è‹¥ processing_time éƒ½ä¸º 0ï¼Œåˆ™ä½¿ç”¨æ–‡ä»¶åä¸­çš„æ—¶é—´æˆ³è¿›è¡Œæ’åºä½œä¸ºå…œåº•
    def extract_name_ts(p: str) -> float:
        base = os.path.basename(p)
        # å½¢å¦‚ contract_analysis_YYYYmmdd_HHMMSS.json
        try:
            stem = os.path.splitext(base)[0]
            parts = stem.split("_")
            if len(parts) >= 3:
                dt = parts[-2] + parts[-1]  # YYYYmmdd + HHMMSS
                # è½¬æ¢ä¸ºç»“æ„åŒ–æ—¶é—´
                import datetime

                d = datetime.datetime.strptime(dt, "%Y%m%d%H%M%S")
                return d.timestamp()
        except Exception:
            pass
        return 0.0

    for c in candidates:
        if not c["_ts"]:
            c["_ts"] = extract_name_ts(c["_path"]) or 0.0

    candidates.sort(key=lambda x: x["_ts"], reverse=True)
    return candidates[0]["data"]


def save_uploaded_file(uploaded_file) -> Optional[str]:
    """ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶"""
    if not uploaded_file:
        return None
    suffix = os.path.splitext(uploaded_file.name)[1]
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
        tmp.write(uploaded_file.read())
        return tmp.name


def get_sample_files() -> List[str]:
    """è·å–æ ·ä¾‹æ–‡ä»¶åˆ—è¡¨"""
    contracts_dir = "contracts"
    if not os.path.exists(contracts_dir):
        return []

    sample_files = []
    for file in os.listdir(contracts_dir):
        file_path = os.path.join(contracts_dir, file)
        if os.path.isfile(file_path) and file.lower().endswith(
            (".pdf", ".docx", ".txt", ".doc")
        ):
            sample_files.append(file_path)

    return sample_files


def copy_sample_file(sample_path: str) -> Optional[str]:
    """å¤åˆ¶æ ·ä¾‹æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•"""
    try:
        suffix = os.path.splitext(sample_path)[1]
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
            with open(sample_path, "rb") as src:
                tmp.write(src.read())
            return tmp.name
    except Exception as e:
        st.error(f"å¤åˆ¶æ ·ä¾‹æ–‡ä»¶å¤±è´¥: {str(e)}")
        return None


def preview_file_content(file_path: str) -> str:
    """é¢„è§ˆæ–‡ä»¶å†…å®¹"""
    try:
        file_ext = os.path.splitext(file_path)[1].lower()

        if file_ext == ".txt":
            encodings = ["utf-8", "gbk", "gb2312", "gb18030"]
            for encoding in encodings:
                try:
                    with open(file_path, "r", encoding=encoding) as f:
                        content = f.read()
                    return content[:2000] + "..." if len(content) > 2000 else content
                except UnicodeDecodeError:
                    continue
            return "æ— æ³•è¯»å–æ–‡ä»¶å†…å®¹"

        elif file_ext == ".docx":
            try:
                import docx

                doc = docx.Document(file_path)
                content = "\n".join([para.text for para in doc.paragraphs])
                return content[:2000] + "..." if len(content) > 2000 else content
            except Exception as e:
                return f"è¯»å–Wordæ–‡æ¡£å¤±è´¥: {str(e)}"

        elif file_ext == ".pdf":
            try:
                from pdfminer.high_level import extract_text

                content = extract_text(file_path)
                return content[:2000] + "..." if len(content) > 2000 else content
            except Exception as e:
                return f"è¯»å–PDFæ–‡ä»¶å¤±è´¥: {str(e)}"

        else:
            return f"ä¸æ”¯æŒé¢„è§ˆ {file_ext} æ ¼å¼æ–‡ä»¶"

    except Exception as e:
        return f"é¢„è§ˆæ–‡ä»¶å¤±è´¥: {str(e)}"


def _read_file_as_base64(file_path: str) -> Optional[str]:
    """è¯»å–æ–‡ä»¶å¹¶è¿”å›base64ï¼ˆç”¨äºå†…åµŒPDFé¢„è§ˆï¼‰ã€‚"""
    try:
        with open(file_path, "rb") as f:
            return base64.b64encode(f.read()).decode("utf-8")
    except Exception:
        return None


def render_file_preview(file_path: str, height: int = 780):
    """å·¦ä¾§æºæ–‡ä»¶é¢„è§ˆã€‚

    - PDF: æŒ‰é¡µæ¸²æŸ“ä¸ºå›¾ç‰‡è¿›è¡Œå±•ç¤ºï¼ˆåŸºäº PyMuPDFï¼‰
    - å…¶ä»–: ä»¥æ–‡æœ¬æ–¹å¼å±•ç¤ºï¼ˆå¸¦æ»šåŠ¨æ¡ï¼‰
    """
    file_ext = os.path.splitext(file_path)[1].lower()

    if file_ext == ".pdf":
        try:
            import fitz  # PyMuPDF

            doc = fitz.open(file_path)
            if doc.page_count == 0:
                st.warning("PDF æ— é¡µé¢å¯é¢„è§ˆ")
                return

            # å½“å‰é¡µï¼ˆç”¨äºæ˜¾ç¤ºé¡µç å’Œè·³è½¬ï¼‰
            page_key = f"pdf_page_{os.path.basename(file_path)}"
            current_page = int(st.session_state.get(page_key, 1))
            if current_page < 1:
                current_page = 1
            if current_page > doc.page_count:
                current_page = doc.page_count

            # æ¸²æŸ“æ‰€æœ‰é¡µé¢åˆ°ä¸€ä¸ªé•¿å®¹å™¨ä¸­
            page_images = []
            for page_num in range(doc.page_count):
                page = doc.load_page(page_num)
                # æé«˜DPIä»¥è·å¾—æ›´æ¸…æ™°çš„å›¾ç‰‡
                pix = page.get_pixmap(matrix=fitz.Matrix(2.5, 2.5))
                img_bytes = pix.tobytes("png")
                img_base64 = base64.b64encode(img_bytes).decode()
                page_images.append({
                    'page_num': page_num + 1,
                    'img_base64': img_base64
                })
            
            # ä½¿ç”¨å›ºå®šé«˜åº¦çš„å¯æ»šåŠ¨å®¹å™¨åŒ…è£…æ‰€æœ‰é¡µé¢
            container_id = f"pdf-container-{os.path.basename(file_path).replace('.', '_').replace(' ', '_')}"
            scroll_key = f"scroll_to_page_{page_key}"
            target_page = st.session_state.get(scroll_key, current_page)
            
            # æ„å»ºæ‰€æœ‰é¡µé¢çš„HTMLå†…å®¹
            pages_html_content = ""
            for page_data in page_images:
                page_num = page_data['page_num']
                img_base64 = page_data['img_base64']
                pages_html_content += f'<div id="pdf-page-{page_num}" style="margin-bottom: 20px; text-align: center;"><img src="data:image/png;base64,{img_base64}" style="width: 100%; max-width: 100%; height: auto; border: 1px solid #ddd; border-radius: 4px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); display: block; margin: 10px auto;" /><div style="margin-top: 10px; color: #666; font-size: 12px;">ç¬¬ {page_num} é¡µ / å…± {doc.page_count} é¡µ</div></div>'
            
            # æ„å»ºå®Œæ•´çš„HTML
            html_content = f"""
            <div id="{container_id}" style="max-height: {height}px; overflow-y: auto; overflow-x: auto; border: 1px solid #e0e0e0; border-radius: 4px; padding: 10px; margin-bottom: 10px; background-color: #fafafa;">
                {pages_html_content}
            </div>
            <script>
                (function() {{
                    const containerId = '{container_id}';
                    const targetPage = {target_page};
                    
                    function scrollToPage(pageNum) {{
                        const container = document.getElementById(containerId);
                        const pageElement = document.getElementById('pdf-page-' + pageNum);
                        if (container && pageElement) {{
                            const scrollTop = pageElement.offsetTop - container.offsetTop - 10;
                            container.scrollTo({{
                                top: scrollTop,
                                behavior: 'smooth'
                            }});
                        }}
                    }}
                    
                    function initScroll() {{
                        const container = document.getElementById(containerId);
                        if (container) {{
                            scrollToPage(targetPage);
                        }} else {{
                            setTimeout(initScroll, 100);
                        }}
                    }}
                    
                    if (document.readyState === 'loading') {{
                        document.addEventListener('DOMContentLoaded', initScroll);
                    }} else {{
                        initScroll();
                    }}
                    
                    window['scrollToPage_' + containerId] = scrollToPage;
                }})();
            </script>
            """
            
            # ä½¿ç”¨markdownæ¸²æŸ“ï¼Œç¡®ä¿HTMLæ­£ç¡®æ˜¾ç¤º
            st.markdown(html_content, unsafe_allow_html=True)

            # æ§ä»¶æ”¾åœ¨å›¾ç‰‡æ­£ä¸‹æ–¹ï¼šä¸Šä¸€é¡µ/é¡µç è¾“å…¥/ä¸‹ä¸€é¡µ
            ctrl_left, ctrl_mid, ctrl_right = st.columns([1, 2, 1])
            with ctrl_left:
                if st.button("ä¸Šä¸€é¡µ", width='stretch', key=f"prev_{page_key}"):
                    new_page = max(1, current_page - 1)
                    if new_page != current_page:
                        st.session_state[page_key] = new_page
                        st.session_state[scroll_key] = new_page
                        st.rerun()
            with ctrl_mid:
                new_val = st.number_input(
                    "é¡µç ",
                    min_value=1,
                    max_value=doc.page_count,
                    value=current_page,
                    step=1,
                    key=f"num_{page_key}",
                    label_visibility="collapsed",
                )
                if int(new_val) != current_page:
                    st.session_state[page_key] = int(new_val)
                    st.session_state[scroll_key] = int(new_val)
                    st.rerun()
            with ctrl_right:
                if st.button("ä¸‹ä¸€é¡µ", width='stretch', key=f"next_{page_key}"):
                    new_page = min(doc.page_count, current_page + 1)
                    if new_page != current_page:
                        st.session_state[page_key] = new_page
                        st.session_state[scroll_key] = new_page
                        st.rerun()
        except Exception:
            # å…œåº•ï¼šå›é€€åˆ°æ–‡æœ¬æ¨¡å¼
            st.warning("å›¾ç‰‡é¢„è§ˆå¤±è´¥ï¼Œå·²åˆ‡æ¢ä¸ºæ–‡æœ¬æ¨¡å¼ã€‚")
            st.text_area(
                "æ–‡ä»¶å†…å®¹",
                preview_file_content(file_path),
                height=height,
                disabled=True,
                key="left_text_area"
            )
    else:
        # éPDFæ–‡ä»¶ä½¿ç”¨text_areaæ˜¾ç¤ºï¼Œç¡®ä¿æœ‰æ»šåŠ¨æ¡
        st.text_area(
            "æ–‡ä»¶å†…å®¹", 
            preview_file_content(file_path), 
            height=height, 
            disabled=True,
            key="left_text_area"
        )


def render_preview_panel(file_path: str, preview_text: str):
    """ä¸¤æ é¢„è§ˆï¼šå·¦ä¾§æºæ–‡ä»¶ï¼Œå³ä¾§è¯†åˆ«ç»“æœå¯¹ç…§ï¼ˆå‚è€ƒç¤ºä¾‹UIï¼‰ï¼Œæ”¯æŒåŒæ­¥æ»šåŠ¨ã€‚"""
    
    # æ·»åŠ åŒæ­¥æ»šåŠ¨çš„JavaScriptä»£ç 
    sync_scroll_js = """
    <script>
    (function() {
        let leftPanel = null;
        let rightPanel = null;
        let isScrolling = false;
        
        function findScrollablePanels() {
            // æŸ¥æ‰¾æ‰€æœ‰å¯æ»šåŠ¨çš„å…ƒç´ 
            const allElements = document.querySelectorAll('*');
            const scrollableElements = [];
            
            for (let el of allElements) {
                const style = window.getComputedStyle(el);
                const hasScroll = el.scrollHeight > el.clientHeight;
                const isScrollable = style.overflow === 'auto' || 
                                    style.overflow === 'scroll' || 
                                    style.overflowY === 'auto' || 
                                    style.overflowY === 'scroll';
                
                // æŸ¥æ‰¾å¯æ»šåŠ¨çš„å®¹å™¨ï¼ˆåŒ…æ‹¬PDFå›¾ç‰‡å®¹å™¨å’Œtextareaï¼‰
                if (hasScroll && isScrollable && el.offsetHeight > 200) {
                    scrollableElements.push(el);
                }
            }
            
            // æŸ¥æ‰¾å³ä¾§çš„textareaï¼ˆç”¨äºOCRè¯†åˆ«ç»“æœï¼‰
            const textareas = Array.from(document.querySelectorAll('textarea'));
            let rightTextarea = null;
            
            // é€šè¿‡ä½ç½®æŸ¥æ‰¾å³ä¾§çš„textarea
            for (let ta of textareas) {
                const rect = ta.getBoundingClientRect();
                if (rect.left > window.innerWidth / 2 && 
                    ta.scrollHeight > ta.clientHeight) {
                    rightTextarea = ta;
                    break;
                }
            }
            
            // æŸ¥æ‰¾å·¦ä¾§çš„å¯æ»šåŠ¨å®¹å™¨ï¼ˆå¯èƒ½æ˜¯PDFå›¾ç‰‡å®¹å™¨æˆ–textareaï¼‰
            let leftPanel = null;
            
            // ä¼˜å…ˆæŸ¥æ‰¾PDFå®¹å™¨ï¼ˆé€šè¿‡IDç‰¹å¾ï¼‰
            for (let el of scrollableElements) {
                const rect = el.getBoundingClientRect();
                // å·¦ä¾§é¢æ¿åº”è¯¥åœ¨å±å¹•å·¦åŠéƒ¨åˆ†
                if (rect.left < window.innerWidth / 2) {
                    // ä¼˜å…ˆé€‰æ‹©PDFå®¹å™¨ï¼ˆIDåŒ…å«pdf-containerï¼‰æˆ–åŒ…å«å¤šä¸ªå›¾ç‰‡çš„å®¹å™¨
                    if (el.id && el.id.includes('pdf-container')) {
                        leftPanel = el;
                        break;
                    }
                    // å…¶æ¬¡é€‰æ‹©åŒ…å«å›¾ç‰‡çš„å®¹å™¨ï¼ˆPDFé¢„è§ˆï¼‰
                    if (el.querySelector('img') || el.tagName === 'TEXTAREA') {
                        leftPanel = el;
                        break;
                    }
                }
            }
            
            // å¦‚æœæ²¡æ‰¾åˆ°å·¦ä¾§é¢æ¿ï¼Œå°è¯•ä»scrollableElementsä¸­é€‰æ‹©æœ€å·¦è¾¹çš„
            if (!leftPanel && scrollableElements.length > 0) {
                scrollableElements.sort((a, b) => {
                    return a.getBoundingClientRect().left - b.getBoundingClientRect().left;
                });
                leftPanel = scrollableElements[0];
            }
            
            // å¦‚æœæ‰¾åˆ°äº†å·¦å³ä¸¤ä¸ªé¢æ¿ï¼Œè¿”å›å®ƒä»¬
            if (leftPanel && rightTextarea && leftPanel !== rightTextarea) {
                return [leftPanel, rightTextarea];
            }
            
            // å¦‚æœæ‰¾ä¸åˆ°å³ä¾§textareaï¼Œå°è¯•ä»scrollableElementsä¸­æ‰¾å³ä¾§çš„
            if (leftPanel && !rightTextarea && scrollableElements.length >= 2) {
                for (let el of scrollableElements) {
                    const rect = el.getBoundingClientRect();
                    if (rect.left > window.innerWidth / 2 && el !== leftPanel) {
                        return [leftPanel, el];
                    }
                }
            }
            
            // å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°ï¼Œå°è¯•ä»scrollableElementsä¸­æŒ‰ä½ç½®æ’åº
            if (scrollableElements.length >= 2) {
                scrollableElements.sort((a, b) => {
                    return a.getBoundingClientRect().left - b.getBoundingClientRect().left;
                });
                return [scrollableElements[0], scrollableElements[1]];
            }
            
            return null;
        }
        
        function syncScroll(source, target) {
            if (isScrolling || !source || !target) return;
            isScrolling = true;
            
            const sourceScrollTop = source.scrollTop;
            const sourceScrollHeight = source.scrollHeight;
            const sourceClientHeight = source.clientHeight;
            const targetScrollHeight = target.scrollHeight;
            const targetClientHeight = target.clientHeight;
            
            if (sourceScrollHeight <= sourceClientHeight || targetScrollHeight <= targetClientHeight) {
                isScrolling = false;
                return;
            }
            
            // è®¡ç®—ç›®æ ‡æ»šåŠ¨ä½ç½®ï¼ˆæŒ‰æ¯”ä¾‹ï¼‰
            const scrollRatio = sourceScrollTop / (sourceScrollHeight - sourceClientHeight);
            const targetScrollTop = scrollRatio * (targetScrollHeight - targetClientHeight);
            
            target.scrollTop = targetScrollTop;
            
            setTimeout(() => { isScrolling = false; }, 10);
        }
        
        function initSyncScroll() {
            const panels = findScrollablePanels();
            if (panels && panels.length === 2) {
                leftPanel = panels[0];
                rightPanel = panels[1];
                
                // ç§»é™¤æ—§çš„äº‹ä»¶ç›‘å¬å™¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if (leftPanel._syncScrollHandler) {
                    leftPanel.removeEventListener('scroll', leftPanel._syncScrollHandler);
                }
                if (rightPanel._syncScrollHandler) {
                    rightPanel.removeEventListener('scroll', rightPanel._syncScrollHandler);
                }
                
                // æ·»åŠ æ–°çš„äº‹ä»¶ç›‘å¬å™¨
                leftPanel._syncScrollHandler = () => syncScroll(leftPanel, rightPanel);
                rightPanel._syncScrollHandler = () => syncScroll(rightPanel, leftPanel);
                
                leftPanel.addEventListener('scroll', leftPanel._syncScrollHandler, { passive: true });
                rightPanel.addEventListener('scroll', rightPanel._syncScrollHandler, { passive: true });
            }
        }
        
        // ä½¿ç”¨MutationObserverç›‘å¬DOMå˜åŒ–
        const observer = new MutationObserver(() => {
            setTimeout(initSyncScroll, 100);
        });
        
        observer.observe(document.body, {
            childList: true,
            subtree: true
        });
        
        // åˆå§‹æ‰§è¡Œ
        setTimeout(initSyncScroll, 1000);
        
        // é¡µé¢æ»šåŠ¨æ—¶ä¹Ÿå°è¯•åˆå§‹åŒ–
        window.addEventListener('load', () => {
            setTimeout(initSyncScroll, 500);
        });
    })();
    </script>
    """
    
    # æ³¨å…¥JavaScript
    st.components.v1.html(sync_scroll_js, height=0)
    
    left, right = st.columns([1, 1], gap="large")
    
    with left:
        # ä½¿ç”¨å®¹å™¨åŒ…è£…å·¦ä¾§å†…å®¹ï¼Œç¡®ä¿æœ‰æ»šåŠ¨æ¡
        st.markdown("#### æºæ–‡ä»¶é¢„è§ˆ")
        left_container = st.container()
        with left_container:
            render_file_preview(file_path)

    with right:
        st.markdown("#### è§£æç»“æœå¯¹ç…§")
        tabs = st.tabs(["OCRè¯†åˆ«å¯¹ç…§", "Markdown", "JSON"])

        with tabs[0]:
            # åœ¨çº¿APIè°ƒç”¨ï¼šç™¾åº¦æ–‡æ¡£è§£æï¼ˆéœ€è¦è®¾ç½®ç¯å¢ƒå˜é‡ BAIDU_PARSER_AUTHï¼‰
            colA, colB = st.columns([1, 1])
            with colA:
                if st.button("â–¶ è°ƒç”¨OCRè§£æ", key="btn_call_ocr"):
                    st.session_state.ocr_parse_result = call_online_parse_api(file_path)
                    st.rerun()
            with colB:
                if st.session_state.ocr_parse_result:
                    if st.session_state.ocr_parse_result.get("_cached"):
                        st.info("å·²ä»ç¼“å­˜åŠ è½½è§£æç»“æœ")
                    else:
                        st.success("å·²è·å–åœ¨çº¿è§£æç»“æœ")

            # OCRè¯†åˆ«å¯¹ç…§ï¼šæ˜¾ç¤ºjson_resultæ ¼å¼åŒ–åçš„æ–‡æœ¬
            ocr_text = None
            if st.session_state.ocr_parse_result and isinstance(
                st.session_state.ocr_parse_result, dict
            ):
                json_result = st.session_state.ocr_parse_result.get("json_result", {})
                if json_result:
                    ocr_text = format_json_result_as_text(json_result)
                else:
                    ocr_text = st.session_state.ocr_parse_result.get("raw_text", preview_text)
            else:
                ocr_text = preview_text
            
            # ä½¿ç”¨å›ºå®šé«˜åº¦çš„æ–‡æœ¬åŒºåŸŸï¼Œç¡®ä¿æœ‰æ»šåŠ¨æ¡
            st.text_area(
                "è¯†åˆ«æ–‡æœ¬",
                ocr_text if ocr_text else preview_text,
                height=780,
                disabled=True,
                label_visibility="collapsed",
                key="right_text_area"
            )

            # è‹¥æœ‰åœ¨çº¿è§£æçš„åŸå§‹è¿”å›ï¼Œæä¾›è°ƒè¯•è¾“å‡º
            if st.session_state.ocr_parse_result and isinstance(
                st.session_state.ocr_parse_result, dict
            ):
                with st.expander("API è°ƒè¯•è¾“å‡º", expanded=False):
                    st.json(st.session_state.ocr_parse_result)

        with tabs[1]:
            # Markdown tabï¼šæ˜¾ç¤ºä»markdown_urlä¸‹è½½ä¸‹æ¥çš„æ–‡ä»¶æ¸²æŸ“çš„ç»“æœ
            markdown_content = None
            if st.session_state.ocr_parse_result and isinstance(
                st.session_state.ocr_parse_result, dict
            ):
                markdown_content = st.session_state.ocr_parse_result.get("markdown_text")
            
            if markdown_content:
                # ä½¿ç”¨å›ºå®šé«˜åº¦çš„å®¹å™¨ç¡®ä¿å¯æ»šåŠ¨ï¼Œä½¿ç”¨Streamlitçš„markdownæ¸²æŸ“
                st.markdown(
                    """
                    <style>
                    .markdown-scroll-container {
                        max-height: 780px;
                        overflow-y: auto;
                        overflow-x: auto;
                        padding: 10px;
                        border: 1px solid #e0e0e0;
                        border-radius: 4px;
                        background-color: #fafafa;
                    }
                    </style>
                    """,
                    unsafe_allow_html=True
                )
                # ä½¿ç”¨Streamlitçš„markdownæ¸²æŸ“
                st.markdown(markdown_content)
            else:
                # å¦‚æœæ²¡æœ‰markdownå†…å®¹ï¼Œæ˜¾ç¤ºé¢„è§ˆæ–‡æœ¬
                st.text_area(
                    "é¢„è§ˆæ–‡æœ¬",
                    preview_text if isinstance(preview_text, str) else str(preview_text),
                    height=780,
                    disabled=True,
                    label_visibility="collapsed",
                    key="markdown_preview_area"
                )

        with tabs[2]:
            # JSON tabï¼šæ˜¾ç¤ºjson_resultçš„åŸå§‹JSONæ ¼å¼
            if st.session_state.ocr_parse_result and isinstance(
                st.session_state.ocr_parse_result, dict
            ):
                json_result = st.session_state.ocr_parse_result.get("json_result", {})
                if json_result:
                    st.json(json_result)
                else:
                    st.info("æš‚æ— JSONç»“æœã€‚")
            elif (
                hasattr(st.session_state, "workflow_result")
                and st.session_state.workflow_result
                and isinstance(st.session_state.workflow_result, dict)
            ):
                st.json(st.session_state.workflow_result)
            else:
                st.info("æš‚æ— JSONç»“æœã€‚å¯åŠ¨åˆ†æåå°†åœ¨æ­¤å±•ç¤ºç»“æ„åŒ–æ•°æ®ã€‚")


def get_cache_file_paths(file_path: str) -> Tuple[str, str]:
    """æ ¹æ®æ–‡ä»¶è·¯å¾„ç”Ÿæˆç¼“å­˜æ–‡ä»¶è·¯å¾„ï¼ˆjsonå’Œmdï¼‰"""
    import hashlib
    # ä½¿ç”¨æ–‡ä»¶è·¯å¾„çš„hashå€¼ä½œä¸ºç¼“å­˜æ–‡ä»¶åï¼Œé¿å…ç‰¹æ®Šå­—ç¬¦é—®é¢˜
    file_hash = hashlib.md5(file_path.encode('utf-8')).hexdigest()
    base_name = os.path.splitext(os.path.basename(file_path))[0]
    # ç»„åˆæ–‡ä»¶åå’Œhashï¼Œç¡®ä¿å”¯ä¸€æ€§
    cache_name = f"{base_name}_{file_hash}"
    
    json_path = os.path.join("jsons", f"{cache_name}.json")
    md_path = os.path.join("mds", f"{cache_name}.md")
    
    return json_path, md_path


def load_cached_parse_result(file_path: str) -> Optional[Dict[str, Any]]:
    """ä»ç¼“å­˜åŠ è½½è§£æç»“æœ"""
    json_path, md_path = get_cache_file_paths(file_path)
    
    if not (os.path.exists(json_path) and os.path.exists(md_path)):
        return None
    
    try:
        with open(json_path, "r", encoding="utf-8") as f:
            json_result = json.load(f)
        with open(md_path, "r", encoding="utf-8") as f:
            markdown_text = f.read()
        
        return {
            "json_result": json_result,
            "markdown_text": markdown_text,
            "raw_text": preview_file_content(file_path),
            "_cached": True,
        }
    except Exception as e:
        print(f"åŠ è½½ç¼“å­˜å¤±è´¥: {e}")
        return None


def save_parse_result(file_path: str, json_result: Dict[str, Any], markdown_text: str):
    """ä¿å­˜è§£æç»“æœåˆ°ç¼“å­˜æ–‡ä»¶"""
    json_path, md_path = get_cache_file_paths(file_path)
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs("jsons", exist_ok=True)
    os.makedirs("mds", exist_ok=True)
    
    try:
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(json_result, f, ensure_ascii=False, indent=2)
        with open(md_path, "w", encoding="utf-8") as f:
            f.write(markdown_text)
        print(f"å·²ä¿å­˜è§£æç»“æœ: {json_path}, {md_path}")
    except Exception as e:
        print(f"ä¿å­˜è§£æç»“æœå¤±è´¥: {e}")


def format_json_result_as_text(json_result: Dict[str, Any]) -> str:
    """å°†JSONç»“æœæ ¼å¼åŒ–ä¸ºå¯è¯»æ–‡æœ¬ï¼ŒåŒ…å«ä½ç½®ä¿¡æ¯"""
    if not json_result:
        return "æš‚æ— JSONç»“æœ"
    
    lines = []
    
    # å¤„ç†æ–‡ä»¶åŸºæœ¬ä¿¡æ¯
    if "file_name" in json_result:
        lines.append(f"ğŸ“„ æ–‡ä»¶å: {json_result.get('file_name', 'N/A')}")
        lines.append(f"ğŸ†” æ–‡ä»¶ID: {json_result.get('file_id', 'N/A')}")
        lines.append("")
    
    # å¤„ç†é¡µé¢ä¿¡æ¯
    pages = json_result.get("pages", [])
    if pages:
        lines.append(f"ğŸ“‘ å…± {len(pages)} é¡µ")
        lines.append("=" * 80)
        lines.append("")
        
        for page_idx, page in enumerate(pages):
            page_num = page.get("page_num", page_idx)
            page_id = page.get("page_id", f"page-{page_idx}")
            
            lines.append(f"ğŸ“„ ç¬¬ {page_num + 1} é¡µ (page_id: {page_id})")
            lines.append("-" * 80)
            
            # é¡µé¢å…ƒä¿¡æ¯
            meta = page.get("meta", {})
            if meta:
                page_width = meta.get("page_width", 0)
                page_height = meta.get("page_height", 0)
                lines.append(f"   ğŸ“ é¡µé¢å°ºå¯¸: {page_width} Ã— {page_height} åƒç´ ")
                lines.append(f"   ğŸ“ é¡µé¢ç±»å‹: {meta.get('page_type', 'N/A')}")
                lines.append("")
            
            # å¤„ç†å¸ƒå±€ä¿¡æ¯ï¼ˆlayoutsï¼‰
            layouts = page.get("layouts", [])
            if layouts:
                lines.append(f"   ğŸ“‹ å¸ƒå±€å…ƒç´  ({len(layouts)} ä¸ª):")
                lines.append("")
                
                # æŒ‰å±‚çº§ç»„ç»‡å¸ƒå±€ï¼ˆå…ˆæ˜¾ç¤ºæ ¹èŠ‚ç‚¹ï¼Œå†æ˜¾ç¤ºå­èŠ‚ç‚¹ï¼‰
                layout_dict = {layout.get("layout_id"): layout for layout in layouts}
                root_layouts = [layout for layout in layouts if layout.get("parent") == "root"]
                
                def format_layout(layout, indent_level=2):
                    """æ ¼å¼åŒ–å•ä¸ªå¸ƒå±€å…ƒç´ """
                    indent = "  " * indent_level
                    layout_id = layout.get("layout_id", "N/A")
                    layout_type = layout.get("type", "N/A")
                    sub_type = layout.get("sub_type", "")
                    text = layout.get("text", "").strip()
                    position = layout.get("position", [])
                    parent = layout.get("parent", "N/A")
                    children = layout.get("children", [])
                    
                    # æ ¼å¼åŒ–ä½ç½®ä¿¡æ¯
                    if position and len(position) >= 4:
                        x, y, w, h = position[0], position[1], position[2], position[3]
                        pos_str = f"ä½ç½®: ({x}, {y}) å°ºå¯¸: {w}Ã—{h}"
                    else:
                        pos_str = "ä½ç½®: N/A"
                    
                    # ç±»å‹æ ‡ç­¾
                    type_label = f"{layout_type}"
                    if sub_type:
                        type_label += f"/{sub_type}"
                    
                    # æ„å»ºæ˜¾ç¤ºå†…å®¹
                    result = []
                    result.append(f"{indent}â”Œâ”€ [{type_label}] {layout_id}")
                    result.append(f"{indent}â”‚  {pos_str}")
                    if text:
                        # é™åˆ¶æ–‡æœ¬é•¿åº¦ï¼Œé¿å…è¿‡é•¿
                        text_preview = text.replace("\n", "\\n")[:100]
                        if len(text) > 100:
                            text_preview += "..."
                        result.append(f"{indent}â”‚  æ–‡æœ¬: {text_preview}")
                    if parent != "root":
                        result.append(f"{indent}â”‚  çˆ¶èŠ‚ç‚¹: {parent}")
                    if children:
                        result.append(f"{indent}â”‚  å­èŠ‚ç‚¹: {', '.join(children)}")
                    result.append(f"{indent}â””â”€")
                    
                    return result
                
                # é€’å½’å¤„ç†å¸ƒå±€æ ‘
                def process_layout_tree(layout, indent_level=2, processed=None):
                    """é€’å½’å¤„ç†å¸ƒå±€æ ‘ç»“æ„"""
                    if processed is None:
                        processed = set()
                    
                    layout_id = layout.get("layout_id")
                    if layout_id in processed:
                        return []
                    
                    processed.add(layout_id)
                    result = format_layout(layout, indent_level)
                    
                    # å¤„ç†å­èŠ‚ç‚¹
                    children_ids = layout.get("children", [])
                    if children_ids:
                        for child_id in children_ids:
                            if child_id in layout_dict:
                                child_layout = layout_dict[child_id]
                                child_result = process_layout_tree(child_layout, indent_level + 1, processed)
                                result.extend(child_result)
                    
                    return result
                
                # å¤„ç†æ‰€æœ‰æ ¹å¸ƒå±€ï¼ˆparentä¸º"root"çš„å¸ƒå±€ï¼‰
                processed_ids = set()
                for root_layout in root_layouts:
                    layout_lines = process_layout_tree(root_layout, indent_level=2, processed=processed_ids)
                    lines.extend(layout_lines)
                    lines.append("")
                
                # æ˜¾ç¤ºæœªå¤„ç†çš„å¸ƒå±€ï¼ˆparentä¸æ˜¯"root"ä¸”ä¸åœ¨ä»»ä½•childrenä¸­çš„å¸ƒå±€ï¼‰
                orphan_layouts = [layout for layout in layouts 
                                 if layout.get("layout_id") not in processed_ids]
                if orphan_layouts:
                    lines.append("   âš ï¸  å…¶ä»–å¸ƒå±€å…ƒç´ :")
                    for orphan in orphan_layouts:
                        layout_lines = format_layout(orphan, indent_level=2)
                        lines.extend(layout_lines)
                        lines.append("")
            
            # å¤„ç†è¡¨æ ¼
            tables = page.get("tables", [])
            if tables:
                lines.append(f"   ğŸ“Š è¡¨æ ¼ ({len(tables)} ä¸ª):")
                for i, table in enumerate(tables):
                    lines.append(f"      [{i+1}] è¡¨æ ¼ID: {table.get('table_id', 'N/A')}")
                    if "position" in table:
                        pos = table["position"]
                        if len(pos) >= 4:
                            lines.append(f"          ä½ç½®: ({pos[0]}, {pos[1]}) å°ºå¯¸: {pos[2]}Ã—{pos[3]}")
                lines.append("")
            
            # å¤„ç†å›¾ç‰‡
            images = page.get("images", [])
            if images:
                lines.append(f"   ğŸ–¼ï¸  å›¾ç‰‡ ({len(images)} ä¸ª):")
                for i, image in enumerate(images):
                    lines.append(f"      [{i+1}] å›¾ç‰‡ID: {image.get('image_id', 'N/A')}")
                    if "position" in image:
                        pos = image["position"]
                        if len(pos) >= 4:
                            lines.append(f"          ä½ç½®: ({pos[0]}, {pos[1]}) å°ºå¯¸: {pos[2]}Ã—{pos[3]}")
                lines.append("")
            
            lines.append("")
            lines.append("=" * 80)
            lines.append("")
    
    return "\n".join(lines)


def call_online_parse_api(file_path: str) -> Optional[Dict[str, Any]]:
    """è°ƒç”¨ç™¾åº¦æ–‡æ¡£è§£æåœ¨çº¿APIï¼Œå¹¶è¿”å›è§£ææ–‡æœ¬/JSON/ä¸‹è½½é“¾æ¥ã€‚"""
    # å…ˆæ£€æŸ¥ç¼“å­˜
    cached_result = load_cached_parse_result(file_path)
    if cached_result:
        print(f"ä»ç¼“å­˜åŠ è½½è§£æç»“æœ: {file_path}")
        return cached_result
    
    try:
        create_url = "https://aip.baidubce.com/rest/2.0/brain/online/v2/parser/task"
        query_url = (
            "https://aip.baidubce.com/rest/2.0/brain/online/v2/parser/task/query"
        )

        params = {
            "file_data": _read_file_as_base64(file_path) or "",
            "file_name": os.path.basename(file_path),
            "recognize_formula": "True",
            "analysis_chart": "True",
            "angle_adjust": "True",
            "parse_image_layout": "True",
            "language_type": "CHN_ENG",
            "switch_digital_width": "auto",
        }
        payload = urllib.parse.urlencode(params)
        headers = {
            "Content-Type": "application/x-www-form-urlencoded",
            "Accept": "application/json",
            "Authorization": "Bearer bce-v3/ALTAK-IS6uG1qXcgDDP9RrmjYD9/ede55d516092e0ca5e9041eab19455df12c7db7f",
        }

        # æ·»åŠ é‡è¯•æœºåˆ¶å’Œè¶…æ—¶è®¾ç½®
        max_retries = 3
        retry_delay = 2  # ç§’
        resp = None
        data = {}
        
        for attempt in range(max_retries):
            try:
                # æ ¹æ®æ–‡ä»¶å¤§å°åŠ¨æ€è®¾ç½®è¶…æ—¶æ—¶é—´ï¼ˆå¤§æ–‡ä»¶éœ€è¦æ›´é•¿æ—¶é—´ï¼‰
                file_size = os.path.getsize(file_path) if os.path.exists(file_path) else 0
                # åŸºç¡€è¶…æ—¶30ç§’ï¼Œå¤§æ–‡ä»¶ï¼ˆ>5MBï¼‰å¢åŠ åˆ°60ç§’
                timeout = 60 if file_size > 5 * 1024 * 1024 else 30
                
                resp = requests.post(
                    create_url, 
                    headers=headers, 
                    data=payload.encode("utf-8"),
                    timeout=timeout,
                    verify=True  # å¯ç”¨SSLéªŒè¯
                )
                resp.raise_for_status()  # æ£€æŸ¥HTTPé”™è¯¯
                
                data = (
                    resp.json()
                    if resp.headers.get("content-type", "").startswith("application/json")
                    else {}
                )
                break  # æˆåŠŸåˆ™é€€å‡ºé‡è¯•å¾ªç¯
                
            except requests.exceptions.SSLError as e:
                if attempt < max_retries - 1:
                    print(f"SSLé”™è¯¯ï¼Œç¬¬{attempt + 1}æ¬¡é‡è¯•... é”™è¯¯: {str(e)}")
                    time.sleep(retry_delay * (attempt + 1))  # æŒ‡æ•°é€€é¿
                else:
                    # æœ€åä¸€æ¬¡å°è¯•ï¼Œå¦‚æœè¿˜æ˜¯SSLé”™è¯¯ï¼Œå°è¯•ç¦ç”¨SSLéªŒè¯ï¼ˆä¸æ¨èä½†ä½œä¸ºå¤‡é€‰ï¼‰
                    try:
                        print("æœ€åä¸€æ¬¡å°è¯•ï¼Œä¸´æ—¶ç¦ç”¨SSLéªŒè¯ï¼ˆä»…ç”¨äºè§£å†³SSLè¿æ¥é—®é¢˜ï¼‰...")
                        st.warning("âš ï¸ æ£€æµ‹åˆ°SSLè¿æ¥é—®é¢˜ï¼Œæ­£åœ¨å°è¯•å¤‡ç”¨è¿æ¥æ–¹å¼...")
                        resp = requests.post(
                            create_url, 
                            headers=headers, 
                            data=payload.encode("utf-8"),
                            timeout=timeout,
                            verify=False  # ä¸´æ—¶ç¦ç”¨SSLéªŒè¯
                        )
                        resp.raise_for_status()
                        data = (
                            resp.json()
                            if resp.headers.get("content-type", "").startswith("application/json")
                            else {}
                        )
                        st.info("âœ… å·²é€šè¿‡å¤‡ç”¨æ–¹å¼è¿æ¥æˆåŠŸ")
                        break
                    except Exception as e2:
                        st.error(f"è°ƒç”¨åœ¨çº¿è§£æAPIå¤±è´¥ï¼ˆSSLé”™è¯¯ï¼‰: {str(e2)}")
                        st.info("ğŸ’¡ å»ºè®®ï¼šæ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•ã€‚å¦‚æœé—®é¢˜æŒç»­ï¼Œå¯èƒ½æ˜¯æœåŠ¡å™¨ç«¯SSLé…ç½®é—®é¢˜ã€‚")
                        print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {type(e2).__name__}: {str(e2)}")
                        return None
                        
            except requests.exceptions.Timeout as e:
                if attempt < max_retries - 1:
                    print(f"è¯·æ±‚è¶…æ—¶ï¼Œç¬¬{attempt + 1}æ¬¡é‡è¯•...")
                    time.sleep(retry_delay * (attempt + 1))
                else:
                    st.error(f"è¯·æ±‚è¶…æ—¶: æ–‡ä»¶å¯èƒ½è¿‡å¤§ï¼Œè¯·ç¨åé‡è¯•")
                    return None
                    
            except requests.exceptions.RequestException as e:
                if attempt < max_retries - 1:
                    print(f"è¯·æ±‚é”™è¯¯ï¼Œç¬¬{attempt + 1}æ¬¡é‡è¯•... é”™è¯¯: {str(e)}")
                    time.sleep(retry_delay * (attempt + 1))
                else:
                    st.error(f"è°ƒç”¨åœ¨çº¿è§£æAPIå¤±è´¥: {str(e)}")
                    print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {type(e).__name__}: {str(e)}")
                    return None
        
        if not resp:
            st.error("åˆ›å»ºåœ¨çº¿è§£æä»»åŠ¡å¤±è´¥ï¼šæ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨")
            return None
            
        task_id = (
            (data.get("result", {}) or {}).get("task_id")
            if isinstance(data, dict)
            else None
        )
        if not task_id:
            error_msg = data.get("error_msg", "æœªçŸ¥é”™è¯¯")
            st.error(f"åˆ›å»ºåœ¨çº¿è§£æä»»åŠ¡å¤±è´¥: {error_msg}")
            return None

        # è½®è¯¢æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
        max_query_retries = 30
        interval = 2
        result_json: Optional[Dict[str, Any]] = None
        query_headers = {
            "Content-Type": "application/x-www-form-urlencoded",
            "Accept": "application/json",
            "Authorization": "Bearer bce-v3/ALTAK-IS6uG1qXcgDDP9RrmjYD9/ede55d516092e0ca5e9041eab19455df12c7db7f",
        }
        
        for i in range(max_query_retries):
            try:
                q = requests.post(
                    query_url,
                    headers=query_headers,
                    data=f"task_id={task_id}".encode("utf-8"),
                    timeout=30,
                    verify=True
                )
                q.raise_for_status()
                try:
                    result_json = q.json()
                except Exception:
                    result_json = None
                status = (result_json or {}).get("result", {}).get("status")
                if status == "success":
                    break
                if status in ("failed", "error"):
                    error_msg = (result_json or {}).get("result", {}).get("task_error", "æœªçŸ¥é”™è¯¯")
                    st.warning(f"ä»»åŠ¡å¤„ç†å¤±è´¥: {error_msg}")
                    break
            except requests.exceptions.RequestException as e:
                if i < max_query_retries - 1:
                    print(f"æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€å¤±è´¥ï¼Œé‡è¯•ä¸­... ({i+1}/{max_query_retries})")
                else:
                    st.error(f"æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}")
                    return None
            time.sleep(interval)

        if not result_json:
            st.error("åœ¨çº¿è§£æä»»åŠ¡æ— è¿”å›")
            return None

        r = result_json.get("result", {}) if isinstance(result_json, dict) else {}
        parse_result_url = r.get("parse_result_url")
        markdown_url = r.get("markdown_url")

        json_result: Dict[str, Any] = {}
        markdown_text: Optional[str] = None
        try:
            if parse_result_url:
                jr = requests.get(parse_result_url, timeout=30, verify=True)
                jr.raise_for_status()
                # æ˜¾å¼è®¾ç½®ç¼–ç ä¸ºUTF-8ï¼Œé¿å…ä¸­æ–‡ä¹±ç 
                jr.encoding = 'utf-8'
                json_result = jr.json() if jr.ok else {}
        except requests.exceptions.RequestException as e:
            print(f"ä¸‹è½½JSONç»“æœå¤±è´¥: {str(e)}")
            json_result = {}
        try:
            if markdown_url:
                mr = requests.get(markdown_url, timeout=30, verify=True)
                mr.raise_for_status()
                # æ˜¾å¼è®¾ç½®ç¼–ç ä¸ºUTF-8ï¼Œé¿å…ä¸­æ–‡ä¹±ç 
                mr.encoding = 'utf-8'
                markdown_text = mr.text if mr.ok else None
        except requests.exceptions.RequestException as e:
            print(f"ä¸‹è½½Markdownç»“æœå¤±è´¥: {str(e)}")
            markdown_text = None

        # ä¿å­˜åˆ°ç¼“å­˜
        if json_result and markdown_text:
            save_parse_result(file_path, json_result, markdown_text)

        result_payload = {
            "task_id": task_id,
            "parse_result_url": parse_result_url,
            "markdown_url": markdown_url,
            "json_result": json_result,
            "markdown_text": markdown_text,
            # å›é€€çš„åŸå§‹æ–‡æœ¬
            "raw_text": preview_file_content(file_path),
            # é¢å¤–æš´éœ²ä¸€æ¬¡æ ¸å¿ƒ API è¿”å›ï¼Œä¾¿äºæ‰“å°/è°ƒè¯•
            "_api_create_resp": data,
            "_api_query_resp": result_json,
        }

        # æ‰“å°åˆ°æ§åˆ¶å°ï¼ˆå¼€å‘æœŸéœ€æ±‚ï¼‰
        print(
            "[call_online_parse_api] create_resp:", json.dumps(data, ensure_ascii=False)
        )
        print(
            "[call_online_parse_api] query_resp:",
            json.dumps(result_json or {}, ensure_ascii=False),
        )

        return result_payload
    except Exception as e:
        st.error(f"è°ƒç”¨åœ¨çº¿è§£æAPIå¤±è´¥: {e}")
        return None


def add_highlights_to_text(text: str, issues: List[Dict]) -> str:
    """ä¸ºæ–‡æœ¬æ·»åŠ ç®€å•æ ‡è®° - æ‰€æœ‰é—®é¢˜éƒ½æ ‡è®°æ˜¾ç¤º"""
    if not issues:
        return text

    highlighted_text = text
    for issue in issues:
        clause = issue.get("æ¡æ¬¾", "")
        risk_level = issue.get("é£é™©ç­‰çº§", "ä½")
        issue_type = issue.get("ç±»å‹", "é—®é¢˜")

        if clause and clause in highlighted_text:
            # æ ¹æ®é£é™©ç­‰çº§é€‰æ‹©æ ‡è®°ç¬¦å·
            if risk_level == "é«˜":
                marker = "ğŸ”´ã€é‡å¤§é£é™©ã€‘"
            elif risk_level == "ä¸­":
                marker = "ğŸŸ¡ã€ä¸€èˆ¬é£é™©ã€‘"
            else:
                marker = "ğŸŸ¢ã€ä½é£é™©ã€‘"

            # æ·»åŠ ç®€å•æ ‡è®°
            marked_text = f"{marker} {clause}"
            highlighted_text = highlighted_text.replace(clause, marked_text)

    return highlighted_text


def filter_issues_by_risk(issues: List[Dict], risk_level: str) -> List[Dict]:
    """æ ¹æ®é£é™©ç­‰çº§ç­›é€‰é—®é¢˜"""
    if risk_level == "å…¨éƒ¨":
        return issues

    level_mapping = {"é‡å¤§é£é™©": "é«˜", "ä¸€èˆ¬é£é™©": "ä¸­", "ä½é£é™©": "ä½"}

    target_level = level_mapping.get(risk_level, "ä½")
    return [issue for issue in issues if issue.get("é£é™©ç­‰çº§") == target_level]


def render_risk_analysis(risk_analysis: Dict[str, Any]):
    """æ¸²æŸ“é£é™©åˆ†æç»“æœ"""
    st.markdown("### ğŸ” é£é™©åˆ†æç»“æœ")

    statistics = risk_analysis.get("statistics", {})
    all_issues = risk_analysis.get("all_issues", [])

    # é£é™©ç»Ÿè®¡
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("æ€»é—®é¢˜æ•°", statistics.get("total_issues", 0))
    with col2:
        st.metric("é«˜é£é™©", statistics.get("by_level", {}).get("é«˜", 0))
    with col3:
        st.metric("ä¸­é£é™©", statistics.get("by_level", {}).get("ä¸­", 0))
    with col4:
        st.metric("ä½é£é™©", statistics.get("by_level", {}).get("ä½", 0))

    # é£é™©è¯„åˆ†
    risk_score = statistics.get("risk_score", 0)
    risk_level = statistics.get("risk_level", "ä½")

    st.markdown("### ğŸ“Š é£é™©è¯„åˆ†")
    col1, col2 = st.columns(2)
    with col1:
        st.metric("é£é™©è¯„åˆ†", f"{risk_score}/100")
    with col2:
        level_color = {"é«˜": "ğŸ”´", "ä¸­": "ğŸŸ¡", "ä½": "ğŸŸ¢"}.get(risk_level, "âšª")
        st.metric("é£é™©ç­‰çº§", f"{level_color} {risk_level}")

    # é—®é¢˜è¯¦æƒ…
    if all_issues:
        st.markdown("### ğŸ“‹ é—®é¢˜è¯¦æƒ…")

        # æŒ‰é£é™©ç­‰çº§åˆ†ç±»
        high_risk_issues = [
            issue for issue in all_issues if issue.get("é£é™©ç­‰çº§") == "é«˜"
        ]
        medium_risk_issues = [
            issue for issue in all_issues if issue.get("é£é™©ç­‰çº§") == "ä¸­"
        ]
        low_risk_issues = [
            issue for issue in all_issues if issue.get("é£é™©ç­‰çº§") == "ä½"
        ]

        # æ˜¾ç¤ºé«˜é£é™©é—®é¢˜
        if high_risk_issues:
            st.markdown("#### ğŸ”´ é«˜é£é™©é—®é¢˜")
            for i, issue in enumerate(high_risk_issues, 1):
                with st.expander(
                    f"{i}. {issue.get('ç±»å‹', 'æœªçŸ¥ç±»å‹')} - {issue.get('æ¡æ¬¾', 'N/A')[:50]}...",
                    expanded=True,
                ):
                    st.write(f"**é—®é¢˜æè¿°:** {issue.get('é—®é¢˜æè¿°', 'N/A')}")
                    st.write(f"**ä¿®æ”¹å»ºè®®:** {issue.get('ä¿®æ”¹å»ºè®®', 'N/A')}")
                    if issue.get("æ³•å¾‹ä¾æ®"):
                        st.write(f"**æ³•å¾‹ä¾æ®:** {issue['æ³•å¾‹ä¾æ®']}")
                    if issue.get("å½±å“åˆ†æ"):
                        st.write(f"**å½±å“åˆ†æ:** {issue['å½±å“åˆ†æ']}")

        # æ˜¾ç¤ºä¸­é£é™©é—®é¢˜
        if medium_risk_issues:
            st.markdown("#### ğŸŸ¡ ä¸­é£é™©é—®é¢˜")
            for i, issue in enumerate(medium_risk_issues, 1):
                with st.expander(
                    f"{i}. {issue.get('ç±»å‹', 'æœªçŸ¥ç±»å‹')} - {issue.get('æ¡æ¬¾', 'N/A')[:50]}...",
                    expanded=False,
                ):
                    st.write(f"**é—®é¢˜æè¿°:** {issue.get('é—®é¢˜æè¿°', 'N/A')}")
                    st.write(f"**ä¿®æ”¹å»ºè®®:** {issue.get('ä¿®æ”¹å»ºè®®', 'N/A')}")
                    if issue.get("å½±å“åˆ†æ"):
                        st.write(f"**å½±å“åˆ†æ:** {issue['å½±å“åˆ†æ']}")

        # æ˜¾ç¤ºä½é£é™©é—®é¢˜
        if low_risk_issues:
            st.markdown("#### ğŸŸ¢ ä½é£é™©é—®é¢˜")
            for i, issue in enumerate(low_risk_issues, 1):
                with st.expander(
                    f"{i}. {issue.get('ç±»å‹', 'æœªçŸ¥ç±»å‹')} - {issue.get('æ¡æ¬¾', 'N/A')[:50]}...",
                    expanded=False,
                ):
                    st.write(f"**é—®é¢˜æè¿°:** {issue.get('é—®é¢˜æè¿°', 'N/A')}")
                    st.write(f"**ä¿®æ”¹å»ºè®®:** {issue.get('ä¿®æ”¹å»ºè®®', 'N/A')}")
    else:
        st.info("æœªå‘ç°é—®é¢˜")


def render_suggestions(suggestions: Dict[str, Any]):
    """æ¸²æŸ“å»ºè®®å’Œæ¨è"""
    st.markdown("### ğŸ’¡ ç»¼åˆå»ºè®®")

    summary = suggestions.get("summary", {})
    analysis = suggestions.get("analysis", {})
    recommendation = suggestions.get("recommendation", {})

    # æ‘˜è¦ä¿¡æ¯
    st.markdown("#### ğŸ“Š åˆ†ææ‘˜è¦")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("é£é™©è¯„åˆ†", f"{summary.get('risk_score', 0)}/100")
    with col2:
        st.metric("æ€»é—®é¢˜æ•°", summary.get("total_issues", 0))
    with col3:
        st.metric("è¿æ³•æ¡æ¬¾", summary.get("illegal_clauses", 0))

    # ä¸»è¦é£é™©ç‚¹
    if analysis.get("key_risks"):
        st.markdown("#### ğŸ”´ ä¸»è¦é£é™©ç‚¹")
        for risk in analysis["key_risks"]:
            st.write(f"â€¢ {risk}")

    # å½±å“åˆ†æ
    if analysis.get("impact_analysis"):
        st.markdown("#### ğŸ“ˆ å½±å“åˆ†æ")
        st.write(analysis["impact_analysis"])

    # ä¼˜åŒ–å»ºè®®
    if analysis.get("optimization_suggestions"):
        st.markdown("#### ğŸ› ï¸ ä¼˜åŒ–å»ºè®®")
        for suggestion in analysis["optimization_suggestions"]:
            st.write(f"â€¢ {suggestion}")

    # ç­¾çº¦å»ºè®®
    if recommendation.get("signing_advice"):
        st.markdown("#### ğŸ“ ç­¾çº¦å»ºè®®")
        signing_advice = recommendation["signing_advice"]
        if "ä¸å»ºè®®" in signing_advice or "âŒ" in signing_advice:
            st.error(f"**{signing_advice}**")
        elif "è°¨æ…" in signing_advice or "âš ï¸" in signing_advice:
            st.warning(f"**{signing_advice}**")
        elif "å¯ä»¥" in signing_advice or "âœ…" in signing_advice:
            st.success(f"**{signing_advice}**")
        else:
            st.info(f"**{signing_advice}**")

    # è°ˆåˆ¤è¦ç‚¹
    if recommendation.get("negotiation_points"):
        st.markdown("#### ğŸ¤ è°ˆåˆ¤è¦ç‚¹")
        for point in recommendation["negotiation_points"]:
            st.write(f"â€¢ {point}")

    # é£é™©ç¼“è§£æªæ–½
    if recommendation.get("risk_mitigation"):
        st.markdown("#### ğŸ›¡ï¸ é£é™©ç¼“è§£æªæ–½")
        for measure in recommendation["risk_mitigation"]:
            st.write(f"â€¢ {measure}")


def process_contract_workflow(file_path: str):
    """å¤„ç†åˆåŒå·¥ä½œæµ"""
    try:
        st.session_state.processing_status = "processing"

        # åˆ›å»ºå·¥ä½œæµå®ä¾‹
        workflow = ContractWorkflow()

        # æ­¥éª¤1: æ–‡æ¡£è§£æ/åˆ†æ
        with st.spinner("æ­£åœ¨è§£ææ–‡æ¡£å¹¶åˆ†æ..."):
            result = workflow.process_contract(
                file_path, original_file_name=st.session_state.file_name
            )

        if "error" in result:
            st.session_state.processing_status = "error"
            st.error(f"å¤„ç†å¤±è´¥: {result['error']}")
            return

        st.session_state.workflow_result = result
        st.session_state.processing_status = "completed"

        st.success("åˆåŒåˆ†æå®Œæˆï¼")

    except Exception as e:
        st.session_state.processing_status = "error"
        st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")


def main():
    """ä¸»å‡½æ•°"""
    initialize_session_state()

    # é¡µé¢æ ‡é¢˜
    st.title("ğŸ“„ åˆåŒå®¡æŸ¥ç³»ç»Ÿ")

    # ä¾§è¾¹æ  - æ–‡ä»¶ä¸Šä¼ 
    with st.sidebar:
        st.markdown("### ğŸ“ æ–‡ä»¶é€‰æ‹©")

        # åˆ›å»ºé€‰é¡¹å¡
        tab1, tab2 = st.tabs(["ğŸ“¤ ä¸Šä¼ æ–‡ä»¶", "ğŸ“‹ é€‰æ‹©æ ·ä¾‹"])

        with tab1:
            uploaded_file = st.file_uploader(
                "ä¸Šä¼ åˆåŒæ–‡ä»¶",
                type=["pdf", "docx", "txt", "doc"],
                help="æ”¯æŒPDFã€DOCXã€TXTã€DOCæ ¼å¼",
            )

            if uploaded_file:
                saved_path = save_uploaded_file(uploaded_file)
                if saved_path:
                    # åˆ‡æ¢æ–‡ä»¶æ—¶æ¸…ç©ºå†å²åˆ†æçŠ¶æ€ï¼Œå›åˆ°é¢„è§ˆæ€
                    st.session_state.workflow_result = None
                    st.session_state.processing_status = "idle"
                    st.session_state.loaded_from_history = False

                    st.session_state.saved_file_path = saved_path
                    st.session_state.file_name = uploaded_file.name
                    st.session_state.preview_content = preview_file_content(saved_path)

        with tab2:
            sample_files = get_sample_files()
            if sample_files:
                st.write("é€‰æ‹©æ ·ä¾‹æ–‡ä»¶ï¼š")
                for i, sample_path in enumerate(sample_files):
                    file_name = os.path.basename(sample_path)
                    if st.button(f"ğŸ“„ {file_name}", key=f"sample_{i}"):
                        temp_path = copy_sample_file(sample_path)
                        if temp_path:
                            # åˆ‡æ¢æ ·ä¾‹æ—¶æ¸…ç©ºå†å²åˆ†æçŠ¶æ€ï¼Œå›åˆ°é¢„è§ˆæ€
                            st.session_state.workflow_result = None
                            st.session_state.processing_status = "idle"
                            st.session_state.loaded_from_history = False

                            st.session_state.saved_file_path = temp_path
                            st.session_state.file_name = file_name
                            st.session_state.preview_content = preview_file_content(
                                temp_path
                            )
                            st.success(f"å·²é€‰æ‹©: {file_name}")
                            st.rerun()
            else:
                st.info("contractsç›®å½•ä¸‹æ²¡æœ‰æ ·ä¾‹æ–‡ä»¶")

    # ä¸»ç•Œé¢
    if (
        hasattr(st.session_state, "saved_file_path")
        and st.session_state.saved_file_path
    ):

        # æ–‡ä»¶ä¿¡æ¯
        st.markdown("### ğŸ“„ å½“å‰æ–‡ä»¶")
        col1, col2 = st.columns([3, 1])
        with col1:
            st.write(f"**æ–‡ä»¶å:** {st.session_state.file_name}")
        with col2:
            # é¡¶éƒ¨å³ä¾§ä¸å†å—çŠ¶æ€é™åˆ¶ï¼ŒæŒ‰é’®ä½ç½®å°†ä¸‹ç§»åˆ°è‡ªåŠ¨åŠ è½½é€»è¾‘ä¹‹å
            pass

        # è‹¥é€‰æ‹©äº†æ–‡ä»¶ï¼Œå°è¯•è‡ªåŠ¨åŠ è½½å†å²æœ€æ–°åˆ†æç»“æœ
        if (
            st.session_state.processing_status == "idle"
            and st.session_state.file_name
            and not st.session_state.loaded_from_history
        ):
            cached = load_latest_result_by_filename(st.session_state.file_name)
            if cached:
                st.session_state.workflow_result = cached
                st.session_state.processing_status = "completed"
                st.session_state.loaded_from_history = True
                st.success("å·²åŠ è½½å†å²æœ€æ–°åˆ†æç»“æœ")

        # æ“ä½œæŒ‰é’®ï¼šidle æ˜¾ç¤ºâ€œå¼€å§‹åˆ†æâ€ï¼›completed æ˜¾ç¤ºâ€œé‡æ–°æäº¤æ¨¡å‹åˆ†æâ€
        if st.session_state.processing_status in ("idle", "completed"):
            if st.session_state.processing_status == "completed":
                label = "ğŸ” é‡æ–°æäº¤æ¨¡å‹åˆ†æ"
            else:
                label = "ğŸš€ å¼€å§‹åˆ†æ"
            if st.button(label, type="primary", width='stretch'):
                process_contract_workflow(st.session_state.saved_file_path)
                st.rerun()

        # æ˜¾ç¤ºå¤„ç†çŠ¶æ€
        if st.session_state.processing_status == "processing":
            st.info("æ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨å€™...")

        # æ˜¾ç¤ºåˆ†æç»“æœ
        if (
            st.session_state.processing_status == "completed"
            and st.session_state.workflow_result
        ):
            result = st.session_state.workflow_result
            risk_analysis = result.get("risk_analysis", {})
            all_issues = risk_analysis.get("all_issues", [])

            # åˆ›å»ºå·¦å³åˆ†æ å¸ƒå±€
            col1, col2 = st.columns([1, 1], gap="large")

            with col1:
                # å·¦ä¾§ï¼šåˆåŒå†…å®¹åŒºåŸŸ
                st.markdown("### ğŸ“„ åˆåŒæ–‡æ¡£")

                # åˆåŒæ ‡é¢˜ï¼ˆç§»é™¤é‡å¤æŒ‰é’®ï¼Œä»…å±•ç¤ºæ–‡ä»¶åï¼‰
                st.markdown(f"**{st.session_state.file_name}**")

                # æ˜¾ç¤ºåˆåŒå†…å®¹ï¼ˆå¸¦é«˜äº®ï¼‰
                document_text = result.get("document_text", "")
                if document_text:
                    # ä¸ºé—®é¢˜æ·»åŠ é«˜äº®æ ‡è®°
                    highlighted_text = add_highlights_to_text(document_text, all_issues)

                    # æ˜¾ç¤ºæ ‡è®°åçš„æ–‡æœ¬
                    st.markdown("### ğŸ“„ åˆåŒå†…å®¹ï¼ˆå·²æ ‡è®°é—®é¢˜ï¼‰")
                    st.text_area(
                        "åˆåŒå†…å®¹ï¼ˆå·²æ ‡è®°ï¼‰",
                        value=highlighted_text,
                        height=800,
                        disabled=True,
                        label_visibility="collapsed",
                    )
                else:
                    st.warning("æœªè·å–åˆ°æ–‡æ¡£å†…å®¹")

            with col2:
                # å³ä¾§ï¼šé£é™©åˆ†æåŒºåŸŸ
                st.markdown("### ğŸ” å®¡æŸ¥ç»“æœ")

                # è§†å›¾åˆ‡æ¢ï¼šé£é™©ç‚¹ / ç»¼åˆå»ºè®®
                view = st.radio(
                    "é€‰æ‹©æŸ¥çœ‹å†…å®¹",
                    ["é£é™©ç‚¹", "ç»¼åˆå»ºè®®"],
                    horizontal=True,
                    key="result_view_switch",
                )

                suggestions = result.get("suggestions", {})
                statistics = risk_analysis.get("statistics", {})

                if view == "é£é™©ç‚¹":
                    # é£é™©ç­‰çº§ç­›é€‰
                    st.markdown("**é£é™©ç­‰çº§**")
                    risk_levels = ["å…¨éƒ¨", "é‡å¤§é£é™©", "ä¸€èˆ¬é£é™©", "ä½é£é™©"]
                    selected_level = st.radio(
                        "é€‰æ‹©é£é™©ç­‰çº§", risk_levels, horizontal=True, key="risk_filter"
                    )

                    # ç­›é€‰é—®é¢˜
                    filtered_issues = filter_issues_by_risk(all_issues, selected_level)

                    # é£é™©ç»Ÿè®¡
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("æ€»é—®é¢˜æ•°", len(filtered_issues))
                    with col2:
                        risk_score = statistics.get("risk_score", 0)
                        st.metric("é£é™©è¯„åˆ†", f"{risk_score}/100")
                    with col3:
                        risk_level = statistics.get("risk_level", "ä½")
                        level_color = {"é«˜": "ğŸ”´", "ä¸­": "ğŸŸ¡", "ä½": "ğŸŸ¢"}.get(
                            risk_level, "âšª"
                        )
                        st.metric("é£é™©ç­‰çº§", f"{level_color} {risk_level}")

                    # é£é™©é¡¹ç›®åˆ—è¡¨
                    if filtered_issues:
                        st.markdown("---")
                        for i, issue in enumerate(filtered_issues, 1):
                            risk_level = issue.get("é£é™©ç­‰çº§", "ä½")
                            issue_type = issue.get("ç±»å‹", "æœªçŸ¥ç±»å‹")

                            if risk_level == "é«˜":
                                risk_color = "ğŸ”´"
                                risk_label = "é‡å¤§é£é™©"
                            elif risk_level == "ä¸­":
                                risk_color = "ğŸŸ¡"
                                risk_label = "ä¸€èˆ¬é£é™©"
                            else:
                                risk_color = "ğŸŸ¢"
                                risk_label = "ä½é£é™©"

                            with st.container():
                                col1, col2 = st.columns([3, 1])

                                with col1:
                                    st.markdown(f"**{risk_color} {issue_type}**")
                                with col2:
                                    st.markdown(f"**{risk_label}**")

                                with st.expander("è¯¦ç»†ä¿¡æ¯", expanded=True):
                                    st.write(
                                        f"**æ¡æ¬¾ä½ç½®ï¼š** {issue.get('æ¡æ¬¾', 'N/A')}"
                                    )
                                    st.write(
                                        f"**é—®é¢˜æè¿°ï¼š** {issue.get('é—®é¢˜æè¿°', 'N/A')}"
                                    )
                                    st.write(
                                        f"**ä¿®æ”¹å»ºè®®ï¼š** {issue.get('ä¿®æ”¹å»ºè®®', 'N/A')}"
                                    )
                                    if issue.get("æ³•å¾‹ä¾æ®"):
                                        st.write(
                                            f"**æ³•å¾‹ä¾æ®ï¼š** {issue.get('æ³•å¾‹ä¾æ®', 'N/A')}"
                                        )
                                    if issue.get("å½±å“åˆ†æ"):
                                        st.write(
                                            f"**å½±å“åˆ†æï¼š** {issue.get('å½±å“åˆ†æ', 'N/A')}"
                                        )
                                    if issue.get("å•†ä¸šä¼˜åŒ–"):
                                        st.write(
                                            f"**å•†ä¸šä¼˜åŒ–ï¼š** {issue.get('å•†ä¸šä¼˜åŒ–', 'N/A')}"
                                        )

                                st.markdown("---")
                    else:
                        st.info("æœªå‘ç°é—®é¢˜")
                else:
                    # ç»¼åˆå»ºè®®è§†å›¾
                    if not suggestions:
                        st.info("æš‚æ— ç»¼åˆå»ºè®®")
                    else:
                        # æ˜¾ç¤ºæ ¸å¿ƒæ‘˜è¦ä¸å»ºè®®
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric(
                                "é£é™©è¯„åˆ†", f"{statistics.get('risk_score', 0)}/100"
                            )
                        with col2:
                            st.metric(
                                "æ€»é—®é¢˜æ•°",
                                statistics.get("total_issues", len(all_issues)),
                            )
                        with col3:
                            risk_level = statistics.get("risk_level", "ä½")
                            level_color = {"é«˜": "ğŸ”´", "ä¸­": "ğŸŸ¡", "ä½": "ğŸŸ¢"}.get(
                                risk_level, "âšª"
                            )
                            st.metric("é£é™©ç­‰çº§", f"{level_color} {risk_level}")

                        st.markdown("---")
                        # ç›´æ¥å¤ç”¨ç°æœ‰æ¸²æŸ“å‡½æ•°
                        render_suggestions(suggestions)

                # ä¸‹è½½ç»“æœæŒ‰é’®ï¼ˆç›´æ¥ä¸‹è½½ï¼‰
                st.markdown("---")
                json_bytes = json.dumps(result, ensure_ascii=False, indent=2).encode(
                    "utf-8"
                )
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½ç»“æœ",
                    data=json_bytes,
                    file_name=f"contract_analysis_{int(time.time())}.json",
                    mime="application/json",
                    width='stretch',
                )

        # æ˜¾ç¤ºæ–‡ä»¶é¢„è§ˆï¼ˆé‡æ„ä¸ºå·¦å³å¯¹ç…§å¸ƒå±€ï¼‰
        if (
            st.session_state.processing_status == "idle"
            and st.session_state.preview_content
        ):
            st.markdown("### ğŸ‘€ æ–‡ä»¶é¢„è§ˆä¸è¯†åˆ«å¯¹ç…§")
            render_preview_panel(
                st.session_state.saved_file_path, st.session_state.preview_content
            )

    else:
        st.info("è¯·ä¸Šä¼ åˆåŒæ–‡ä»¶æˆ–é€‰æ‹©æ ·ä¾‹æ–‡ä»¶å¼€å§‹åˆ†æ")

        # æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
        st.markdown("### ğŸ“– ä½¿ç”¨è¯´æ˜")
        st.markdown(
            """
        1. **ä¸Šä¼ æ–‡ä»¶**: åœ¨å·¦ä¾§è¾¹æ ä¸Šä¼ æ‚¨çš„åˆåŒæ–‡ä»¶ï¼ˆæ”¯æŒPDFã€DOCXã€TXTã€DOCæ ¼å¼ï¼‰
        2. **é€‰æ‹©æ ·ä¾‹**: æˆ–è€…ä»æ ·ä¾‹æ–‡ä»¶ä¸­é€‰æ‹©ä¸€ä¸ªè¿›è¡Œæµ‹è¯•
        3. **å¼€å§‹åˆ†æ**: ç‚¹å‡»"å¼€å§‹åˆ†æ"æŒ‰é’®ï¼Œç³»ç»Ÿå°†ä¾æ¬¡æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š
           - ğŸ“„ è§£ææ–‡æ¡£ï¼šæå–åˆåŒæ–‡æœ¬å†…å®¹
           - ğŸ” é£é™©åˆ†æï¼šè¯†åˆ«æ³•å¾‹ã€å•†ä¸šã€æ ¼å¼é£é™©
           - ğŸ’¡ å»ºè®®ç”Ÿæˆï¼šç”Ÿæˆç»¼åˆåˆ†æå’Œä¿®æ”¹å»ºè®®
           - ğŸ“Š ç»“æœå±•ç¤ºï¼šå±•ç¤ºè¯¦ç»†çš„åˆ†æç»“æœ
        4. **æŸ¥çœ‹ç»“æœ**: åœ¨ç»“æœé¡µé¢æŸ¥çœ‹é£é™©åˆ†æã€ä¿®æ”¹å»ºè®®å’Œç­¾çº¦å»ºè®®
        """
        )


if __name__ == "__main__":
    main()
