# ui_workflow.py
# åŸºäºå·¥ä½œæµçš„åˆåŒå®¡æŸ¥ç³»ç»ŸUIç•Œé¢

import os
import json
import time
import tempfile
import base64
from io import BytesIO
import logging
from typing import Dict, List, Optional, Any, Tuple
import streamlit as st
from contract_workflow import ContractWorkflow
import requests
import urllib
import warnings
import urllib3
from PIL import Image

# ç¦ç”¨SSLè­¦å‘Šï¼ˆä»…åœ¨ç¦ç”¨SSLéªŒè¯æ—¶ä½¿ç”¨ï¼‰
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="åˆåŒå®¡æŸ¥ç³»ç»Ÿ - å·¥ä½œæµç‰ˆ",
    page_icon="ğŸ“„",
    layout="wide",
    initial_sidebar_state="expanded",
)
warnings.filterwarnings("ignore")
# é™ä½è§¦å‘ç©º label æç¤ºçš„æ¨¡å—æ—¥å¿—çº§åˆ«ï¼ˆåŒä¿é™©ï¼‰
logging.getLogger("streamlit.elements.lib.policies").setLevel(logging.ERROR)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown(
    """
<style>
    /* ä¸»å®¹å™¨æ ·å¼ */
    .main-container {
        padding: 1px 2px;
        background-color: #f8f9fa;
    }
    
    div:has(> #left-preview-anchor),
    div:has(> #right-panel-anchor) {
        border: 1px solid #dee2e6;
        border-radius: 8px;
        background-color: #fff;
        padding: 16px;
        box-shadow: 0 2px 8px rgba(0,0,0,0.08);
    }
    
    div:has(> #left-preview-anchor) {
        height: 860px;
        overflow: auto;
    }
    
    div:has(> #right-panel-anchor) {
        height: 860px;
        overflow-y: auto;
        display: flex;
        flex-direction: column;
        gap: 12px;
    }
    
    .overall-image-wrapper {
        max-height: 780px;
        overflow-y: auto;
        overflow-x: hidden;
        padding: 12px;
        border: 1px solid #dee2e6;
        border-radius: 8px;
        background-color: #fafafa;
        display: flex;
        flex-direction: column;
        gap: 16px;
    }

    .overall-image-item {
        display: flex;
        flex-direction: column;
        align-items: center;
        gap: 8px;
    }

    .overall-image-item img {
        width: 100%;
        max-width: 100%;
        height: auto;
        border: 1px solid #e0e0e0;
        border-radius: 4px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }

    .overall-image-caption {
        font-size: 12px;
        color: #666;
        text-align: center;
    }
    
    /* å‡å°‘é¡µé¢é¡¶éƒ¨ç©ºç™½ */
    .main .block-container {
        padding-top: 1rem;
        padding-bottom: 1rem;
    }
    
    /* å‡å°‘æ ‡é¢˜é—´è·å’Œè°ƒæ•´å¤§å° */
    h1, h2, h3 {
        margin-top: 0.5rem;
        margin-bottom: 0.5rem;
    }
    
    /* è°ƒæ•´ä¸»æ ‡é¢˜å¤§å° */
    h1 {
        font-size: 1.8rem !important;
        font-weight: 600 !important;
    }
    
    /* éšè—æˆ–è°ƒå°å³ä¸Šè§’çš„rerunæŒ‰é’® */
    .stApp > header {
        visibility: hidden;
    }
    
    /* éšè—Streamlitçš„èœå•æŒ‰é’® */
    .stApp > div[data-testid="stToolbar"] {
        visibility: hidden;
    }
    
    /* éšè—å³ä¸Šè§’çš„èœå• */
    .stApp > div[data-testid="stHeader"] {
        visibility: hidden;
    }
    
    /* å·¥ä½œæµæ­¥éª¤æ ·å¼ */
    .workflow-step {
        background-color: white;
        border-radius: 8px;
        padding: 20px;
        margin: 10px 0;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        border-left: 4px solid #007bff;
    }
    
    .workflow-step.completed {
        border-left-color: #28a745;
        background-color: #f8fff9;
    }
    
    .workflow-step.current {
        border-left-color: #ffc107;
        background-color: #fffdf0;
    }
    
    .workflow-step.error {
        border-left-color: #dc3545;
        background-color: #fff5f5;
    }
    
    /* é£é™©å¡ç‰‡æ ·å¼ */
    .risk-card {
        background-color: #fff;
        border-radius: 8px;
        padding: 16px;
        margin: 8px 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        transition: transform 0.2s ease;
    }
    
    .risk-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 8px rgba(0,0,0,0.15);
    }
    
    /* é£é™©ç­‰çº§æ ‡ç­¾æ ·å¼ */
    .risk-high {
        background-color: #f44336;
        color: white;
        padding: 4px 8px;
        border-radius: 4px;
        font-size: 12px;
        font-weight: bold;
    }
    
    .risk-medium {
        background-color: #ff9800;
        color: white;
        padding: 4px 8px;
        border-radius: 4px;
        font-size: 12px;
        font-weight: bold;
    }
    
    .risk-low {
        background-color: #4caf50;
        color: white;
        padding: 4px 8px;
        border-radius: 4px;
        font-size: 12px;
        font-weight: bold;
    }
    
    /* ç¡®ä¿æ–‡æœ¬åŒºåŸŸæœ‰æ»šåŠ¨æ¡ */
    textarea {
        overflow-y: auto !important;
    }
    
    /* ç‰¹åˆ«é’ˆå¯¹å³ä¾§OCRè¯†åˆ«å¯¹ç…§åŒºåŸŸçš„æ–‡æœ¬åŒºåŸŸ - è®¾ç½®ä¸ºç™½è‰²èƒŒæ™¯ */
    div[data-testid="stTextArea"] textarea,
    textarea.stTextArea {
        background-color: white !important;
    }
    
    /* é’ˆå¯¹æ‰€æœ‰ç¦ç”¨çš„æ–‡æœ¬åŒºåŸŸï¼ˆé€šå¸¸ç”¨äºæ˜¾ç¤ºï¼‰ */
    textarea:disabled {
        background-color: white !important;
        opacity: 1 !important;
    }
    
    /* åŒæ­¥æ»šåŠ¨å®¹å™¨æ ·å¼ */
    .sync-scroll-container {
        max-height: 780px;
        overflow-y: auto;
        overflow-x: hidden;
    }
    
</style>
""",
    unsafe_allow_html=True,
)


def initialize_session_state():
    """åˆå§‹åŒ–session state"""
    if "workflow_result" not in st.session_state:
        st.session_state.workflow_result = None
    if "processing_status" not in st.session_state:
        st.session_state.processing_status = (
            "idle"  # idle, processing, completed, error
        )
    if "file_name" not in st.session_state:
        st.session_state.file_name = None
    if "preview_content" not in st.session_state:
        st.session_state.preview_content = None
    if "loaded_from_history" not in st.session_state:
        st.session_state.loaded_from_history = False
    if "ocr_parse_result" not in st.session_state:
        # ç”¨äºå³ä¾§å¯¹ç…§é¢æ¿çš„åœ¨çº¿è§£æç»“æœç¼“å­˜
        st.session_state.ocr_parse_result = None
    if "ocr_parsed_file_path" not in st.session_state:
        # è®°å½•ä¸Šæ¬¡OCRè§£æçš„æ–‡ä»¶è·¯å¾„ï¼Œç”¨äºæ£€æŸ¥æ–‡ä»¶æ˜¯å¦åˆ‡æ¢
        st.session_state.ocr_parsed_file_path = None
    if "view_mode" not in st.session_state:
        # preview: é¢„è§ˆç•Œé¢ï¼›analysis: åˆ†æç»“æœç•Œé¢
        st.session_state.view_mode = "preview"


def load_latest_result_by_filename(file_name: str) -> Optional[Dict[str, Any]]:
    """æ ¹æ®æ–‡ä»¶ååŠ è½½è¯¥æ–‡ä»¶çš„æœ€æ–°åˆ†æç»“æœã€‚

    ä¼˜å…ˆåŒ¹é… result["original_file_name"] == file_nameï¼›
    å…¼å®¹æ—§ç»“æœï¼šè‹¥æ—  original_file_nameï¼Œåˆ™ç”¨ basename(result["file_path"]) æ¯”å¯¹ã€‚
    """
    results_dir = "contract_analysis_results"
    if not os.path.exists(results_dir):
        return None

    candidates: List[Dict[str, Any]] = []
    for fname in os.listdir(results_dir):
        if not fname.lower().endswith(".json"):
            continue
        fpath = os.path.join(results_dir, fname)
        try:
            with open(fpath, "r", encoding="utf-8") as f:
                data = json.load(f)
            # åŒ¹é…é€»è¾‘
            match = False
            ori = data.get("original_file_name")
            if ori and ori == file_name:
                match = True
            else:
                # å…¼å®¹æ—§æ•°æ®
                fp = data.get("file_path")
                if isinstance(fp, str) and os.path.basename(fp) == file_name:
                    match = True
            if match:
                # ä»¥ processing_time ä¸ºä¸»ï¼Œé€€åŒ–åˆ°æ–‡ä»¶åæ—¶é—´æˆ³æ’åº
                ts = data.get("processing_time")
                candidates.append(
                    {
                        "_ts": float(ts) if isinstance(ts, (int, float)) else 0.0,
                        "_path": fpath,
                        "data": data,
                    }
                )
        except Exception:
            continue

    if not candidates:
        return None

    # è‹¥ processing_time éƒ½ä¸º 0ï¼Œåˆ™ä½¿ç”¨æ–‡ä»¶åä¸­çš„æ—¶é—´æˆ³è¿›è¡Œæ’åºä½œä¸ºå…œåº•
    def extract_name_ts(p: str) -> float:
        base = os.path.basename(p)
        # å½¢å¦‚ contract_analysis_YYYYmmdd_HHMMSS.json
        try:
            stem = os.path.splitext(base)[0]
            parts = stem.split("_")
            if len(parts) >= 3:
                dt = parts[-2] + parts[-1]  # YYYYmmdd + HHMMSS
                # è½¬æ¢ä¸ºç»“æ„åŒ–æ—¶é—´
                import datetime

                d = datetime.datetime.strptime(dt, "%Y%m%d%H%M%S")
                return d.timestamp()
        except Exception:
            pass
        return 0.0

    for c in candidates:
        if not c["_ts"]:
            c["_ts"] = extract_name_ts(c["_path"]) or 0.0

    candidates.sort(key=lambda x: x["_ts"], reverse=True)
    return candidates[0]["data"]


def save_uploaded_file(uploaded_file) -> Optional[str]:
    """ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶"""
    if not uploaded_file:
        return None
    suffix = os.path.splitext(uploaded_file.name)[1]
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
        tmp.write(uploaded_file.read())
        return tmp.name


def get_sample_files() -> List[str]:
    """è·å–æ ·ä¾‹æ–‡ä»¶åˆ—è¡¨"""
    contracts_dir = "contracts"
    if not os.path.exists(contracts_dir):
        return []

    sample_files = []
    for file in os.listdir(contracts_dir):
        file_path = os.path.join(contracts_dir, file)
        if os.path.isfile(file_path) and file.lower().endswith(
            (".pdf", ".docx", ".txt", ".doc")
        ):
            sample_files.append(file_path)

    return sample_files


def copy_sample_file(sample_path: str) -> Optional[str]:
    """å¤åˆ¶æ ·ä¾‹æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•"""
    try:
        suffix = os.path.splitext(sample_path)[1]
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
            with open(sample_path, "rb") as src:
                tmp.write(src.read())
            return tmp.name
    except Exception as e:
        st.error(f"å¤åˆ¶æ ·ä¾‹æ–‡ä»¶å¤±è´¥: {str(e)}")
        return None


def preview_file_content(file_path: str) -> str:
    """é¢„è§ˆæ–‡ä»¶å†…å®¹"""
    try:
        file_ext = os.path.splitext(file_path)[1].lower()

        if file_ext == ".txt":
            encodings = ["utf-8", "gbk", "gb2312", "gb18030"]
            for encoding in encodings:
                try:
                    with open(file_path, "r", encoding=encoding) as f:
                        content = f.read()
                    return content[:2000] + "..." if len(content) > 2000 else content
                except UnicodeDecodeError:
                    continue
            return "æ— æ³•è¯»å–æ–‡ä»¶å†…å®¹"

        elif file_ext == ".docx":
            try:
                import docx

                doc = docx.Document(file_path)
                content = "\n".join([para.text for para in doc.paragraphs])
                return content[:2000] + "..." if len(content) > 2000 else content
            except Exception as e:
                return f"è¯»å–Wordæ–‡æ¡£å¤±è´¥: {str(e)}"

        elif file_ext == ".pdf":
            try:
                from pdfminer.high_level import extract_text

                content = extract_text(file_path)
                return content[:2000] + "..." if len(content) > 2000 else content
            except Exception as e:
                return f"è¯»å–PDFæ–‡ä»¶å¤±è´¥: {str(e)}"

        else:
            return f"ä¸æ”¯æŒé¢„è§ˆ {file_ext} æ ¼å¼æ–‡ä»¶"

    except Exception as e:
        return f"é¢„è§ˆæ–‡ä»¶å¤±è´¥: {str(e)}"


def _read_file_as_base64(file_path: str) -> Optional[str]:
    """è¯»å–æ–‡ä»¶å¹¶è¿”å›base64ï¼ˆç”¨äºå†…åµŒPDFé¢„è§ˆï¼‰ã€‚"""
    try:
        with open(file_path, "rb") as f:
            return base64.b64encode(f.read()).decode("utf-8")
    except Exception:
        return None


def render_file_preview(file_path: str, height: int = 780):
    """å·¦ä¾§æºæ–‡ä»¶é¢„è§ˆã€‚

    - PDF: æŒ‰é¡µæ¸²æŸ“ä¸ºå›¾ç‰‡è¿›è¡Œå±•ç¤ºï¼ˆåŸºäº PyMuPDFï¼‰
    - å…¶ä»–: ä»¥æ–‡æœ¬æ–¹å¼å±•ç¤ºï¼ˆå¸¦æ»šåŠ¨æ¡ï¼‰
    """
    file_ext = os.path.splitext(file_path)[1].lower()

    if file_ext == ".pdf":
        try:
            import fitz  # PyMuPDF

            doc = fitz.open(file_path)
            if doc.page_count == 0:
                st.warning("PDF æ— é¡µé¢å¯é¢„è§ˆ")
                return

            # å½“å‰é¡µï¼ˆç”¨äºæ˜¾ç¤ºé¡µç å’Œè·³è½¬ï¼‰
            page_key = f"pdf_page_{os.path.basename(file_path)}"
            current_page = int(st.session_state.get(page_key, 1))
            if current_page < 1:
                current_page = 1
            if current_page > doc.page_count:
                current_page = doc.page_count

            # æ¸²æŸ“æ‰€æœ‰é¡µé¢åˆ°ä¸€ä¸ªé•¿å®¹å™¨ä¸­
            page_images = []
            for page_num in range(doc.page_count):
                page = doc.load_page(page_num)
                # æé«˜DPIä»¥è·å¾—æ›´æ¸…æ™°çš„å›¾ç‰‡
                pix = page.get_pixmap(matrix=fitz.Matrix(2.5, 2.5))
                img_bytes = pix.tobytes("png")
                img_base64 = base64.b64encode(img_bytes).decode()
                page_images.append({
                    'page_num': page_num + 1,
                    'img_base64': img_base64
                })
            
            # ä½¿ç”¨å›ºå®šé«˜åº¦çš„å¯æ»šåŠ¨å®¹å™¨åŒ…è£…æ‰€æœ‰é¡µé¢
            container_id = f"pdf-container-{os.path.basename(file_path).replace('.', '_').replace(' ', '_')}"
            scroll_key = f"scroll_to_page_{page_key}"
            target_page = st.session_state.get(scroll_key, current_page)
            
            # æ„å»ºæ‰€æœ‰é¡µé¢çš„HTMLå†…å®¹
            pages_html_content = ""
            for page_data in page_images:
                page_num = page_data['page_num']
                img_base64 = page_data['img_base64']
                pages_html_content += f'<div id="pdf-page-{page_num}" style="margin-bottom: 20px; text-align: center;"><img src="data:image/png;base64,{img_base64}" style="width: 100%; max-width: 100%; height: auto; border: 1px solid #ddd; border-radius: 4px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); display: block; margin: 10px auto;" /><div style="margin-top: 10px; color: #666; font-size: 12px;">ç¬¬ {page_num} é¡µ / å…± {doc.page_count} é¡µ</div></div>'
            
            # æ„å»ºå®Œæ•´çš„HTML
            html_content = f"""
            <div id="{container_id}" style="max-height: {height}px; overflow-y: auto; overflow-x: auto; border: 1px solid #e0e0e0; border-radius: 4px; padding: 10px; margin-bottom: 10px; background-color: #fafafa;">
                {pages_html_content}
            </div>
            <script>
                (function() {{
                    const containerId = '{container_id}';
                    const targetPage = {target_page};
                    
                    function scrollToPage(pageNum) {{
                        const container = document.getElementById(containerId);
                        const pageElement = document.getElementById('pdf-page-' + pageNum);
                        if (container && pageElement) {{
                            const scrollTop = pageElement.offsetTop - container.offsetTop - 10;
                            container.scrollTo({{
                                top: scrollTop,
                                behavior: 'smooth'
                            }});
                        }}
                    }}
                    
                    function initScroll() {{
                        const container = document.getElementById(containerId);
                        if (container) {{
                            scrollToPage(targetPage);
                        }} else {{
                            setTimeout(initScroll, 100);
                        }}
                    }}
                    
                    if (document.readyState === 'loading') {{
                        document.addEventListener('DOMContentLoaded', initScroll);
                    }} else {{
                        initScroll();
                    }}
                    
                    window['scrollToPage_' + containerId] = scrollToPage;
                }})();
            </script>
            """
            
            # ä½¿ç”¨markdownæ¸²æŸ“ï¼Œç¡®ä¿HTMLæ­£ç¡®æ˜¾ç¤º
            st.markdown(html_content, unsafe_allow_html=True)

            # æ§ä»¶æ”¾åœ¨å›¾ç‰‡æ­£ä¸‹æ–¹ï¼šä¸Šä¸€é¡µ/é¡µç è¾“å…¥/ä¸‹ä¸€é¡µ
            ctrl_left, ctrl_mid, ctrl_right = st.columns([1, 2, 1])
            with ctrl_left:
                if st.button("ä¸Šä¸€é¡µ", width='stretch', key=f"prev_{page_key}"):
                    new_page = max(1, current_page - 1)
                    if new_page != current_page:
                        st.session_state[page_key] = new_page
                        st.session_state[scroll_key] = new_page
                        st.rerun()
            with ctrl_mid:
                new_val = st.number_input(
                    "é¡µç ",
                    min_value=1,
                    max_value=doc.page_count,
                    value=current_page,
                    step=1,
                    key=f"num_{page_key}",
                    label_visibility="collapsed",
                )
                if int(new_val) != current_page:
                    st.session_state[page_key] = int(new_val)
                    st.session_state[scroll_key] = int(new_val)
                    st.rerun()
            with ctrl_right:
                if st.button("ä¸‹ä¸€é¡µ", width='stretch', key=f"next_{page_key}"):
                    new_page = min(doc.page_count, current_page + 1)
                    if new_page != current_page:
                        st.session_state[page_key] = new_page
                        st.session_state[scroll_key] = new_page
                        st.rerun()
        except Exception:
            # å…œåº•ï¼šå›é€€åˆ°æ–‡æœ¬æ¨¡å¼
            st.warning("å›¾ç‰‡é¢„è§ˆå¤±è´¥ï¼Œå·²åˆ‡æ¢ä¸ºæ–‡æœ¬æ¨¡å¼ã€‚")
            st.text_area(
                "æ–‡ä»¶å†…å®¹",
                preview_file_content(file_path),
                height=height,
                disabled=True,
                key="left_text_area"
            )
    else:
        # éPDFæ–‡ä»¶ä½¿ç”¨text_areaæ˜¾ç¤ºï¼Œç¡®ä¿æœ‰æ»šåŠ¨æ¡
        st.text_area(
            "æ–‡ä»¶å†…å®¹", 
            preview_file_content(file_path), 
            height=height, 
            disabled=True,
            key="left_text_area"
        )


def render_preview_panel(file_path: str, preview_text: str):
    """ä¸¤æ é¢„è§ˆï¼šå·¦ä¾§æºæ–‡ä»¶ï¼Œå³ä¾§è¯†åˆ«ç»“æœå¯¹ç…§ï¼ˆå‚è€ƒç¤ºä¾‹UIï¼‰ï¼Œæ”¯æŒåŒæ­¥æ»šåŠ¨ã€‚"""
    
    # æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ”¹å˜ï¼Œå¦‚æœæ”¹å˜åˆ™å°è¯•åŠ è½½æ–°æ–‡ä»¶çš„ç¼“å­˜
    if st.session_state.ocr_parsed_file_path != file_path:
        # å°è¯•åŠ è½½æ–°æ–‡ä»¶çš„ç¼“å­˜ï¼ˆä½¿ç”¨åŸå§‹æ–‡ä»¶åï¼‰
        original_file_name = st.session_state.get("file_name")
        cached_result = load_cached_parse_result(file_path, original_file_name)
        if cached_result:
            # å¦‚æœæœ‰ç¼“å­˜ï¼ŒåŠ è½½å¹¶æ˜¾ç¤º
            st.session_state.ocr_parse_result = cached_result
            st.session_state.ocr_parsed_file_path = file_path
        else:
            # å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œæ¸…ç©ºOCRè§£æç»“æœ
            st.session_state.ocr_parse_result = None
            st.session_state.ocr_parsed_file_path = None
    
    # æ·»åŠ åŒæ­¥æ»šåŠ¨çš„JavaScriptä»£ç 
    sync_scroll_js = """
    <script>
    (function() {
        let leftPanel = null;
        let rightPanel = null;
        let isScrolling = false;
        
        function findScrollablePanels() {
            // æŸ¥æ‰¾æ‰€æœ‰å¯æ»šåŠ¨çš„å…ƒç´ 
            const allElements = document.querySelectorAll('*');
            const scrollableElements = [];
            
            for (let el of allElements) {
                const style = window.getComputedStyle(el);
                const hasScroll = el.scrollHeight > el.clientHeight;
                const isScrollable = style.overflow === 'auto' || 
                                    style.overflow === 'scroll' || 
                                    style.overflowY === 'auto' || 
                                    style.overflowY === 'scroll';
                
                // æŸ¥æ‰¾å¯æ»šåŠ¨çš„å®¹å™¨ï¼ˆåŒ…æ‹¬PDFå›¾ç‰‡å®¹å™¨å’Œtextareaï¼‰
                if (hasScroll && isScrollable && el.offsetHeight > 200) {
                    scrollableElements.push(el);
                }
            }
            
            // æŸ¥æ‰¾å³ä¾§çš„textareaï¼ˆç”¨äºOCRè¯†åˆ«ç»“æœï¼‰
            const textareas = Array.from(document.querySelectorAll('textarea'));
            let rightTextarea = null;
            
            // é€šè¿‡ä½ç½®æŸ¥æ‰¾å³ä¾§çš„textarea
            for (let ta of textareas) {
                const rect = ta.getBoundingClientRect();
                if (rect.left > window.innerWidth / 2 && 
                    ta.scrollHeight > ta.clientHeight) {
                    rightTextarea = ta;
                    break;
                }
            }
            
            // æŸ¥æ‰¾å·¦ä¾§çš„å¯æ»šåŠ¨å®¹å™¨ï¼ˆå¯èƒ½æ˜¯PDFå›¾ç‰‡å®¹å™¨æˆ–textareaï¼‰
            let leftPanel = null;
            
            // ä¼˜å…ˆæŸ¥æ‰¾PDFå®¹å™¨ï¼ˆé€šè¿‡IDç‰¹å¾ï¼‰
            for (let el of scrollableElements) {
                const rect = el.getBoundingClientRect();
                // å·¦ä¾§é¢æ¿åº”è¯¥åœ¨å±å¹•å·¦åŠéƒ¨åˆ†
                if (rect.left < window.innerWidth / 2) {
                    // ä¼˜å…ˆé€‰æ‹©PDFå®¹å™¨ï¼ˆIDåŒ…å«pdf-containerï¼‰æˆ–åŒ…å«å¤šä¸ªå›¾ç‰‡çš„å®¹å™¨
                    if (el.id && el.id.includes('pdf-container')) {
                        leftPanel = el;
                        break;
                    }
                    // å…¶æ¬¡é€‰æ‹©åŒ…å«å›¾ç‰‡çš„å®¹å™¨ï¼ˆPDFé¢„è§ˆï¼‰
                    if (el.querySelector('img') || el.tagName === 'TEXTAREA') {
                        leftPanel = el;
                        break;
                    }
                }
            }
            
            // å¦‚æœæ²¡æ‰¾åˆ°å·¦ä¾§é¢æ¿ï¼Œå°è¯•ä»scrollableElementsä¸­é€‰æ‹©æœ€å·¦è¾¹çš„
            if (!leftPanel && scrollableElements.length > 0) {
                scrollableElements.sort((a, b) => {
                    return a.getBoundingClientRect().left - b.getBoundingClientRect().left;
                });
                leftPanel = scrollableElements[0];
            }
            
            // å¦‚æœæ‰¾åˆ°äº†å·¦å³ä¸¤ä¸ªé¢æ¿ï¼Œè¿”å›å®ƒä»¬
            if (leftPanel && rightTextarea && leftPanel !== rightTextarea) {
                return [leftPanel, rightTextarea];
            }
            
            // å¦‚æœæ‰¾ä¸åˆ°å³ä¾§textareaï¼Œå°è¯•ä»scrollableElementsä¸­æ‰¾å³ä¾§çš„
            if (leftPanel && !rightTextarea && scrollableElements.length >= 2) {
                for (let el of scrollableElements) {
                    const rect = el.getBoundingClientRect();
                    if (rect.left > window.innerWidth / 2 && el !== leftPanel) {
                        return [leftPanel, el];
                    }
                }
            }
            
            // å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°ï¼Œå°è¯•ä»scrollableElementsä¸­æŒ‰ä½ç½®æ’åº
            if (scrollableElements.length >= 2) {
                scrollableElements.sort((a, b) => {
                    return a.getBoundingClientRect().left - b.getBoundingClientRect().left;
                });
                return [scrollableElements[0], scrollableElements[1]];
            }
            
            return null;
        }
        
        function syncScroll(source, target) {
            if (isScrolling || !source || !target) return;
            isScrolling = true;
            
            const sourceScrollTop = source.scrollTop;
            const sourceScrollHeight = source.scrollHeight;
            const sourceClientHeight = source.clientHeight;
            const targetScrollHeight = target.scrollHeight;
            const targetClientHeight = target.clientHeight;
            
            if (sourceScrollHeight <= sourceClientHeight || targetScrollHeight <= targetClientHeight) {
                isScrolling = false;
                return;
            }
            
            // è®¡ç®—ç›®æ ‡æ»šåŠ¨ä½ç½®ï¼ˆæŒ‰æ¯”ä¾‹ï¼‰
            const scrollRatio = sourceScrollTop / (sourceScrollHeight - sourceClientHeight);
            const targetScrollTop = scrollRatio * (targetScrollHeight - targetClientHeight);
            
            target.scrollTop = targetScrollTop;
            
            setTimeout(() => { isScrolling = false; }, 10);
        }
        
        function initSyncScroll() {
            const panels = findScrollablePanels();
            if (panels && panels.length === 2) {
                leftPanel = panels[0];
                rightPanel = panels[1];
                
                // ç§»é™¤æ—§çš„äº‹ä»¶ç›‘å¬å™¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if (leftPanel._syncScrollHandler) {
                    leftPanel.removeEventListener('scroll', leftPanel._syncScrollHandler);
                }
                if (rightPanel._syncScrollHandler) {
                    rightPanel.removeEventListener('scroll', rightPanel._syncScrollHandler);
                }
                
                // æ·»åŠ æ–°çš„äº‹ä»¶ç›‘å¬å™¨
                leftPanel._syncScrollHandler = () => syncScroll(leftPanel, rightPanel);
                rightPanel._syncScrollHandler = () => syncScroll(rightPanel, leftPanel);
                
                leftPanel.addEventListener('scroll', leftPanel._syncScrollHandler, { passive: true });
                rightPanel.addEventListener('scroll', rightPanel._syncScrollHandler, { passive: true });
            }
        }
        
        // ä½¿ç”¨MutationObserverç›‘å¬DOMå˜åŒ–
        const observer = new MutationObserver(() => {
            setTimeout(initSyncScroll, 100);
        });
        
        observer.observe(document.body, {
            childList: true,
            subtree: true
        });
        
        // åˆå§‹æ‰§è¡Œ
        setTimeout(initSyncScroll, 1000);
        
        // é¡µé¢æ»šåŠ¨æ—¶ä¹Ÿå°è¯•åˆå§‹åŒ–
        window.addEventListener('load', () => {
            setTimeout(initSyncScroll, 500);
        });
    })();
    </script>
    """
    
    # æ³¨å…¥JavaScript
    st.components.v1.html(sync_scroll_js, height=0)
    
    left, right = st.columns([1, 1], gap="large")
    
    with left:
        st.markdown("#### æºæ–‡ä»¶é¢„è§ˆ")
        left_container = st.container()
        with left_container:
            st.markdown('<span id="left-preview-anchor"></span>', unsafe_allow_html=True)
            render_file_preview(file_path)

    with right:
        st.markdown("#### è§£æç»“æœå¯¹ç…§")
        right_container = st.container()
        with right_container:
            st.markdown('<span id="right-panel-anchor"></span>', unsafe_allow_html=True)
            tabs = st.tabs(["OCRè¯†åˆ«å¯¹ç…§", "Markdown", "JSON"])

            with tabs[0]:
                # åœ¨çº¿APIè°ƒç”¨ï¼šç™¾åº¦æ–‡æ¡£è§£æï¼ˆéœ€è¦è®¾ç½®ç¯å¢ƒå˜é‡ BAIDU_PARSER_AUTHï¼‰
                colA, colB = st.columns([1, 1])
                with colA:
                    if st.button("â–¶ è°ƒç”¨OCRè§£æ", key="btn_call_ocr"):
                        st.session_state.ocr_parse_result = call_online_parse_api(file_path)
                        st.session_state.ocr_parsed_file_path = file_path  # è®°å½•å½“å‰è§£æçš„æ–‡ä»¶è·¯å¾„
                        st.rerun()
                with colB:
                    if st.session_state.ocr_parse_result:
                        if st.session_state.ocr_parse_result.get("_cached"):
                            st.info("å·²ä»ç¼“å­˜åŠ è½½è§£æç»“æœ")
                        else:
                            st.success("å·²è·å–åœ¨çº¿è§£æç»“æœ")

                # è‡ªåŠ¨å±•ç¤ºæ•´ä½“OCRå›¾
                img_paths: List[str] = []
                if st.session_state.ocr_parse_result and isinstance(
                    st.session_state.ocr_parse_result, dict
                ):
                    img_paths = st.session_state.ocr_parse_result.get("overall_image_paths") or []
                if img_paths:
                    st.markdown("##### æ•´ä½“OCRå›¾")
                    image_blocks: List[str] = []
                    for p in img_paths:
                        if not os.path.exists(p):
                            continue
                        caption = os.path.basename(p)
                        try:
                            with Image.open(p) as img:
                                width, height = img.size
                                crop_left = width // 2
                                right_half = img.crop((crop_left, 0, width, height)).copy()
                                buffer = BytesIO()
                                right_half.save(buffer, format="PNG")
                                img_data = base64.b64encode(buffer.getvalue()).decode()
                        except Exception as exc:
                            st.warning(f"åŠ è½½æ•´ä½“OCRå›¾å¤±è´¥ï¼š{caption}ï¼ŒåŸå› ï¼š{exc}")
                            try:
                                with open(p, "rb") as fallback_file:
                                    img_data = base64.b64encode(fallback_file.read()).decode()
                            except Exception:
                                continue
                        image_blocks.append(
                            (
                                '<div class="overall-image-item">'
                                f'<img src="data:image/png;base64,{img_data}" alt="{caption}" />'
                                f'<div class="overall-image-caption">{caption}</div>'
                                "</div>"
                            )
                        )
                    if image_blocks:
                        images_html = '<div class="overall-image-wrapper">' + "".join(image_blocks) + "</div>"
                        st.markdown(images_html, unsafe_allow_html=True)
                elif st.session_state.ocr_parse_result:
                    st.info("æš‚æ— æ•´ä½“OCRå›¾å¯å±•ç¤º")

                # OCRè¯†åˆ«å¯¹ç…§ï¼šä»JSONä¸­æå–æ–‡å­—ã€ä½ç½®ã€æ’ç‰ˆç­‰ä¿¡æ¯å¹¶æ¸²æŸ“
                # åœ¨è°ƒç”¨OCRè§£æä¹‹å‰åº”è¯¥æ˜¾ç¤ºä¸ºç©º
                ocr_text = None
                if st.session_state.ocr_parse_result and isinstance(
                    st.session_state.ocr_parse_result, dict
                ):
                    json_result = st.session_state.ocr_parse_result.get("json_result", {})
                    if json_result:
                        # ä½¿ç”¨format_json_result_as_textå‡½æ•°ä»JSONä¸­æå–å¹¶æ ¼å¼åŒ–ä¿¡æ¯
                        ocr_text = format_json_result_as_text(json_result)
                    else:
                        # å¦‚æœæ²¡æœ‰JSONç»“æœï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬
                        ocr_text = st.session_state.ocr_parse_result.get("raw_text", "")
                else:
                    ocr_text = ""  # è°ƒç”¨OCRè§£æä¹‹å‰æ˜¾ç¤ºä¸ºç©º
                
                # ä½¿ç”¨å›ºå®šé«˜åº¦çš„æ–‡æœ¬åŒºåŸŸï¼Œç¡®ä¿æœ‰æ»šåŠ¨æ¡
                st.text_area(
                    "è¯†åˆ«æ–‡æœ¬",
                    ocr_text if ocr_text else "",
                    height=780,
                    disabled=True,
                    label_visibility="collapsed",
                    key="right_text_area"
                )

                # è‹¥æœ‰åœ¨çº¿è§£æçš„åŸå§‹è¿”å›ï¼Œæä¾›è°ƒè¯•è¾“å‡º
                if st.session_state.ocr_parse_result and isinstance(
                    st.session_state.ocr_parse_result, dict
                ):
                    with st.expander("API è°ƒè¯•è¾“å‡º", expanded=False):
                        st.json(st.session_state.ocr_parse_result)

            with tabs[1]:
                # Markdown tabï¼šæ˜¾ç¤ºä»markdown_urlä¸‹è½½ä¸‹æ¥çš„æ–‡ä»¶æ¸²æŸ“çš„ç»“æœ
                # åœ¨è°ƒç”¨OCRè§£æä¹‹å‰åº”è¯¥æ˜¾ç¤ºä¸ºç©º
                markdown_content = None
                if st.session_state.ocr_parse_result and isinstance(
                    st.session_state.ocr_parse_result, dict
                ):
                    markdown_content = st.session_state.ocr_parse_result.get("markdown_text")
                
                if markdown_content:
                    # ä½¿ç”¨å›ºå®šé«˜åº¦çš„å®¹å™¨ç¡®ä¿å¯æ»šåŠ¨ï¼Œä½¿ç”¨Streamlitçš„markdownæ¸²æŸ“
                    st.markdown(
                        """
                        <style>
                        .markdown-scroll-container {
                            max-height: 780px;
                            overflow-y: auto;
                            overflow-x: auto;
                            padding: 10px;
                            border: 1px solid #e0e0e0;
                            border-radius: 4px;
                            background-color: #fafafa;
                        }
                        </style>
                        """,
                        unsafe_allow_html=True
                    )
                    # ä½¿ç”¨Streamlitçš„markdownæ¸²æŸ“
                    st.markdown(markdown_content)
                else:
                    # è°ƒç”¨OCRè§£æä¹‹å‰æ˜¾ç¤ºä¸ºç©º
                    st.text_area(
                        "Markdownå†…å®¹",
                        "",
                        height=780,
                        disabled=True,
                        label_visibility="collapsed",
                        key="markdown_preview_area"
                    )

            with tabs[2]:
                # JSON tabï¼šæ˜¾ç¤ºjson_resultçš„åŸå§‹JSONæ ¼å¼
                # åœ¨è°ƒç”¨OCRè§£æä¹‹å‰åº”è¯¥æ˜¾ç¤ºä¸ºç©º
                if st.session_state.ocr_parse_result and isinstance(
                    st.session_state.ocr_parse_result, dict
                ):
                    json_result = st.session_state.ocr_parse_result.get("json_result", {})
                    if json_result:
                        st.json(json_result)
                    else:
                        st.info("æš‚æ— JSONç»“æœã€‚")
                else:
                    # è°ƒç”¨OCRè§£æä¹‹å‰æ˜¾ç¤ºä¸ºç©º
                    st.text_area(
                        "JSONå†…å®¹",
                        "",
                        height=780,
                        disabled=True,
                        label_visibility="collapsed",
                        key="json_preview_area"
                    )


def get_cache_file_paths(file_path: str, original_file_name: Optional[str] = None) -> Tuple[str, str]:
    """æ ¹æ®æ–‡ä»¶è·¯å¾„ç”Ÿæˆç¼“å­˜æ–‡ä»¶è·¯å¾„ï¼ˆjsonå’Œmdï¼‰
    
    ä¼˜å…ˆä½¿ç”¨åŸå§‹æ–‡ä»¶åï¼ˆoriginal_file_nameï¼‰ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æ–‡ä»¶è·¯å¾„ä¸­çš„æ–‡ä»¶åã€‚
    ä½¿ç”¨PDFæ–‡ä»¶åï¼ˆå»æ‰æ‰©å±•åï¼‰ä½œä¸ºåŸºç¡€åç§°ï¼Œä¾¿äºä¸PDFå¯¹åº”ã€‚
    å¦‚æœæ–‡ä»¶ååŒ…å«ç‰¹æ®Šå­—ç¬¦ï¼Œä¼šè¿›è¡Œæ¸…ç†ä»¥ç¡®ä¿æ–‡ä»¶ç³»ç»Ÿå…¼å®¹æ€§ã€‚
    """
    import re
    # ä¼˜å…ˆä½¿ç”¨åŸå§‹æ–‡ä»¶åï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æ–‡ä»¶è·¯å¾„ä¸­çš„æ–‡ä»¶å
    if original_file_name:
        base_name = os.path.splitext(original_file_name)[0]
    else:
        base_name = os.path.splitext(os.path.basename(file_path))[0]
    
    # æ¸…ç†æ–‡ä»¶åä¸­çš„ç‰¹æ®Šå­—ç¬¦ï¼Œåªä¿ç•™å­—æ¯ã€æ•°å­—ã€ä¸­æ–‡ã€æ•°å­—ã€ä¸‹åˆ’çº¿å’Œè¿å­—ç¬¦
    # æ›¿æ¢å…¶ä»–ç‰¹æ®Šå­—ç¬¦ä¸ºä¸‹åˆ’çº¿
    safe_name = re.sub(r'[^\w\u4e00-\u9fff-]', '_', base_name)
    # å»é™¤è¿ç»­çš„ä¸‹åˆ’çº¿
    safe_name = re.sub(r'_+', '_', safe_name)
    # å»é™¤é¦–å°¾çš„ä¸‹åˆ’çº¿
    safe_name = safe_name.strip('_')
    
    # å¦‚æœæ¸…ç†åä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤åç§°
    if not safe_name:
        safe_name = "unnamed_file"
    
    json_path = os.path.join("jsons", f"{safe_name}.json")
    md_path = os.path.join("mds", f"{safe_name}.md")
    
    return json_path, md_path


def get_overall_image_dir(file_path: str, original_file_name: Optional[str] = None) -> str:
    """è·å–æ•´ä½“OCRå›¾ç‰‡ä¿å­˜ç›®å½•ï¼ˆæŒ‰åŸæ–‡ä»¶ååŒºåˆ†ï¼‰ã€‚"""
    json_path, _ = get_cache_file_paths(file_path, original_file_name)
    safe_name = os.path.splitext(os.path.basename(json_path))[0]
    base_dir = "Eoverall_ocr_res"
    return os.path.join(base_dir, safe_name)


def load_cached_parse_result(file_path: str, original_file_name: Optional[str] = None) -> Optional[Dict[str, Any]]:
    """ä»ç¼“å­˜åŠ è½½è§£æç»“æœ
    
    é¦–å…ˆå°è¯•ä½¿ç”¨æ–°æ ¼å¼çš„ç¼“å­˜æ–‡ä»¶åï¼ˆåŸºäºåŸå§‹æ–‡ä»¶åï¼‰ï¼Œ
    å¦‚æœæ‰¾ä¸åˆ°ï¼Œåˆ™å°è¯•é€šè¿‡æ–‡ä»¶å†…å®¹åŒ¹é…æ¥æŸ¥æ‰¾æ—§æ ¼å¼çš„ç¼“å­˜ã€‚
    """
    import glob
    
    # é¦–å…ˆå°è¯•æ–°æ ¼å¼çš„ç¼“å­˜
    json_path, md_path = get_cache_file_paths(file_path, original_file_name)
    
    if os.path.exists(json_path) and os.path.exists(md_path):
        try:
            with open(json_path, "r", encoding="utf-8") as f:
                json_result = json.load(f)
            with open(md_path, "r", encoding="utf-8") as f:
                markdown_text = f.read()
            
            overall_dir = get_overall_image_dir(file_path, original_file_name)
            overall_imgs: List[str] = []
            if os.path.isdir(overall_dir):
                for fname in sorted(os.listdir(overall_dir)):
                    if fname.lower().endswith(".jpg"):
                        overall_imgs.append(os.path.join(overall_dir, fname))
            
            return {
                "json_result": json_result,
                "markdown_text": markdown_text,
                "raw_text": preview_file_content(file_path),
                "overall_image_paths": overall_imgs,
                "_cached": True,
            }
        except Exception as e:
            print(f"åŠ è½½æ–°æ ¼å¼ç¼“å­˜å¤±è´¥: {e}")
    
    # å¦‚æœæ–°æ ¼å¼ç¼“å­˜ä¸å­˜åœ¨ï¼Œå°è¯•æŸ¥æ‰¾æ—§æ ¼å¼çš„ç¼“å­˜
    # é€šè¿‡è¯»å–å½“å‰æ–‡ä»¶çš„å‰å‡ é¡µå†…å®¹ï¼Œä¸æ—§ç¼“å­˜æ–‡ä»¶çš„å†…å®¹è¿›è¡ŒåŒ¹é…
    try:
        # è¯»å–å½“å‰æ–‡ä»¶çš„å‰1000ä¸ªå­—ç¬¦ä½œä¸ºç‰¹å¾
        current_content = preview_file_content(file_path)
        if len(current_content) > 1000:
            current_content = current_content[:1000]
        
        # æ‰«ææ‰€æœ‰æ—§æ ¼å¼çš„JSONæ–‡ä»¶ï¼ˆä»¥tmpå¼€å¤´çš„ï¼‰
        jsons_dir = "jsons"
        mds_dir = "mds"
        if os.path.exists(jsons_dir) and os.path.exists(mds_dir):
            json_files = glob.glob(os.path.join(jsons_dir, "tmp*.json"))
            
            for old_json_file in json_files:
                try:
                    # è¯»å–æ—§ç¼“å­˜æ–‡ä»¶
                    with open(old_json_file, "r", encoding="utf-8") as f:
                        old_json_result = json.load(f)
                    
                    # è·å–æ—§ç¼“å­˜çš„ç¬¬ä¸€é¡µæ–‡æœ¬å†…å®¹
                    old_pages = old_json_result.get("pages", [])
                    if old_pages:
                        old_first_page_text = old_pages[0].get("text", "")
                        if len(old_first_page_text) > 1000:
                            old_first_page_text = old_first_page_text[:1000]
                        
                        # ç®€å•åŒ¹é…ï¼šæ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„ç›¸ä¼¼æ–‡æœ¬
                        # è¿™é‡Œä½¿ç”¨ç®€å•çš„åŒ…å«å…³ç³»ï¼Œæ›´å¤æ‚çš„åŒ¹é…å¯ä»¥ä½¿ç”¨ç›¸ä¼¼åº¦ç®—æ³•
                        common_chars = set(current_content) & set(old_first_page_text)
                        if len(common_chars) > 50:  # å¦‚æœå…±åŒå­—ç¬¦è¶…è¿‡50ä¸ªï¼Œè®¤ä¸ºå¯èƒ½æ˜¯åŒä¸€ä¸ªæ–‡ä»¶
                            # æ‰¾åˆ°å¯¹åº”çš„MDæ–‡ä»¶
                            old_md_file = os.path.join(mds_dir, os.path.basename(old_json_file).replace(".json", ".md"))
                            if os.path.exists(old_md_file):
                                with open(old_md_file, "r", encoding="utf-8") as f:
                                    old_markdown_text = f.read()
                                
                                print(f"é€šè¿‡å†…å®¹åŒ¹é…æ‰¾åˆ°æ—§æ ¼å¼ç¼“å­˜: {os.path.basename(old_json_file)}")
                                
                                # å¦‚æœæ‰¾åˆ°äº†åŒ¹é…çš„æ—§ç¼“å­˜ï¼Œå¯ä»¥å°è¯•è¿ç§»åˆ°æ–°æ ¼å¼
                                if original_file_name:
                                    try:
                                        new_json_path, new_md_path = get_cache_file_paths(file_path, original_file_name)
                                        # å¤åˆ¶åˆ°æ–°æ ¼å¼
                                        import shutil
                                        shutil.copy2(old_json_file, new_json_path)
                                        shutil.copy2(old_md_file, new_md_path)
                                        print(f"å·²è¿ç§»ç¼“å­˜æ–‡ä»¶åˆ°æ–°æ ¼å¼: {os.path.basename(new_json_path)}")
                                        
                                        # é‡æ–°åŠ è½½æ–°æ ¼å¼çš„ç¼“å­˜
                                        with open(new_json_path, "r", encoding="utf-8") as f:
                                            json_result = json.load(f)
                                        with open(new_md_path, "r", encoding="utf-8") as f:
                                            markdown_text = f.read()
                                        
                                        return {
                                            "json_result": json_result,
                                            "markdown_text": markdown_text,
                                            "raw_text": preview_file_content(file_path),
                                            "_cached": True,
                                        }
                                    except Exception as e:
                                        print(f"è¿ç§»ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}")
                                
                                # å¦‚æœè¿ç§»å¤±è´¥ï¼Œç›´æ¥è¿”å›æ—§æ ¼å¼çš„ç¼“å­˜
                                return {
                                    "json_result": old_json_result,
                                    "markdown_text": old_markdown_text,
                                    "raw_text": preview_file_content(file_path),
                                    "overall_image_paths": [],
                                    "_cached": True,
                                }
                except Exception as e:
                    print(f"æ£€æŸ¥æ—§ç¼“å­˜æ–‡ä»¶ {old_json_file} æ—¶å‡ºé”™: {e}")
                    continue
    except Exception as e:
        print(f"æŸ¥æ‰¾æ—§æ ¼å¼ç¼“å­˜æ—¶å‡ºé”™: {e}")
    
    return None


def save_parse_result(file_path: str, json_result: Dict[str, Any], markdown_text: str, original_file_name: Optional[str] = None):
    """ä¿å­˜è§£æç»“æœåˆ°ç¼“å­˜æ–‡ä»¶
    
    ä½¿ç”¨åŸå§‹æ–‡ä»¶åï¼ˆoriginal_file_nameï¼‰æ¥å‘½åç¼“å­˜æ–‡ä»¶ï¼Œä¾¿äºä¸PDFå¯¹åº”ã€‚
    å¦‚æœæ²¡æœ‰æä¾›åŸå§‹æ–‡ä»¶åï¼Œåˆ™ä½¿ç”¨æ–‡ä»¶è·¯å¾„ä¸­çš„æ–‡ä»¶åã€‚
    """
    json_path, md_path = get_cache_file_paths(file_path, original_file_name)
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs("jsons", exist_ok=True)
    os.makedirs("mds", exist_ok=True)
    
    try:
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(json_result, f, ensure_ascii=False, indent=2)
        with open(md_path, "w", encoding="utf-8") as f:
            f.write(markdown_text)
        print(f"å·²ä¿å­˜è§£æç»“æœ: {json_path}, {md_path}")
    except Exception as e:
        print(f"ä¿å­˜è§£æç»“æœå¤±è´¥: {e}")


def migrate_old_cache_files():
    """è¿ç§»æ—§çš„ç¼“å­˜æ–‡ä»¶åˆ°æ–°çš„å‘½åæ ¼å¼
    
    æ‰«æjsonså’Œmdsç›®å½•ï¼ŒæŸ¥æ‰¾ä½¿ç”¨æ—§å‘½åæ ¼å¼ï¼ˆä¸´æ—¶æ–‡ä»¶åï¼‰çš„ç¼“å­˜æ–‡ä»¶ï¼Œ
    å¦‚æœJSONæ–‡ä»¶ä¸­åŒ…å«åŸå§‹æ–‡ä»¶åä¿¡æ¯ï¼Œåˆ™å°è¯•é‡å‘½åã€‚
    æ³¨æ„ï¼šæ­¤å‡½æ•°éœ€è¦ç”¨æˆ·æ‰‹åŠ¨è°ƒç”¨ï¼Œæˆ–è€…å¯ä»¥åœ¨å¯åŠ¨æ—¶è‡ªåŠ¨æ‰§è¡Œä¸€æ¬¡ã€‚
    """
    import glob
    
    jsons_dir = "jsons"
    mds_dir = "mds"
    
    if not (os.path.exists(jsons_dir) and os.path.exists(mds_dir)):
        return
    
    # æŸ¥æ‰¾æ‰€æœ‰JSONæ–‡ä»¶
    json_files = glob.glob(os.path.join(jsons_dir, "*.json"))
    
    migrated_count = 0
    for json_file in json_files:
        try:
            # è¯»å–JSONæ–‡ä»¶
            with open(json_file, "r", encoding="utf-8") as f:
                json_data = json.load(f)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ—§æ ¼å¼ï¼ˆæ–‡ä»¶åä»¥tmpå¼€å¤´ï¼‰
            old_file_name = os.path.basename(json_file)
            if not old_file_name.startswith("tmp"):
                continue  # å·²ç»æ˜¯æ–°æ ¼å¼ï¼Œè·³è¿‡
            
            # å°è¯•ä»JSONä¸­è·å–åŸå§‹æ–‡ä»¶å
            # æ³¨æ„ï¼šæ—§æ ¼å¼çš„JSONä¸­file_nameå¯èƒ½æ˜¯ä¸´æ—¶æ–‡ä»¶åï¼Œæ— æ³•ç›´æ¥è·å–åŸå§‹æ–‡ä»¶å
            # è¿™é‡Œåªæ˜¯æä¾›ä¸€ä¸ªæ¡†æ¶ï¼Œå®é™…è¿ç§»å¯èƒ½éœ€è¦ç”¨æˆ·æ‰‹åŠ¨æŒ‡å®šæˆ–é€šè¿‡å…¶ä»–æ–¹å¼è¯†åˆ«
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„MDæ–‡ä»¶
            md_file = os.path.join(mds_dir, old_file_name.replace(".json", ".md"))
            if not os.path.exists(md_file):
                continue
            
            # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤šçš„è¯†åˆ«é€»è¾‘ï¼Œæ¯”å¦‚ï¼š
            # 1. ä»JSONå†…å®¹ä¸­æå–æ–‡æ¡£æ ‡é¢˜
            # 2. é€šè¿‡æ–‡ä»¶å†…å®¹åŒ¹é…æ¥è¯†åˆ«
            # 3. æˆ–è€…è®©ç”¨æˆ·æ‰‹åŠ¨æŒ‡å®š
            
            print(f"å‘ç°æ—§æ ¼å¼ç¼“å­˜æ–‡ä»¶: {old_file_name}ï¼Œéœ€è¦æ‰‹åŠ¨è¿ç§»")
            
        except Exception as e:
            print(f"å¤„ç†æ–‡ä»¶ {json_file} æ—¶å‡ºé”™: {e}")
            continue
    
    if migrated_count > 0:
        print(f"å·²è¿ç§» {migrated_count} ä¸ªç¼“å­˜æ–‡ä»¶")


def format_json_result_as_text(json_result: Dict[str, Any]) -> str:
    """ä»JSONä¸­æå–æ–‡å­—ã€ä½ç½®ã€æ’ç‰ˆç­‰ä¿¡æ¯å¹¶æ ¼å¼åŒ–ä¸ºå¯è¯»æ–‡æœ¬"""
    if not json_result:
        return "æš‚æ— JSONç»“æœ"
    
    lines = []
    
    # å¤„ç†æ–‡ä»¶åŸºæœ¬ä¿¡æ¯
    if "file_name" in json_result:
        lines.append(f"ğŸ“„ æ–‡ä»¶å: {json_result.get('file_name', 'N/A')}")
        lines.append(f"ğŸ†” æ–‡ä»¶ID: {json_result.get('file_id', 'N/A')}")
        lines.append("")
    
    # å¤„ç†é¡µé¢ä¿¡æ¯
    pages = json_result.get("pages", [])
    if pages:
        lines.append(f"ğŸ“‘ å…± {len(pages)} é¡µ")
        lines.append("=" * 80)
        lines.append("")
        
        for page_idx, page in enumerate(pages):
            page_num = page.get("page_num", page_idx)
            page_id = page.get("page_id", f"page-{page_idx}")
            
            lines.append(f"ğŸ“„ ç¬¬ {page_num + 1} é¡µ (page_id: {page_id})")
            lines.append("-" * 80)
            
            # é¡µé¢å…ƒä¿¡æ¯
            meta = page.get("meta", {})
            if meta:
                page_width = meta.get("page_width", 0)
                page_height = meta.get("page_height", 0)
                lines.append(f"ğŸ“ é¡µé¢å°ºå¯¸: {page_width} Ã— {page_height} åƒç´  | é¡µé¢ç±»å‹: {meta.get('page_type', 'N/A')}")
                lines.append("")
            
            # ä¼˜å…ˆæ˜¾ç¤ºé¡µé¢å®Œæ•´æ–‡æœ¬å†…å®¹
            page_text = page.get("text", "").strip()
            if page_text:
                lines.append("ã€è¯†åˆ«æ–‡æœ¬å†…å®¹ã€‘")
                lines.append("-" * 80)
                lines.append(page_text)
                lines.append("")
                lines.append("-" * 80)
                lines.append("")
            
            # å¤„ç†å¸ƒå±€ä¿¡æ¯ï¼ˆlayoutsï¼‰- æŒ‰é¡ºåºå±•ç¤ºï¼ŒåŒ…å«ä½ç½®å’Œæ’ç‰ˆä¿¡æ¯
            layouts = page.get("layouts", [])
            if layouts:
                lines.append(f"ã€å¸ƒå±€ç»“æ„ä¿¡æ¯ã€‘å…± {len(layouts)} ä¸ªå¸ƒå±€å…ƒç´ ")
                lines.append("")
                
                # æŒ‰å±‚çº§ç»„ç»‡å¸ƒå±€ï¼ˆå…ˆæ˜¾ç¤ºæ ¹èŠ‚ç‚¹ï¼Œå†æ˜¾ç¤ºå­èŠ‚ç‚¹ï¼‰
                layout_dict = {layout.get("layout_id"): layout for layout in layouts}
                root_layouts = [layout for layout in layouts if layout.get("parent") == "root"]
                
                def format_layout_with_text(layout, indent_level=0):
                    """æ ¼å¼åŒ–å•ä¸ªå¸ƒå±€å…ƒç´ ï¼Œçªå‡ºæ˜¾ç¤ºæ–‡æœ¬å’Œä½ç½®ä¿¡æ¯"""
                    indent = "  " * indent_level
                    layout_id = layout.get("layout_id", "N/A")
                    layout_type = layout.get("type", "N/A")
                    sub_type = layout.get("sub_type", "")
                    text = layout.get("text", "").strip()
                    position = layout.get("position", [])
                    
                    # æ ¼å¼åŒ–ä½ç½®ä¿¡æ¯ï¼Œå¹¶åˆ¤æ–­æ–‡æœ¬æ–¹å‘
                    direction_hint = ""
                    if position and len(position) >= 4:
                        x, y, w, h = position[0], position[1], position[2], position[3]
                        # æ ¹æ®å®½é«˜æ¯”åˆ¤æ–­æ–‡æœ¬æ–¹å‘
                        if w > 0 and h > 0:
                            aspect_ratio = w / h
                            if aspect_ratio > 2.0:  # å®½åº¦æ˜æ˜¾å¤§äºé«˜åº¦ï¼Œæ°´å¹³æ–‡æœ¬
                                direction_hint = " [æ°´å¹³]"
                            elif aspect_ratio < 0.5:  # é«˜åº¦æ˜æ˜¾å¤§äºå®½åº¦ï¼Œå‚ç›´æ–‡æœ¬
                                direction_hint = " [å‚ç›´]"
                        pos_str = f"[ä½ç½®: ({x}, {y}) å°ºå¯¸: {w}Ã—{h}{direction_hint}]"
                    else:
                        pos_str = "[ä½ç½®: N/A]"
                    
                    # ç±»å‹æ ‡ç­¾
                    type_label = f"{layout_type}"
                    if sub_type:
                        type_label += f"/{sub_type}"
                    
                    # æ„å»ºæ˜¾ç¤ºå†…å®¹ - ä¼˜å…ˆæ˜¾ç¤ºæ–‡æœ¬å†…å®¹
                    result = []
                    if text:
                        # æ ¹æ®ä½ç½®å°ºå¯¸åˆ¤æ–­æ–‡æœ¬æ–¹å‘ï¼Œå†³å®šå¦‚ä½•æ˜¾ç¤ºæ–‡æœ¬
                        text_to_display = text
                        if position and len(position) >= 4:
                            x, y, w, h = position[0], position[1], position[2], position[3]
                            if w > 0 and h > 0:
                                aspect_ratio = w / h
                                text_lines = text.split("\n")
                                # æ£€æŸ¥æ˜¯å¦æ˜¯æ¯è¡Œä¸€ä¸ªå­—ç¬¦çš„å‚ç›´æ’åˆ—ï¼ˆå¯èƒ½æ˜¯æ°´å¹³æ–‡æœ¬è¢«é”™è¯¯åˆ†å‰²ï¼‰
                                is_single_char_per_line = all(len(line.strip()) == 1 for line in text_lines if line.strip())
                                
                                # å¦‚æœå®½åº¦å¤§äºé«˜åº¦ï¼Œä¸”æ–‡æœ¬æ˜¯æ¯è¡Œä¸€ä¸ªå­—ç¬¦ï¼Œè¯´æ˜æ˜¯æ°´å¹³æ–‡æœ¬è¢«é”™è¯¯åˆ†å‰²
                                # åº”è¯¥åˆå¹¶ä¸ºä¸€è¡Œæ˜¾ç¤º
                                if aspect_ratio > 1.2 and is_single_char_per_line:
                                    # åˆå¹¶ä¸ºæ°´å¹³æ–‡æœ¬
                                    text_to_display = "".join(line.strip() for line in text_lines if line.strip())
                                    result.append(f"{indent}ã€{type_label}ã€‘{pos_str}")
                                    result.append(f"{indent}  æ–‡æœ¬ï¼ˆæ°´å¹³ï¼‰: {text_to_display}")
                                elif aspect_ratio < 0.8:
                                    # é«˜åº¦å¤§äºå®½åº¦ï¼Œå¯èƒ½æ˜¯å‚ç›´æ–‡æœ¬
                                    result.append(f"{indent}ã€{type_label}ã€‘{pos_str}")
                                    result.append(f"{indent}  æ–‡æœ¬ï¼ˆå‚ç›´æ’åˆ—ï¼‰:")
                                    for line in text_lines:
                                        if line.strip():
                                            result.append(f"{indent}    {line}")
                                else:
                                    # å…¶ä»–æƒ…å†µï¼ŒæŒ‰åŸå§‹æ ¼å¼æ˜¾ç¤º
                                    if len(text_lines) == 1:
                                        result.append(f"{indent}ã€{type_label}ã€‘{pos_str}")
                                        result.append(f"{indent}  æ–‡æœ¬: {text_to_display}")
                                    else:
                                        result.append(f"{indent}ã€{type_label}ã€‘{pos_str}")
                                        result.append(f"{indent}  æ–‡æœ¬:")
                                        for line in text_lines:
                                            if line.strip():
                                                result.append(f"{indent}    {line}")
                            else:
                                # æ²¡æœ‰æœ‰æ•ˆçš„å°ºå¯¸ä¿¡æ¯ï¼ŒæŒ‰åŸå§‹æ ¼å¼æ˜¾ç¤º
                                text_lines = text_to_display.split("\n")
                                if len(text_lines) == 1:
                                    result.append(f"{indent}ã€{type_label}ã€‘{pos_str}")
                                    result.append(f"{indent}  æ–‡æœ¬: {text_to_display}")
                                else:
                                    result.append(f"{indent}ã€{type_label}ã€‘{pos_str}")
                                    result.append(f"{indent}  æ–‡æœ¬:")
                                    for line in text_lines:
                                        if line.strip():
                                            result.append(f"{indent}    {line}")
                        else:
                            # æ²¡æœ‰ä½ç½®ä¿¡æ¯ï¼ŒæŒ‰åŸå§‹æ ¼å¼æ˜¾ç¤º
                            text_lines = text_to_display.split("\n")
                            if len(text_lines) == 1:
                                result.append(f"{indent}ã€{type_label}ã€‘{pos_str}")
                                result.append(f"{indent}  æ–‡æœ¬: {text_to_display}")
                            else:
                                result.append(f"{indent}ã€{type_label}ã€‘{pos_str}")
                                result.append(f"{indent}  æ–‡æœ¬:")
                                for line in text_lines:
                                    if line.strip():
                                        result.append(f"{indent}    {line}")
                    else:
                        result.append(f"{indent}ã€{type_label}ã€‘{layout_id} {pos_str}")
                    
                    return result
                
                # é€’å½’å¤„ç†å¸ƒå±€æ ‘ï¼ŒæŒ‰é¡ºåºå±•ç¤º
                def process_layout_tree_ordered(layout, indent_level=0, processed=None):
                    """é€’å½’å¤„ç†å¸ƒå±€æ ‘ç»“æ„ï¼ŒæŒ‰é¡ºåºå±•ç¤ºæ–‡æœ¬å†…å®¹"""
                    if processed is None:
                        processed = set()
                    
                    layout_id = layout.get("layout_id")
                    if layout_id in processed:
                        return []
                    
                    processed.add(layout_id)
                    result = format_layout_with_text(layout, indent_level)
                    
                    # å¤„ç†å­èŠ‚ç‚¹
                    children_ids = layout.get("children", [])
                    if children_ids:
                        for child_id in children_ids:
                            if child_id in layout_dict:
                                child_layout = layout_dict[child_id]
                                child_result = process_layout_tree_ordered(child_layout, indent_level + 1, processed)
                                result.extend(child_result)
                    
                    return result
                
                # å¤„ç†æ‰€æœ‰æ ¹å¸ƒå±€ï¼ˆparentä¸º"root"çš„å¸ƒå±€ï¼‰
                processed_ids = set()
                for root_layout in root_layouts:
                    layout_lines = process_layout_tree_ordered(root_layout, indent_level=0, processed=processed_ids)
                    lines.extend(layout_lines)
                    lines.append("")
                
                # æ˜¾ç¤ºæœªå¤„ç†çš„å¸ƒå±€ï¼ˆparentä¸æ˜¯"root"ä¸”ä¸åœ¨ä»»ä½•childrenä¸­çš„å¸ƒå±€ï¼‰
                orphan_layouts = [layout for layout in layouts 
                                 if layout.get("layout_id") not in processed_ids]
                if orphan_layouts:
                    lines.append("ã€å…¶ä»–å¸ƒå±€å…ƒç´ ã€‘")
                    for orphan in orphan_layouts:
                        layout_lines = format_layout_with_text(orphan, indent_level=0)
                        lines.extend(layout_lines)
                        lines.append("")
            
            # å¤„ç†è¡¨æ ¼
            tables = page.get("tables", [])
            if tables:
                lines.append(f"ã€è¡¨æ ¼ä¿¡æ¯ã€‘å…± {len(tables)} ä¸ªè¡¨æ ¼")
                for i, table in enumerate(tables):
                    lines.append(f"  è¡¨æ ¼ {i+1}: ID={table.get('table_id', 'N/A')}")
                    if "position" in table:
                        pos = table["position"]
                        if len(pos) >= 4:
                            lines.append(f"    ä½ç½®: ({pos[0]}, {pos[1]}) å°ºå¯¸: {pos[2]}Ã—{pos[3]}")
                lines.append("")
            
            # å¤„ç†å›¾ç‰‡
            images = page.get("images", [])
            if images:
                lines.append(f"ã€å›¾ç‰‡ä¿¡æ¯ã€‘å…± {len(images)} ä¸ªå›¾ç‰‡")
                for i, image in enumerate(images):
                    lines.append(f"  å›¾ç‰‡ {i+1}: ID={image.get('image_id', 'N/A')}")
                    if "position" in image:
                        pos = image["position"]
                        if len(pos) >= 4:
                            lines.append(f"    ä½ç½®: ({pos[0]}, {pos[1]}) å°ºå¯¸: {pos[2]}Ã—{pos[3]}")
                lines.append("")
            
            lines.append("")
            lines.append("=" * 80)
            lines.append("")
    
    return "\n".join(lines)


def call_online_parse_api(file_path: str) -> Optional[Dict[str, Any]]:
    """è°ƒç”¨å¸ƒå±€è§£æåœ¨çº¿APIï¼ˆåŸºäºtest_ppsv3.pyï¼‰ï¼Œå¹¶è¿”å›markdownã€åŸå§‹JSONä¸æ•´ä½“OCRå›¾è·¯å¾„ã€‚"""
    # å…ˆæ£€æŸ¥ç¼“å­˜ï¼ˆä½¿ç”¨åŸå§‹æ–‡ä»¶åï¼‰
    original_file_name = st.session_state.get("file_name")
    cached_result = load_cached_parse_result(file_path, original_file_name)
    if cached_result:
        print(f"ä»ç¼“å­˜åŠ è½½è§£æç»“æœ: {file_path}")
        # å…¼å®¹ï¼šå°è¯•è¡¥å……å·²ä¸‹è½½çš„overallå›¾ç‰‡åˆ—è¡¨ï¼ˆè‹¥å­˜åœ¨ï¼‰
        overall_dir = get_overall_image_dir(file_path, original_file_name)
        overall_imgs = []
        if os.path.isdir(overall_dir):
            for fname in sorted(os.listdir(overall_dir)):
                if fname.lower().endswith(".jpg"):
                    overall_imgs.append(os.path.join(overall_dir, fname))
        cached_result["overall_image_paths"] = overall_imgs
        return cached_result
    
    try:
        # ä¸ test_ppsv3.py å¯¹é½çš„API
        API_URL = "https://uft8mbk5g3ndv3m1.aistudio-app.com/layout-parsing"
        TOKEN = "6f83207f504098cd644f75618f9ed9507a5dfa7b"

        with open(file_path, "rb") as file:
            file_bytes = file.read()
            file_data = base64.b64encode(file_bytes).decode("ascii")

        headers = {"Authorization": f"token {TOKEN}", "Content-Type": "application/json"}
        payload = {
            "file": file_data,
            "fileType": 0,
            "useDocOrientationClassify": False,
            "useDocUnwarping": False,
            "useTextlineOrientation": False,
            "useChartRecognition": False,
        }

        # è¯·æ±‚æ¥å£
        resp = requests.post(API_URL, json=payload, headers=headers, timeout=120)
        if resp.status_code != 200:
            st.error(f"åœ¨çº¿è§£æå¤±è´¥ï¼ŒçŠ¶æ€ç : {resp.status_code}")
            return None
        api_json = resp.json()
        result = api_json.get("result", {})

        # ç»„ç»‡markdownï¼šæŠŠå„partçš„markdownæ‹¼æ¥ä¸ºä¸€ä¸ªæ–‡æ¡£
        layout_results = result.get("layoutParsingResults", []) or []
        merged_markdown_parts: List[str] = []
        overall_image_paths: List[str] = []

        # ä»…ä¿ç•™ overall_ocr_res å›¾ç‰‡ï¼Œä¿å­˜åˆ°æŒ‡å®šç›®å½•å¹¶æŒ‰æ–‡ä»¶ååŒºåˆ†
        overall_dir = get_overall_image_dir(file_path, original_file_name)
        os.makedirs(overall_dir, exist_ok=True)
        # æ¸…ç†æ—§å›¾ç‰‡
        for fname in os.listdir(overall_dir):
            if fname.lower().endswith(".jpg"):
                try:
                    os.remove(os.path.join(overall_dir, fname))
                except OSError:
                    pass

        for i, res in enumerate(layout_results):
            md_text = ((res.get("markdown") or {}).get("text")) or ""
            if md_text:
                merged_markdown_parts.append(md_text)

            # ä¸‹è½½ overall_ocr_res
            output_images = res.get("outputImages") or {}
            for img_name, img_url in output_images.items():
                if not isinstance(img_url, str):
                    continue
                if "overall_ocr_res" not in img_name.lower():
                    continue
                try:
                    img_response = requests.get(img_url, timeout=120)
                    if img_response.status_code == 200:
                        filename = os.path.join(overall_dir, f"{img_name}_{i}.jpg")
                        with open(filename, "wb") as f:
                            f.write(img_response.content)
                        overall_image_paths.append(filename)
                except Exception as _:
                    continue

        markdown_text = "\n\n---\n\n".join(merged_markdown_parts) if merged_markdown_parts else ""
        json_result = result  # åŸæ ¼å¼JSON

        # ç¼“å­˜ï¼šä»…ä¿å­˜ md ä¸ åŸæ ¼å¼ json
        if json_result and markdown_text:
            save_parse_result(file_path, json_result, markdown_text, original_file_name)

        result_payload = {
            "json_result": json_result,
            "markdown_text": markdown_text,
            "overall_image_paths": overall_image_paths,
            "raw_text": preview_file_content(file_path),
        }

        return result_payload
    except Exception as e:
        st.error(f"è°ƒç”¨åœ¨çº¿è§£æAPIå¤±è´¥: {e}")
        return None


def add_highlights_to_text(text: str, issues: List[Dict]) -> str:
    """ä¸ºæ–‡æœ¬æ·»åŠ ç®€å•æ ‡è®° - æ‰€æœ‰é—®é¢˜éƒ½æ ‡è®°æ˜¾ç¤º"""
    if not issues:
        return text

    highlighted_text = text
    for issue in issues:
        clause = issue.get("æ¡æ¬¾", "")
        risk_level = issue.get("é£é™©ç­‰çº§", "ä½")
        issue_type = issue.get("ç±»å‹", "é—®é¢˜")

        if clause and clause in highlighted_text:
            # æ ¹æ®é£é™©ç­‰çº§é€‰æ‹©æ ‡è®°ç¬¦å·
            if risk_level == "é«˜":
                marker = "ğŸ”´ã€é‡å¤§é£é™©ã€‘"
            elif risk_level == "ä¸­":
                marker = "ğŸŸ¡ã€ä¸€èˆ¬é£é™©ã€‘"
            else:
                marker = "ğŸŸ¢ã€ä½é£é™©ã€‘"

            # æ·»åŠ ç®€å•æ ‡è®°
            marked_text = f"{marker} {clause}"
            highlighted_text = highlighted_text.replace(clause, marked_text)

    return highlighted_text


def filter_issues_by_risk(issues: List[Dict], risk_level: str) -> List[Dict]:
    """æ ¹æ®é£é™©ç­‰çº§ç­›é€‰é—®é¢˜"""
    if risk_level == "å…¨éƒ¨":
        return issues

    level_mapping = {"é‡å¤§é£é™©": "é«˜", "ä¸€èˆ¬é£é™©": "ä¸­", "ä½é£é™©": "ä½"}

    target_level = level_mapping.get(risk_level, "ä½")
    return [issue for issue in issues if issue.get("é£é™©ç­‰çº§") == target_level]


def render_risk_analysis(risk_analysis: Dict[str, Any]):
    """æ¸²æŸ“é£é™©åˆ†æç»“æœ"""
    st.markdown("### ğŸ” é£é™©åˆ†æç»“æœ")

    statistics = risk_analysis.get("statistics", {})
    all_issues = risk_analysis.get("all_issues", [])

    # é£é™©ç»Ÿè®¡
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("æ€»é—®é¢˜æ•°", statistics.get("total_issues", 0))
    with col2:
        st.metric("é«˜é£é™©", statistics.get("by_level", {}).get("é«˜", 0))
    with col3:
        st.metric("ä¸­é£é™©", statistics.get("by_level", {}).get("ä¸­", 0))
    with col4:
        st.metric("ä½é£é™©", statistics.get("by_level", {}).get("ä½", 0))

    # é£é™©è¯„åˆ†
    risk_score = statistics.get("risk_score", 0)
    risk_level = statistics.get("risk_level", "ä½")

    st.markdown("### ğŸ“Š é£é™©è¯„åˆ†")
    col1, col2 = st.columns(2)
    with col1:
        st.metric("é£é™©è¯„åˆ†", f"{risk_score}/100")
    with col2:
        level_color = {"é«˜": "ğŸ”´", "ä¸­": "ğŸŸ¡", "ä½": "ğŸŸ¢"}.get(risk_level, "âšª")
        st.metric("é£é™©ç­‰çº§", f"{level_color} {risk_level}")

    # é—®é¢˜è¯¦æƒ…
    if all_issues:
        st.markdown("### ğŸ“‹ é—®é¢˜è¯¦æƒ…")

        # æŒ‰é£é™©ç­‰çº§åˆ†ç±»
        high_risk_issues = [
            issue for issue in all_issues if issue.get("é£é™©ç­‰çº§") == "é«˜"
        ]
        medium_risk_issues = [
            issue for issue in all_issues if issue.get("é£é™©ç­‰çº§") == "ä¸­"
        ]
        low_risk_issues = [
            issue for issue in all_issues if issue.get("é£é™©ç­‰çº§") == "ä½"
        ]

        # æ˜¾ç¤ºé«˜é£é™©é—®é¢˜
        if high_risk_issues:
            st.markdown("#### ğŸ”´ é«˜é£é™©é—®é¢˜")
            for i, issue in enumerate(high_risk_issues, 1):
                with st.expander(
                    f"{i}. {issue.get('ç±»å‹', 'æœªçŸ¥ç±»å‹')} - {issue.get('æ¡æ¬¾', 'N/A')[:50]}...",
                    expanded=True,
                ):
                    st.write(f"**é—®é¢˜æè¿°:** {issue.get('é—®é¢˜æè¿°', 'N/A')}")
                    st.write(f"**ä¿®æ”¹å»ºè®®:** {issue.get('ä¿®æ”¹å»ºè®®', 'N/A')}")
                    if issue.get("æ³•å¾‹ä¾æ®"):
                        st.write(f"**æ³•å¾‹ä¾æ®:** {issue['æ³•å¾‹ä¾æ®']}")
                    if issue.get("å½±å“åˆ†æ"):
                        st.write(f"**å½±å“åˆ†æ:** {issue['å½±å“åˆ†æ']}")

        # æ˜¾ç¤ºä¸­é£é™©é—®é¢˜
        if medium_risk_issues:
            st.markdown("#### ğŸŸ¡ ä¸­é£é™©é—®é¢˜")
            for i, issue in enumerate(medium_risk_issues, 1):
                with st.expander(
                    f"{i}. {issue.get('ç±»å‹', 'æœªçŸ¥ç±»å‹')} - {issue.get('æ¡æ¬¾', 'N/A')[:50]}...",
                    expanded=False,
                ):
                    st.write(f"**é—®é¢˜æè¿°:** {issue.get('é—®é¢˜æè¿°', 'N/A')}")
                    st.write(f"**ä¿®æ”¹å»ºè®®:** {issue.get('ä¿®æ”¹å»ºè®®', 'N/A')}")
                    if issue.get("å½±å“åˆ†æ"):
                        st.write(f"**å½±å“åˆ†æ:** {issue['å½±å“åˆ†æ']}")

        # æ˜¾ç¤ºä½é£é™©é—®é¢˜
        if low_risk_issues:
            st.markdown("#### ğŸŸ¢ ä½é£é™©é—®é¢˜")
            for i, issue in enumerate(low_risk_issues, 1):
                with st.expander(
                    f"{i}. {issue.get('ç±»å‹', 'æœªçŸ¥ç±»å‹')} - {issue.get('æ¡æ¬¾', 'N/A')[:50]}...",
                    expanded=False,
                ):
                    st.write(f"**é—®é¢˜æè¿°:** {issue.get('é—®é¢˜æè¿°', 'N/A')}")
                    st.write(f"**ä¿®æ”¹å»ºè®®:** {issue.get('ä¿®æ”¹å»ºè®®', 'N/A')}")
    else:
        st.info("æœªå‘ç°é—®é¢˜")


def render_suggestions(suggestions: Dict[str, Any]):
    """æ¸²æŸ“å»ºè®®å’Œæ¨è"""
    st.markdown("### ğŸ’¡ ç»¼åˆå»ºè®®")

    summary = suggestions.get("summary", {})
    analysis = suggestions.get("analysis", {})
    recommendation = suggestions.get("recommendation", {})

    # æ‘˜è¦ä¿¡æ¯
    st.markdown("#### ğŸ“Š åˆ†ææ‘˜è¦")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("é£é™©è¯„åˆ†", f"{summary.get('risk_score', 0)}/100")
    with col2:
        st.metric("æ€»é—®é¢˜æ•°", summary.get("total_issues", 0))
    with col3:
        st.metric("è¿æ³•æ¡æ¬¾", summary.get("illegal_clauses", 0))

    # ä¸»è¦é£é™©ç‚¹
    if analysis.get("key_risks"):
        st.markdown("#### ğŸ”´ ä¸»è¦é£é™©ç‚¹")
        for risk in analysis["key_risks"]:
            st.write(f"â€¢ {risk}")

    # å½±å“åˆ†æ
    if analysis.get("impact_analysis"):
        st.markdown("#### ğŸ“ˆ å½±å“åˆ†æ")
        st.write(analysis["impact_analysis"])

    # ä¼˜åŒ–å»ºè®®
    if analysis.get("optimization_suggestions"):
        st.markdown("#### ğŸ› ï¸ ä¼˜åŒ–å»ºè®®")
        for suggestion in analysis["optimization_suggestions"]:
            st.write(f"â€¢ {suggestion}")

    # ç­¾çº¦å»ºè®®
    if recommendation.get("signing_advice"):
        st.markdown("#### ğŸ“ ç­¾çº¦å»ºè®®")
        signing_advice = recommendation["signing_advice"]
        if "ä¸å»ºè®®" in signing_advice or "âŒ" in signing_advice:
            st.error(f"**{signing_advice}**")
        elif "è°¨æ…" in signing_advice or "âš ï¸" in signing_advice:
            st.warning(f"**{signing_advice}**")
        elif "å¯ä»¥" in signing_advice or "âœ…" in signing_advice:
            st.success(f"**{signing_advice}**")
        else:
            st.info(f"**{signing_advice}**")

    # è°ˆåˆ¤è¦ç‚¹
    if recommendation.get("negotiation_points"):
        st.markdown("#### ğŸ¤ è°ˆåˆ¤è¦ç‚¹")
        for point in recommendation["negotiation_points"]:
            st.write(f"â€¢ {point}")

    # é£é™©ç¼“è§£æªæ–½
    if recommendation.get("risk_mitigation"):
        st.markdown("#### ğŸ›¡ï¸ é£é™©ç¼“è§£æªæ–½")
        for measure in recommendation["risk_mitigation"]:
            st.write(f"â€¢ {measure}")


def process_contract_workflow(file_path: str):
    """å¤„ç†åˆåŒå·¥ä½œæµ"""
    try:
        st.session_state.processing_status = "processing"

        # åˆ›å»ºå·¥ä½œæµå®ä¾‹
        workflow = ContractWorkflow()

        # æ­¥éª¤1: æ–‡æ¡£è§£æ/åˆ†æ
        with st.spinner("æ­£åœ¨è§£ææ–‡æ¡£å¹¶åˆ†æ..."):
            result = workflow.process_contract(
                file_path, original_file_name=st.session_state.file_name
            )

        if "error" in result:
            st.session_state.processing_status = "error"
            st.error(f"å¤„ç†å¤±è´¥: {result['error']}")
            return

        st.session_state.workflow_result = result
        st.session_state.processing_status = "completed"
        st.session_state.view_mode = "analysis"

        st.success("åˆåŒåˆ†æå®Œæˆï¼")

    except Exception as e:
        st.session_state.processing_status = "error"
        st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")


def main():
    """ä¸»å‡½æ•°"""
    initialize_session_state()

    # é¡µé¢æ ‡é¢˜
    st.title("ğŸ“„ åˆåŒå®¡æŸ¥ç³»ç»Ÿ")

    # ä¾§è¾¹æ  - æ–‡ä»¶ä¸Šä¼ 
    with st.sidebar:
        st.markdown("### ğŸ“ æ–‡ä»¶é€‰æ‹©")

        # åˆ›å»ºé€‰é¡¹å¡
        tab1, tab2 = st.tabs(["ğŸ“¤ ä¸Šä¼ æ–‡ä»¶", "ğŸ“‹ é€‰æ‹©æ ·ä¾‹"])

        with tab1:
            uploaded_file = st.file_uploader(
                "ä¸Šä¼ åˆåŒæ–‡ä»¶",
                type=["pdf", "docx", "txt", "doc"],
                help="æ”¯æŒPDFã€DOCXã€TXTã€DOCæ ¼å¼",
            )

            if uploaded_file:
                saved_path = save_uploaded_file(uploaded_file)
                if saved_path:
                    # åˆ‡æ¢æ–‡ä»¶æ—¶æ¸…ç©ºå†å²åˆ†æçŠ¶æ€ï¼Œå›åˆ°é¢„è§ˆæ€
                    st.session_state.workflow_result = None
                    st.session_state.processing_status = "idle"
                    st.session_state.loaded_from_history = False
                    st.session_state.view_mode = "preview"
                    # ä¸æ¸…ç©ºOCRè§£æç»“æœï¼Œè®©render_preview_panelè‡ªåŠ¨æ£€æŸ¥å¹¶åŠ è½½ç¼“å­˜
                    # å¦‚æœæ–°æ–‡ä»¶æœ‰ç¼“å­˜ä¼šè‡ªåŠ¨åŠ è½½ï¼Œæ²¡æœ‰ç¼“å­˜ä¼šè‡ªåŠ¨æ¸…ç©º

                    st.session_state.saved_file_path = saved_path
                    st.session_state.file_name = uploaded_file.name
                    st.session_state.preview_content = preview_file_content(saved_path)

        with tab2:
            sample_files = get_sample_files()
            if sample_files:
                st.write("é€‰æ‹©æ ·ä¾‹æ–‡ä»¶ï¼š")
                for i, sample_path in enumerate(sample_files):
                    file_name = os.path.basename(sample_path)
                    if st.button(f"ğŸ“„ {file_name}", key=f"sample_{i}"):
                        temp_path = copy_sample_file(sample_path)
                        if temp_path:
                            # åˆ‡æ¢æ ·ä¾‹æ—¶æ¸…ç©ºå†å²åˆ†æçŠ¶æ€ï¼Œå›åˆ°é¢„è§ˆæ€
                            st.session_state.workflow_result = None
                            st.session_state.processing_status = "idle"
                            st.session_state.loaded_from_history = False
                            st.session_state.view_mode = "preview"
                            # ä¸æ¸…ç©ºOCRè§£æç»“æœï¼Œè®©render_preview_panelè‡ªåŠ¨æ£€æŸ¥å¹¶åŠ è½½ç¼“å­˜
                            # å¦‚æœæ–°æ–‡ä»¶æœ‰ç¼“å­˜ä¼šè‡ªåŠ¨åŠ è½½ï¼Œæ²¡æœ‰ç¼“å­˜ä¼šè‡ªåŠ¨æ¸…ç©º

                            st.session_state.saved_file_path = temp_path
                            st.session_state.file_name = file_name
                            st.session_state.preview_content = preview_file_content(
                                temp_path
                            )
                            st.success(f"å·²é€‰æ‹©: {file_name}")
                            st.rerun()
            else:
                st.info("contractsç›®å½•ä¸‹æ²¡æœ‰æ ·ä¾‹æ–‡ä»¶")

    # ä¸»ç•Œé¢
    if (
        hasattr(st.session_state, "saved_file_path")
        and st.session_state.saved_file_path
    ):

        # æ–‡ä»¶ä¿¡æ¯
        st.markdown("### ğŸ“„ å½“å‰æ–‡ä»¶")
        col1, col2 = st.columns([3, 1])
        with col1:
            st.write(f"**æ–‡ä»¶å:** {st.session_state.file_name}")
        with col2:
            # é¡¶éƒ¨å³ä¾§ä¸å†å—çŠ¶æ€é™åˆ¶ï¼ŒæŒ‰é’®ä½ç½®å°†ä¸‹ç§»åˆ°è‡ªåŠ¨åŠ è½½é€»è¾‘ä¹‹å
            pass

        # è‹¥é€‰æ‹©äº†æ–‡ä»¶ï¼Œå°è¯•è‡ªåŠ¨åŠ è½½å†å²æœ€æ–°åˆ†æç»“æœ
        if (
            st.session_state.processing_status == "idle"
            and st.session_state.file_name
            and not st.session_state.loaded_from_history
        ):
            cached = load_latest_result_by_filename(st.session_state.file_name)
            if cached:
                st.session_state.workflow_result = cached
                st.session_state.processing_status = "completed"
                st.session_state.loaded_from_history = True
                st.session_state.view_mode = "analysis"
                st.success("å·²åŠ è½½å†å²æœ€æ–°åˆ†æç»“æœ")

        # æ“ä½œæŒ‰é’®ï¼šidle æ˜¾ç¤ºâ€œå¼€å§‹åˆ†æâ€ï¼›completed æ˜¾ç¤ºâ€œé‡æ–°æäº¤æ¨¡å‹åˆ†æâ€
        if st.session_state.processing_status in ("idle", "completed"):
            if st.session_state.processing_status == "completed":
                label = "ğŸ” é‡æ–°æäº¤æ¨¡å‹åˆ†æ"
            else:
                label = "ğŸš€ å¼€å§‹åˆ†æ"
            if st.button(label, type="primary", width='stretch'):
                process_contract_workflow(st.session_state.saved_file_path)
                st.rerun()

        # æ˜¾ç¤ºå¤„ç†çŠ¶æ€
        if st.session_state.processing_status == "processing":
            st.info("æ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨å€™...")

        # æ˜¾ç¤ºåˆ†æç»“æœ
        if (
            st.session_state.processing_status == "completed"
            and st.session_state.workflow_result
            and st.session_state.get("view_mode") == "analysis"
        ):
            result = st.session_state.workflow_result
            risk_analysis = result.get("risk_analysis", {})
            all_issues = risk_analysis.get("all_issues", [])

            # åˆ›å»ºå·¦å³åˆ†æ å¸ƒå±€
            col1, col2 = st.columns([1, 1], gap="large")

            with col1:
                # å·¦ä¾§ï¼šåˆåŒå†…å®¹åŒºåŸŸ
                st.markdown("### ğŸ“„ åˆåŒæ–‡æ¡£")

                # åˆåŒæ ‡é¢˜ï¼ˆç§»é™¤é‡å¤æŒ‰é’®ï¼Œä»…å±•ç¤ºæ–‡ä»¶åï¼‰
                st.markdown(f"**{st.session_state.file_name}**")

                # æ˜¾ç¤ºåˆåŒå†…å®¹ï¼ˆå¸¦é«˜äº®ï¼‰
                document_text = result.get("document_text", "")
                if document_text:
                    # ä¸ºé—®é¢˜æ·»åŠ é«˜äº®æ ‡è®°
                    highlighted_text = add_highlights_to_text(document_text, all_issues)

                    # æ˜¾ç¤ºæ ‡è®°åçš„æ–‡æœ¬
                    st.markdown("### ğŸ“„ åˆåŒå†…å®¹ï¼ˆå·²æ ‡è®°é—®é¢˜ï¼‰")
                    st.text_area(
                        "åˆåŒå†…å®¹ï¼ˆå·²æ ‡è®°ï¼‰",
                        value=highlighted_text,
                        height=800,
                        disabled=True,
                        label_visibility="collapsed",
                    )
                else:
                    st.warning("æœªè·å–åˆ°æ–‡æ¡£å†…å®¹")

            with col2:
                # å³ä¾§ï¼šé£é™©åˆ†æåŒºåŸŸ
                st.markdown("### ğŸ” å®¡æŸ¥ç»“æœ")

                # è§†å›¾åˆ‡æ¢ï¼šé£é™©ç‚¹ / ç»¼åˆå»ºè®®
                view = st.radio(
                    "é€‰æ‹©æŸ¥çœ‹å†…å®¹",
                    ["é£é™©ç‚¹", "ç»¼åˆå»ºè®®"],
                    horizontal=True,
                    key="result_view_switch",
                )

                suggestions = result.get("suggestions", {})
                statistics = risk_analysis.get("statistics", {})

                if view == "é£é™©ç‚¹":
                    # é£é™©ç­‰çº§ç­›é€‰
                    st.markdown("**é£é™©ç­‰çº§**")
                    risk_levels = ["å…¨éƒ¨", "é‡å¤§é£é™©", "ä¸€èˆ¬é£é™©", "ä½é£é™©"]
                    selected_level = st.radio(
                        "é€‰æ‹©é£é™©ç­‰çº§", risk_levels, horizontal=True, key="risk_filter"
                    )

                    # ç­›é€‰é—®é¢˜
                    filtered_issues = filter_issues_by_risk(all_issues, selected_level)

                    # é£é™©ç»Ÿè®¡
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("æ€»é—®é¢˜æ•°", len(filtered_issues))
                    with col2:
                        risk_score = statistics.get("risk_score", 0)
                        st.metric("é£é™©è¯„åˆ†", f"{risk_score}/100")
                    with col3:
                        risk_level = statistics.get("risk_level", "ä½")
                        level_color = {"é«˜": "ğŸ”´", "ä¸­": "ğŸŸ¡", "ä½": "ğŸŸ¢"}.get(
                            risk_level, "âšª"
                        )
                        st.metric("é£é™©ç­‰çº§", f"{level_color} {risk_level}")

                    # é£é™©é¡¹ç›®åˆ—è¡¨
                    if filtered_issues:
                        st.markdown("---")
                        for i, issue in enumerate(filtered_issues, 1):
                            risk_level = issue.get("é£é™©ç­‰çº§", "ä½")
                            issue_type = issue.get("ç±»å‹", "æœªçŸ¥ç±»å‹")

                            if risk_level == "é«˜":
                                risk_color = "ğŸ”´"
                                risk_label = "é‡å¤§é£é™©"
                            elif risk_level == "ä¸­":
                                risk_color = "ğŸŸ¡"
                                risk_label = "ä¸€èˆ¬é£é™©"
                            else:
                                risk_color = "ğŸŸ¢"
                                risk_label = "ä½é£é™©"

                            with st.container():
                                col1, col2 = st.columns([3, 1])

                                with col1:
                                    st.markdown(f"**{risk_color} {issue_type}**")
                                with col2:
                                    st.markdown(f"**{risk_label}**")

                                with st.expander("è¯¦ç»†ä¿¡æ¯", expanded=True):
                                    st.write(
                                        f"**æ¡æ¬¾ä½ç½®ï¼š** {issue.get('æ¡æ¬¾', 'N/A')}"
                                    )
                                    st.write(
                                        f"**é—®é¢˜æè¿°ï¼š** {issue.get('é—®é¢˜æè¿°', 'N/A')}"
                                    )
                                    st.write(
                                        f"**ä¿®æ”¹å»ºè®®ï¼š** {issue.get('ä¿®æ”¹å»ºè®®', 'N/A')}"
                                    )
                                    if issue.get("æ³•å¾‹ä¾æ®"):
                                        st.write(
                                            f"**æ³•å¾‹ä¾æ®ï¼š** {issue.get('æ³•å¾‹ä¾æ®', 'N/A')}"
                                        )
                                    if issue.get("å½±å“åˆ†æ"):
                                        st.write(
                                            f"**å½±å“åˆ†æï¼š** {issue.get('å½±å“åˆ†æ', 'N/A')}"
                                        )
                                    if issue.get("å•†ä¸šä¼˜åŒ–"):
                                        st.write(
                                            f"**å•†ä¸šä¼˜åŒ–ï¼š** {issue.get('å•†ä¸šä¼˜åŒ–', 'N/A')}"
                                        )

                                st.markdown("---")
                    else:
                        st.info("æœªå‘ç°é—®é¢˜")
                else:
                    # ç»¼åˆå»ºè®®è§†å›¾
                    if not suggestions:
                        st.info("æš‚æ— ç»¼åˆå»ºè®®")
                    else:
                        # æ˜¾ç¤ºæ ¸å¿ƒæ‘˜è¦ä¸å»ºè®®
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric(
                                "é£é™©è¯„åˆ†", f"{statistics.get('risk_score', 0)}/100"
                            )
                        with col2:
                            st.metric(
                                "æ€»é—®é¢˜æ•°",
                                statistics.get("total_issues", len(all_issues)),
                            )
                        with col3:
                            risk_level = statistics.get("risk_level", "ä½")
                            level_color = {"é«˜": "ğŸ”´", "ä¸­": "ğŸŸ¡", "ä½": "ğŸŸ¢"}.get(
                                risk_level, "âšª"
                            )
                            st.metric("é£é™©ç­‰çº§", f"{level_color} {risk_level}")

                        st.markdown("---")
                        # ç›´æ¥å¤ç”¨ç°æœ‰æ¸²æŸ“å‡½æ•°
                        render_suggestions(suggestions)

                # ä¸‹è½½ç»“æœæŒ‰é’®ï¼ˆç›´æ¥ä¸‹è½½ï¼‰
                st.markdown("---")
                json_bytes = json.dumps(result, ensure_ascii=False, indent=2).encode(
                    "utf-8"
                )
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½ç»“æœ",
                    data=json_bytes,
                    file_name=f"contract_analysis_{int(time.time())}.json",
                    mime="application/json",
                    width='stretch',
                )

                if st.button("â¬…ï¸ è¿”å›é¢„è§ˆç•Œé¢", use_container_width=True):
                    st.session_state.view_mode = "preview"
                    st.rerun()

        # æ˜¾ç¤ºæ–‡ä»¶é¢„è§ˆï¼ˆé‡æ„ä¸ºå·¦å³å¯¹ç…§å¸ƒå±€ï¼‰
        if (
            st.session_state.preview_content
            and st.session_state.get("view_mode") == "preview"
        ):
            st.markdown("### ğŸ‘€ æ–‡ä»¶é¢„è§ˆä¸è¯†åˆ«å¯¹ç…§")
            render_preview_panel(
                st.session_state.saved_file_path, st.session_state.preview_content
            )

            if (
                st.session_state.workflow_result
                and st.session_state.processing_status == "completed"
            ):
                if st.button("ğŸ“Š æŸ¥çœ‹åˆ†æç»“æœ", use_container_width=True):
                    st.session_state.view_mode = "analysis"
                    st.rerun()

    else:
        st.info("è¯·ä¸Šä¼ åˆåŒæ–‡ä»¶æˆ–é€‰æ‹©æ ·ä¾‹æ–‡ä»¶å¼€å§‹åˆ†æ")

        # æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
        st.markdown("### ğŸ“– ä½¿ç”¨è¯´æ˜")
        st.markdown(
            """
        1. **ä¸Šä¼ æ–‡ä»¶**: åœ¨å·¦ä¾§è¾¹æ ä¸Šä¼ æ‚¨çš„åˆåŒæ–‡ä»¶ï¼ˆæ”¯æŒPDFã€DOCXã€TXTã€DOCæ ¼å¼ï¼‰
        2. **é€‰æ‹©æ ·ä¾‹**: æˆ–è€…ä»æ ·ä¾‹æ–‡ä»¶ä¸­é€‰æ‹©ä¸€ä¸ªè¿›è¡Œæµ‹è¯•
        3. **å¼€å§‹åˆ†æ**: ç‚¹å‡»"å¼€å§‹åˆ†æ"æŒ‰é’®ï¼Œç³»ç»Ÿå°†ä¾æ¬¡æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š
           - ğŸ“„ è§£ææ–‡æ¡£ï¼šæå–åˆåŒæ–‡æœ¬å†…å®¹
           - ğŸ” é£é™©åˆ†æï¼šè¯†åˆ«æ³•å¾‹ã€å•†ä¸šã€æ ¼å¼é£é™©
           - ğŸ’¡ å»ºè®®ç”Ÿæˆï¼šç”Ÿæˆç»¼åˆåˆ†æå’Œä¿®æ”¹å»ºè®®
           - ğŸ“Š ç»“æœå±•ç¤ºï¼šå±•ç¤ºè¯¦ç»†çš„åˆ†æç»“æœ
        4. **æŸ¥çœ‹ç»“æœ**: åœ¨ç»“æœé¡µé¢æŸ¥çœ‹é£é™©åˆ†æã€ä¿®æ”¹å»ºè®®å’Œç­¾çº¦å»ºè®®
        """
        )


if __name__ == "__main__":
    main()
