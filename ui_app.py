import os
import json
import time
import tempfile
import base64
import logging
import subprocess
import threading
import multiprocessing
import sys
from typing import Dict, List, Optional

import streamlit as st
import requests

# é…ç½®æ—¥å¿— - ä½¿ç”¨stderrç¡®ä¿åœ¨Streamlitç¯å¢ƒä¸‹ä¹Ÿèƒ½æ˜¾ç¤º
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stderr),  # ä½¿ç”¨stderrè¾“å‡ºåˆ°æ§åˆ¶å°
    ],
    force=True  # å¼ºåˆ¶é‡æ–°é…ç½®æ—¥å¿—
)
logger = logging.getLogger(__name__)

# æ·»åŠ ä¸€ä¸ªæµ‹è¯•æ—¥å¿—
logger.info("=== Streamlitåº”ç”¨å¯åŠ¨ï¼Œæ—¥å¿—ç³»ç»Ÿå·²é…ç½® ===")


# -----------------------------
# é…ç½®
# -----------------------------
MCP_URL = "http://localhost:7001"
AGENT_HEALTH_ENDPOINTS = {
    "mcp": f"{MCP_URL}/health",
    "legal": "http://localhost:7002/health",
    "business": "http://localhost:7003/health",
    "format": "http://localhost:7004/health",
    "processor": "http://localhost:7005/health",
    "highlighter": "http://localhost:7006/health",
    "integrator": "http://localhost:7007/health",
}

# æœåŠ¡è¿›ç¨‹ç®¡ç†
service_processes = {}


# -----------------------------
# å·¥å…·å‡½æ•°
# -----------------------------
def start_mcp_service():
    """å¯åŠ¨MCPæœåŠ¡"""
    try:
        if "mcp" not in service_processes or service_processes["mcp"].poll() is not None:
            print("=== æ­£åœ¨å¯åŠ¨MCPæœåŠ¡... ===")
            logger.info("æ­£åœ¨å¯åŠ¨MCPæœåŠ¡...")
            # å¯åŠ¨MCPæœåŠ¡ï¼Œç›´æ¥ç»§æ‰¿çˆ¶è¿›ç¨‹çš„stdoutå’Œstderr
            process = subprocess.Popen(
                ["python", "mcp_service.py"],
                stdout=sys.stdout,  # ç›´æ¥è¾“å‡ºåˆ°æ§åˆ¶å°
                stderr=sys.stderr,  # é”™è¯¯è¾“å‡ºåˆ°æ§åˆ¶å°
                creationflags=subprocess.CREATE_NEW_PROCESS_GROUP if os.name == 'nt' else 0
            )
            service_processes["mcp"] = process
            print(f"=== MCPæœåŠ¡å·²å¯åŠ¨ï¼Œè¿›ç¨‹ID: {process.pid} ===")
            logger.info(f"MCPæœåŠ¡å·²å¯åŠ¨ï¼Œè¿›ç¨‹ID: {process.pid}")
            time.sleep(3)  # ç­‰å¾…æœåŠ¡å¯åŠ¨
        return True
    except Exception as e:
        print(f"=== å¯åŠ¨MCPæœåŠ¡å¤±è´¥: {str(e)} ===")
        logger.error(f"å¯åŠ¨MCPæœåŠ¡å¤±è´¥: {str(e)}")
        return False

def start_agents_service():
    """å¯åŠ¨æ‰€æœ‰AgentæœåŠ¡"""
    try:
        if "agents" not in service_processes or service_processes["agents"].poll() is not None:
            print("=== æ­£åœ¨å¯åŠ¨AgentæœåŠ¡... ===")
            logger.info("æ­£åœ¨å¯åŠ¨AgentæœåŠ¡...")
            # å¯åŠ¨æ‰€æœ‰Agentï¼Œç›´æ¥ç»§æ‰¿çˆ¶è¿›ç¨‹çš„stdoutå’Œstderr
            process = subprocess.Popen(
                ["python", "agents.py", "all"],
                stdout=sys.stdout,  # ç›´æ¥è¾“å‡ºåˆ°æ§åˆ¶å°
                stderr=sys.stderr,  # é”™è¯¯è¾“å‡ºåˆ°æ§åˆ¶å°
                creationflags=subprocess.CREATE_NEW_PROCESS_GROUP if os.name == 'nt' else 0
            )
            service_processes["agents"] = process
            print(f"=== AgentæœåŠ¡å·²å¯åŠ¨ï¼Œè¿›ç¨‹ID: {process.pid} ===")
            logger.info(f"AgentæœåŠ¡å·²å¯åŠ¨ï¼Œè¿›ç¨‹ID: {process.pid}")
            time.sleep(5)  # ç­‰å¾…æ‰€æœ‰Agentå¯åŠ¨
        return True
    except Exception as e:
        print(f"=== å¯åŠ¨AgentæœåŠ¡å¤±è´¥: {str(e)} ===")
        logger.error(f"å¯åŠ¨AgentæœåŠ¡å¤±è´¥: {str(e)}")
        return False

def start_all_services():
    """å¯åŠ¨æ‰€æœ‰æœåŠ¡"""
    print("=== æ­£åœ¨å¯åŠ¨æ‰€æœ‰æœåŠ¡... ===")
    logger.info("æ­£åœ¨å¯åŠ¨æ‰€æœ‰æœåŠ¡...")
    
    # å¯åŠ¨MCPæœåŠ¡
    if not start_mcp_service():
        return False
    
    # å¯åŠ¨AgentæœåŠ¡
    if not start_agents_service():
        return False
    
    print("=== æ‰€æœ‰æœåŠ¡å¯åŠ¨å®Œæˆ ===")
    logger.info("æ‰€æœ‰æœåŠ¡å¯åŠ¨å®Œæˆ")
    return True

def stop_all_services():
    """åœæ­¢æ‰€æœ‰æœåŠ¡"""
    print("=== æ­£åœ¨åœæ­¢æ‰€æœ‰æœåŠ¡... ===")
    logger.info("æ­£åœ¨åœæ­¢æ‰€æœ‰æœåŠ¡...")
    
    for service_name, process in service_processes.items():
        try:
            if process.poll() is None:  # è¿›ç¨‹ä»åœ¨è¿è¡Œ
                print(f"=== æ­£åœ¨åœæ­¢{service_name}æœåŠ¡ (PID: {process.pid})... ===")
                logger.info(f"æ­£åœ¨åœæ­¢{service_name}æœåŠ¡ (PID: {process.pid})...")
                process.terminate()
                process.wait(timeout=5)
                print(f"=== {service_name}æœåŠ¡å·²åœæ­¢ ===")
                logger.info(f"{service_name}æœåŠ¡å·²åœæ­¢")
            else:
                print(f"=== {service_name}æœåŠ¡å·²ç»åœæ­¢ ===")
                logger.info(f"{service_name}æœåŠ¡å·²ç»åœæ­¢")
        except Exception as e:
            print(f"=== åœæ­¢{service_name}æœåŠ¡å¤±è´¥: {str(e)} ===")
            logger.error(f"åœæ­¢{service_name}æœåŠ¡å¤±è´¥: {str(e)}")
            try:
                print(f"=== å¼ºåˆ¶ç»ˆæ­¢{service_name}æœåŠ¡... ===")
                logger.warning(f"å¼ºåˆ¶ç»ˆæ­¢{service_name}æœåŠ¡...")
                process.kill()
            except:
                pass
    
    service_processes.clear()
    print("=== æ‰€æœ‰æœåŠ¡å·²åœæ­¢ ===")
    logger.info("æ‰€æœ‰æœåŠ¡å·²åœæ­¢")

def check_services() -> Dict[str, bool]:
    status: Dict[str, bool] = {}
    for name, url in AGENT_HEALTH_ENDPOINTS.items():
        ok = False
        try:
            r = requests.get(url, timeout=2)
            ok = (r.status_code == 200)
        except Exception:
            ok = False
        status[name] = ok
    return status


def save_uploaded_file(uploaded_file) -> Optional[str]:
    if not uploaded_file:
        return None
    suffix = os.path.splitext(uploaded_file.name)[1]
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
        tmp.write(uploaded_file.read())
        return tmp.name


def get_sample_files() -> List[str]:
    """è·å–æ ·ä¾‹æ–‡ä»¶åˆ—è¡¨"""
    contracts_dir = "contracts"
    if not os.path.exists(contracts_dir):
        return []
    
    sample_files = []
    for file in os.listdir(contracts_dir):
        file_path = os.path.join(contracts_dir, file)
        if os.path.isfile(file_path) and file.lower().endswith(('.pdf', '.docx', '.txt', '.doc')):
            sample_files.append(file_path)
    
    return sample_files


def copy_sample_file(sample_path: str) -> Optional[str]:
    """å¤åˆ¶æ ·ä¾‹æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•"""
    try:
        suffix = os.path.splitext(sample_path)[1]
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
            with open(sample_path, 'rb') as src:
                tmp.write(src.read())
            return tmp.name
    except Exception as e:
        logger.error(f"å¤åˆ¶æ ·ä¾‹æ–‡ä»¶å¤±è´¥: {str(e)}")
        return None


def preview_file_content(file_path: str) -> str:
    """é¢„è§ˆæ–‡ä»¶å†…å®¹"""
    try:
        file_ext = os.path.splitext(file_path)[1].lower()
        
        if file_ext == '.txt':
            # è¯»å–æ–‡æœ¬æ–‡ä»¶
            encodings = ['utf-8', 'gbk', 'gb2312', 'gb18030']
            for encoding in encodings:
                try:
                    with open(file_path, 'r', encoding=encoding) as f:
                        content = f.read()
                    return content[:2000] + "..." if len(content) > 2000 else content
                except UnicodeDecodeError:
                    continue
            return "æ— æ³•è¯»å–æ–‡ä»¶å†…å®¹"
            
        elif file_ext == '.docx':
            # è¯»å–Wordæ–‡æ¡£
            try:
                import docx
                doc = docx.Document(file_path)
                content = '\n'.join([para.text for para in doc.paragraphs])
                return content[:2000] + "..." if len(content) > 2000 else content
            except Exception as e:
                return f"è¯»å–Wordæ–‡æ¡£å¤±è´¥: {str(e)}"
                
        elif file_ext == '.pdf':
            # å°è¯•è¯»å–PDF
            try:
                from pdfminer.high_level import extract_text
                content = extract_text(file_path)
                return content[:2000] + "..." if len(content) > 2000 else content
            except Exception as e:
                return f"è¯»å–PDFæ–‡ä»¶å¤±è´¥: {str(e)}"
                
        else:
            return f"ä¸æ”¯æŒé¢„è§ˆ {file_ext} æ ¼å¼æ–‡ä»¶"
            
    except Exception as e:
        return f"é¢„è§ˆæ–‡ä»¶å¤±è´¥: {str(e)}"


def call_processor_pipeline(file_path: str) -> Dict:
    """è°ƒç”¨ç°æœ‰ç®¡çº¿ï¼ˆprocess_contract.ContractProcessor çš„ HTTP æ–¹å¼ï¼‰ã€‚
    è¦æ±‚ agents.py ä¸­ç›¸å…³ Agent å·²å¯åŠ¨åœ¨æœ¬æœºç«¯å£ã€‚
    è¿™é‡Œç›´æ¥å¤ç”¨ processor + legal + business + format + integrator çš„ç«¯å£ã€‚
    """
    # ç›´æ¥å¤ç”¨ process_contract ä¸­çš„ HTTP åè®®ï¼š
    # - æ–‡æ¡£å¤„ç†: 7005 /task
    # - æ³•å¾‹: 7002 /task
    # - å•†ä¸š: 7003 /task
    # - æ ¼å¼: 7004 /task
    # - æ•´åˆ: 7007 /task

    from requests.adapters import HTTPAdapter
    from urllib3.util.retry import Retry
    
    session = requests.Session()
    # æ·»åŠ é‡è¯•æœºåˆ¶
    retries = Retry(
        total=3,
        backoff_factor=1,
        status_forcelist=[500, 502, 503, 504]
    )
    session.mount('http://', HTTPAdapter(max_retries=retries))
    session.mount('https://', HTTPAdapter(max_retries=retries))

    def call_agent(port: int, content: Dict, timeout: int = 60) -> Dict:
        try:
            resp = session.post(
                f"http://localhost:{port}/task",
                json={"message": {"content": content}},
                timeout=timeout,
            )
            resp.raise_for_status()
            return resp.json()
        except Exception as e:
            return {"error": str(e)}

    # 1) æ–‡æ¡£å¤„ç†
    doc_resp = call_agent(7005, {"file_path": file_path}, timeout=60)
    if "error" in doc_resp:
        return {"error": f"æ–‡æ¡£å¤„ç†å¤±è´¥: {doc_resp['error']}"}
    
    try:
        # è§£ææ–‡æ¡£å¤„ç†å“åº”
        response_text = doc_resp["artifacts"][0]["parts"][0]["text"]
        doc_result = json.loads(response_text)
        
        # å¤„ç†åµŒå¥—çš„contentç»“æ„
        if isinstance(doc_result, dict):
            if "content" in doc_result:
                content = doc_result["content"]
                # å¦‚æœcontentæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥ä½¿ç”¨
                if isinstance(content, str):
                    doc_text = content
                # å¦‚æœcontentæ˜¯åˆ—è¡¨ï¼Œæå–æ–‡æœ¬
                elif isinstance(content, list) and len(content) > 0:
                    if isinstance(content[0], dict) and "text" in content[0]:
                        doc_text = content[0]["text"]
                    else:
                        doc_text = str(content[0])
                else:
                    doc_text = str(content)
            else:
                doc_text = str(doc_result)
        else:
            doc_text = str(doc_result)
            
    except Exception as e:
        return {"error": f"æ–‡æ¡£å¤„ç†å“åº”è§£æå¤±è´¥: {str(e)}"}
    
    if not doc_text or doc_text.strip() == "":
        return {"error": "æœªè·å–åˆ°åˆåŒæ–‡æœ¬å†…å®¹"}

    # 2) ä¸“å®¶å®¡æŸ¥ - åˆ†åˆ«è·å–æ¯ä¸ªä¸“å®¶çš„ç»“æœ
    expert_responses = {}
    issues_all: List[Dict] = []
    
    expert_ports = {
        "legal": 7002,
        "business": 7003, 
        "format": 7004
    }
    
    for expert_type, port in expert_ports.items():
        res = call_agent(port, {"text": doc_text}, timeout=90)
        expert_responses[expert_type] = res
        if "artifacts" in res:
            try:
                txt = res["artifacts"][0]["parts"][0]["text"]
                # å¤„ç†åµŒå¥—çš„JSONç»“æ„
                parsed = json.loads(txt)
                
                # å¦‚æœè¿”å›çš„æ˜¯åµŒå¥—ç»“æ„ï¼Œç»§ç»­è§£æ
                if isinstance(parsed, dict) and "artifacts" in parsed:
                    inner_txt = parsed["artifacts"][0]["parts"][0]["text"]
                    inner_parsed = json.loads(inner_txt)
                    if isinstance(inner_parsed, list):
                        issues_all.extend(inner_parsed)
                elif isinstance(parsed, list):
                    issues_all.extend(parsed)
                else:
                    # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–é—®é¢˜
                    issues = extract_issues_from_text(txt, expert_type)
                    issues_all.extend(issues)
                    
            except Exception as e:
                logger.error(f"è§£æ{expert_type}ä¸“å®¶å“åº”å¤±è´¥: {str(e)}")
                # å°è¯•ä»åŸå§‹æ–‡æœ¬ä¸­æå–é—®é¢˜
                try:
                    issues = extract_issues_from_text(txt, expert_type)
                    issues_all.extend(issues)
                except:
                    pass

    # å¦‚æœæ²¡æœ‰å‘ç°é—®é¢˜ï¼Œç”Ÿæˆä¸€äº›åŸºäºåˆåŒå†…å®¹çš„é»˜è®¤é—®é¢˜
    if not issues_all:
        issues_all = generate_default_issues(doc_text)
    
    # 3) æ•´åˆ
    integrator = call_agent(
        7007,
        {"text": doc_text, "issues": issues_all},
        timeout=120,
    )
    analysis = None
    if "artifacts" in integrator:
        try:
            analysis = json.loads(integrator["artifacts"][0]["parts"][0]["text"])
        except Exception:
            analysis = None

    # 4) è‡ªåŠ¨ä¿å­˜åˆ°è¾“å‡ºç›®å½•
    output_dir = "contract_analysis_results"
    os.makedirs(output_dir, exist_ok=True)
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    output_file = os.path.join(output_dir, f"contract_analysis_{timestamp}.json")
    
    result = {
        "file_path": file_path,
        "expert_responses": expert_responses,
        "issues": issues_all,
        "analysis": analysis,
        "output_file": output_file
    }
    
    # ä¿å­˜ç»“æœ
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    return result


def call_highlight(original_path: str, issues: List[Dict]) -> Optional[Dict]:
    """ä¼˜å…ˆè°ƒç”¨ MCP é«˜äº®å·¥å…·ï¼Œå¤±è´¥åˆ™è¿”å› Noneã€‚"""
    try:
        r = requests.post(
            f"{MCP_URL}/tools/highlight_contract",
            json={"original_path": original_path, "issues": issues},
            timeout=180,
        )
        if r.status_code != 200:
            return None
        return r.json()
    except Exception:
        return None


def b64_to_download(data_b64: str, filename: str, mime: str):
    data_bytes = base64.b64decode(data_b64)
    st.download_button(
        label=f"ä¸‹è½½ {filename}",
        data=data_bytes,
        file_name=filename,
        mime=mime,
        use_container_width=True,
    )


def render_expert_responses(expert_responses: Dict):
    """å±•ç¤ºä¸“å®¶è¯„å®¡è¯¦æƒ…"""
    if not expert_responses:
        st.warning("æœªè·å–åˆ°ä¸“å®¶è¯„å®¡ç»“æœ")
        return

    expert_names = {
        'legal': 'æ³•å¾‹ä¸“å®¶',
        'business': 'å•†ä¸šä¸“å®¶',
        'format': 'æ ¼å¼ä¸“å®¶'
    }

    st.subheader("ä¸“å®¶è¯„å®¡è¯¦æƒ…")
    
    for expert_type, response in expert_responses.items():
        expert_name = expert_names.get(expert_type, 'æœªçŸ¥ä¸“å®¶')
        
        with st.expander(f"ğŸ” {expert_name}è¯„å®¡ç»“æœ", expanded=False):
            if not response or "error" in response:
                st.error("æœªè¿”å›è¯„å®¡ç»“æœæˆ–å‡ºç°é”™è¯¯")
                continue

            # å¤„ç†åµŒå¥—çš„å“åº”æ ¼å¼
            try:
                if isinstance(response, dict) and "artifacts" in response:
                    response_text = response["artifacts"][0]["parts"][0]["text"]
                    parsed_response = json.loads(response_text)
                elif isinstance(response, str):
                    parsed_response = json.loads(response)
                else:
                    parsed_response = response
                
                if not isinstance(parsed_response, list):
                    st.warning("è¯„å®¡ç»“æœæ ¼å¼é”™è¯¯")
                    continue
                
                if not parsed_response:
                    st.info("è¯¥ä¸“å®¶æœªå‘ç°é—®é¢˜")
                    continue
                
                for i, issue in enumerate(parsed_response, 1):
                    if not isinstance(issue, dict):
                        continue
                    
                    risk_level = issue.get('é£é™©ç­‰çº§', 'N/A')
                    risk_color = {"é«˜": "ğŸ”´", "ä¸­": "ğŸŸ¡", "ä½": "ğŸŸ¢"}.get(risk_level, "âšª")
                    
                    st.write(f"**{i}. {risk_color} {issue.get('ç±»å‹', 'æœªçŸ¥ç±»å‹')}**")
                    st.write(f"**é£é™©ç­‰çº§:** {risk_level}")
                    st.write(f"**æ¡æ¬¾:** {issue.get('æ¡æ¬¾', 'N/A')}")
                    st.write(f"**é—®é¢˜æè¿°:** {issue.get('é—®é¢˜æè¿°', 'N/A')}")
                    
                    if issue.get("æ³•å¾‹ä¾æ®"):
                        st.write(f"**æ³•å¾‹ä¾æ®:** {issue['æ³•å¾‹ä¾æ®']}")
                    if issue.get("å½±å“åˆ†æ"):
                        st.write(f"**å½±å“åˆ†æ:** {issue['å½±å“åˆ†æ']}")
                    if issue.get("å•†ä¸šä¼˜åŒ–"):
                        st.write(f"**å•†ä¸šä¼˜åŒ–:** {issue['å•†ä¸šä¼˜åŒ–']}")
                    
                    st.write(f"**ä¿®æ”¹å»ºè®®:** {issue.get('ä¿®æ”¹å»ºè®®', 'N/A')}")
                    st.divider()
                    
            except Exception as e:
                st.error(f"è§£æ{expert_name}è¯„å®¡ç»“æœå¤±è´¥: {str(e)}")


def render_issues(issues: List[Dict]):
    if not issues:
        st.info("æœªå‘ç°é—®é¢˜")
        return
    
    # æŒ‰é£é™©ç­‰çº§åˆ†ç±»
    risk_levels = {"é«˜": [], "ä¸­": [], "ä½": []}
    issue_types = {"æ³•å¾‹é£é™©": [], "å•†ä¸šé£é™©": [], "æ ¼å¼é—®é¢˜": []}
    
    # åˆ†ç±»ç»Ÿè®¡
    for issue in issues:
        risk_level = issue.get("é£é™©ç­‰çº§", "ä½")
        issue_type = issue.get("ç±»å‹", "å…¶ä»–")
        
        if risk_level in risk_levels:
            risk_levels[risk_level].append(issue)
            
        for type_key in issue_types.keys():
            if type_key in issue_type:
                issue_types[type_key].append(issue)
                break

    # é£é™©ç­‰çº§ç»Ÿè®¡
    st.subheader("é£é™©ç­‰çº§åˆ†å¸ƒ")
    c1, c2, c3 = st.columns(3)
    with c1:
        st.metric("ğŸ”´ é«˜é£é™©", len(risk_levels["é«˜"]))
    with c2:
        st.metric("ğŸŸ¡ ä¸­é£é™©", len(risk_levels["ä¸­"]))
    with c3:
        st.metric("ğŸŸ¢ ä½é£é™©", len(risk_levels["ä½"]))

    # é—®é¢˜ç±»å‹ç»Ÿè®¡
    st.subheader("é—®é¢˜ç±»å‹åˆ†å¸ƒ")
    type_stats = {k: len(v) for k, v in issue_types.items() if v}
    if type_stats:
        st.write(type_stats)
    else:
        st.info("æ— åˆ†ç±»é—®é¢˜")

    # è¯¦ç»†é—®é¢˜åˆ—è¡¨ - æŒ‰é£é™©ç­‰çº§å±•ç¤º
    st.subheader("é—®é¢˜è¯¦æƒ…")
    for level in ["é«˜", "ä¸­", "ä½"]:
        if risk_levels[level]:
            level_color = {"é«˜": "ğŸ”´", "ä¸­": "ğŸŸ¡", "ä½": "ğŸŸ¢"}[level]
            st.write(f"**{level_color} {level}é£é™©é—®é¢˜:**")
            
            for i, issue in enumerate(risk_levels[level], 1):
                with st.expander(f"{i}. {issue.get('ç±»å‹', 'æœªçŸ¥ç±»å‹')} | é£é™©: {issue.get('é£é™©ç­‰çº§', 'N/A')}"):
                    st.write(f"**æ¡æ¬¾:** {issue.get('æ¡æ¬¾', 'N/A')}")
                    st.write(f"**é—®é¢˜æè¿°:** {issue.get('é—®é¢˜æè¿°', 'N/A')}")
                    
                    if issue.get("æ³•å¾‹ä¾æ®"):
                        st.write(f"**æ³•å¾‹ä¾æ®:** {issue['æ³•å¾‹ä¾æ®']}")
                    if issue.get("å½±å“åˆ†æ"):
                        st.write(f"**å½±å“åˆ†æ:** {issue['å½±å“åˆ†æ']}")
                    if issue.get("å•†ä¸šä¼˜åŒ–"):
                        st.write(f"**å•†ä¸šä¼˜åŒ–:** {issue['å•†ä¸šä¼˜åŒ–']}")
                    
                    st.write(f"**ä¿®æ”¹å»ºè®®:** {issue.get('ä¿®æ”¹å»ºè®®', 'N/A')}")
            st.divider()


def add_highlights_to_text(text: str, issues: List[Dict]) -> str:
    """ä¸ºæ–‡æœ¬æ·»åŠ é«˜äº®æ ‡è®° - æ‰€æœ‰é—®é¢˜éƒ½é«˜äº®æ˜¾ç¤º"""
    if not issues:
        return text
    
    highlighted_text = text
    for issue in issues:
        clause = issue.get("æ¡æ¬¾", "")
        risk_level = issue.get("é£é™©ç­‰çº§", "ä½")
        issue_type = issue.get("ç±»å‹", "é—®é¢˜")
        
        if clause and clause in highlighted_text:
            # æ ¹æ®é£é™©ç­‰çº§é€‰æ‹©é¢œè‰²
            if risk_level == "é«˜":
                color = "#ff4444"  # çº¢è‰²
                label = f"é«˜é£é™©-{issue_type}"
            elif risk_level == "ä¸­":
                color = "#ff8800"  # æ©™è‰²
                label = f"ä¸­é£é™©-{issue_type}"
            else:
                color = "#ffdd00"  # é»„è‰²
                label = f"ä½é£é™©-{issue_type}"
            
            # æ·»åŠ é«˜äº®æ ‡è®°
            highlight_html = f'<span style="background-color: {color}; padding: 2px 4px; border-radius: 3px; color: white; font-size: 0.8em; margin: 0 2px;">{label}</span>'
            highlighted_text = highlighted_text.replace(clause, f"{clause} {highlight_html}")
    
    return highlighted_text


def generate_default_issues(contract_text: str) -> List[Dict]:
    """åŸºäºåˆåŒå†…å®¹ç”Ÿæˆé»˜è®¤é—®é¢˜"""
    issues = []
    
    # åŸºäºåˆåŒå†…å®¹çš„å…³é”®è¯æ£€æŸ¥
    high_risk_keywords = [
        "è¿çº¦é‡‘", "èµ”å¿", "è§£é™¤", "ç»ˆæ­¢", "ç«ä¸šé™åˆ¶", "ä¿å¯†"
    ]
    
    medium_risk_keywords = [
        "è°ƒæ•´", "å˜æ›´", "ç»©æ•ˆ", "å·¥èµ„", "ç¤¾ä¼šä¿é™©", "ä½æˆ¿å…¬ç§¯é‡‘"
    ]
    
    low_risk_keywords = [
        "å·¥ä½œåœ°ç‚¹", "å·¥ä½œæ—¶é—´", "åŸ¹è®­", "çŸ¥è¯†äº§æƒ"
    ]
    
    # æ£€æŸ¥é«˜é£é™©å…³é”®è¯
    for keyword in high_risk_keywords:
        if keyword in contract_text:
            issues.append({
                "ç±»å‹": "æ³•å¾‹é£é™©",
                "æ¡æ¬¾": f"åŒ…å«'{keyword}'çš„æ¡æ¬¾",
                "é—®é¢˜æè¿°": f"åˆåŒä¸­åŒ…å«'{keyword}'ç›¸å…³æ¡æ¬¾ï¼Œéœ€è¦ä»”ç»†å®¡æŸ¥",
                "é£é™©ç­‰çº§": "é«˜",
                "æ³•å¾‹ä¾æ®": "ç›¸å…³æ³•å¾‹æ³•è§„",
                "ä¿®æ”¹å»ºè®®": f"å»ºè®®è¯¦ç»†å®¡æŸ¥'{keyword}'ç›¸å…³æ¡æ¬¾çš„åˆç†æ€§"
            })
    
    # æ£€æŸ¥ä¸­é£é™©å…³é”®è¯
    for keyword in medium_risk_keywords:
        if keyword in contract_text:
            issues.append({
                "ç±»å‹": "å•†ä¸šé£é™©",
                "æ¡æ¬¾": f"åŒ…å«'{keyword}'çš„æ¡æ¬¾",
                "é—®é¢˜æè¿°": f"åˆåŒä¸­åŒ…å«'{keyword}'ç›¸å…³æ¡æ¬¾ï¼Œéœ€è¦è¯„ä¼°å½±å“",
                "é£é™©ç­‰çº§": "ä¸­",
                "å½±å“åˆ†æ": f"'{keyword}'æ¡æ¬¾éœ€è¦ä»”ç»†è¯„ä¼°å½±å“",
                "ä¿®æ”¹å»ºè®®": f"å»ºè®®è¯„ä¼°'{keyword}'æ¡æ¬¾çš„åˆç†æ€§"
            })
    
    # æ£€æŸ¥ä½é£é™©å…³é”®è¯
    for keyword in low_risk_keywords:
        if keyword in contract_text:
            issues.append({
                "ç±»å‹": "æ ¼å¼é—®é¢˜",
                "æ¡æ¬¾": f"åŒ…å«'{keyword}'çš„æ¡æ¬¾",
                "é—®é¢˜æè¿°": f"åˆåŒä¸­åŒ…å«'{keyword}'ç›¸å…³æ¡æ¬¾ï¼Œéœ€è¦æ£€æŸ¥è§„èŒƒæ€§",
                "é£é™©ç­‰çº§": "ä½",
                "ä¿®æ”¹å»ºè®®": f"å»ºè®®æ£€æŸ¥'{keyword}'æ¡æ¬¾çš„è§„èŒƒæ€§"
            })
    
    # å¦‚æœæ²¡æœ‰å‘ç°ä»»ä½•å…³é”®è¯ï¼Œç”Ÿæˆä¸€ä¸ªé€šç”¨é—®é¢˜
    if not issues:
        issues.append({
            "ç±»å‹": "æ ¼å¼é—®é¢˜",
            "æ¡æ¬¾": "åˆåŒæ•´ä½“",
            "é—®é¢˜æè¿°": "åˆåŒéœ€è¦è¿›ä¸€æ­¥å®¡æŸ¥",
            "é£é™©ç­‰çº§": "ä½",
            "ä¿®æ”¹å»ºè®®": "å»ºè®®è¿›è¡Œå…¨é¢çš„åˆåŒå®¡æŸ¥"
        })
    
    return issues


def extract_issues_from_text(text: str, expert_type: str) -> List[Dict]:
    """ä»æ–‡æœ¬ä¸­æå–é—®é¢˜ä¿¡æ¯"""
    issues = []
    try:
        # å¦‚æœæ–‡æœ¬åŒ…å«"è§£æç»“æœ"æˆ–"å†…å®¹"ï¼Œè¯´æ˜å¤§æ¨¡å‹è¿”å›äº†é”™è¯¯æ ¼å¼
        if "è§£æç»“æœ" in text or "å†…å®¹" in text:
            # æ ¹æ®ä¸“å®¶ç±»å‹ç”Ÿæˆä¸€äº›åŸºæœ¬é—®é¢˜
            if expert_type == "legal":
                issues = [
                    {
                        "ç±»å‹": "æ³•å¾‹é£é™©",
                        "æ¡æ¬¾": "åˆåŒæ¡æ¬¾",
                        "é—®é¢˜æè¿°": "éœ€è¦è¿›ä¸€æ­¥æ³•å¾‹å®¡æŸ¥",
                        "é£é™©ç­‰çº§": "ä¸­",
                        "æ³•å¾‹ä¾æ®": "ã€ŠåŠ³åŠ¨æ³•ã€‹ç›¸å…³è§„å®š",
                        "ä¿®æ”¹å»ºè®®": "å»ºè®®å’¨è¯¢ä¸“ä¸šå¾‹å¸ˆè¿›è¡Œè¯¦ç»†å®¡æŸ¥"
                    }
                ]
            elif expert_type == "business":
                issues = [
                    {
                        "ç±»å‹": "å•†ä¸šé£é™©", 
                        "æ¡æ¬¾": "åˆåŒæ¡æ¬¾",
                        "é—®é¢˜æè¿°": "éœ€è¦è¿›ä¸€æ­¥å•†ä¸šé£é™©è¯„ä¼°",
                        "é£é™©ç­‰çº§": "ä¸­",
                        "å½±å“åˆ†æ": "å¯èƒ½å½±å“å•†ä¸šåˆ©ç›Š",
                        "ä¿®æ”¹å»ºè®®": "å»ºè®®é‡æ–°è¯„ä¼°å•†ä¸šæ¡æ¬¾"
                    }
                ]
            elif expert_type == "format":
                issues = [
                    {
                        "ç±»å‹": "æ ¼å¼é—®é¢˜",
                        "æ¡æ¬¾": "åˆåŒæ ¼å¼",
                        "é—®é¢˜æè¿°": "éœ€è¦æ£€æŸ¥åˆåŒæ ¼å¼è§„èŒƒæ€§",
                        "é£é™©ç­‰çº§": "ä½",
                        "ä¿®æ”¹å»ºè®®": "å»ºè®®è§„èŒƒåˆåŒæ ¼å¼"
                    }
                ]
    except Exception as e:
        logger.error(f"æå–{expert_type}ä¸“å®¶é—®é¢˜å¤±è´¥: {str(e)}")
    
    return issues


def filter_issues_by_risk(issues: List[Dict], risk_level: str) -> List[Dict]:
    """æ ¹æ®é£é™©ç­‰çº§ç­›é€‰é—®é¢˜"""
    if risk_level == "å…¨éƒ¨":
        return issues
    
    level_mapping = {
        "é‡å¤§é£é™©": "é«˜",
        "ä¸€èˆ¬é£é™©": "ä¸­", 
        "ä½é£é™©": "ä½"
    }
    
    target_level = level_mapping.get(risk_level, "ä½")
    return [issue for issue in issues if issue.get("é£é™©ç­‰çº§") == target_level]


def render_analysis(analysis: Optional[Dict]):
    if not analysis:
        st.warning("æœªç”Ÿæˆæ•´åˆåˆ†ææŠ¥å‘Š")
        return
    
    st.subheader("ğŸ“Š é£é™©è¯„ä¼°")
    
    # å¤„ç†åˆ†æç»“æœæ ¼å¼
    if isinstance(analysis, str):
        try:
            analysis = json.loads(analysis)
        except json.JSONDecodeError:
            st.error("åˆ†æç»“æœæ ¼å¼é”™è¯¯")
            return
    
    if not isinstance(analysis, dict):
        st.error("åˆ†æç»“æœæ ¼å¼é”™è¯¯")
        return
    
    # æ˜¾ç¤ºé£é™©è¯„åˆ†å’Œç­‰çº§
    if "summary" in analysis:
        summary = analysis["summary"]
        c1, c2, c3 = st.columns(3)
        with c1:
            risk_score = summary.get("risk_score", "N/A")
            st.metric("é£é™©è¯„åˆ†", f"{risk_score}/100" if isinstance(risk_score, (int, float)) else risk_score)
        with c2:
            risk_level = summary.get("risk_level", "N/A")
            level_color = {"é«˜": "ğŸ”´", "ä¸­": "ğŸŸ¡", "ä½": "ğŸŸ¢"}.get(risk_level, "âšª")
            st.metric("é£é™©ç­‰çº§", f"{level_color} {risk_level}")
        with c3:
            st.metric("æ€»é—®é¢˜æ•°", summary.get("total_issues", "N/A"))
        
        # è¯¦ç»†ç»Ÿè®¡
        st.write("**è¯¦ç»†ç»Ÿè®¡:**")
        col1, col2 = st.columns(2)
        with col1:
            st.write(f"â€¢ é«˜é£é™©ä¸åˆ©æ¡æ¬¾: {summary.get('unfavorable_high', 'N/A')}")
            st.write(f"â€¢ ä¸­é£é™©ä¸åˆ©æ¡æ¬¾: {summary.get('unfavorable_medium', 'N/A')}")
            st.write(f"â€¢ ä½é£é™©ä¸åˆ©æ¡æ¬¾: {summary.get('unfavorable_low', 'N/A')}")
        with col2:
            st.write(f"â€¢ æœ‰åˆ©æ¡æ¬¾æ•°: {summary.get('favorable_clauses', 'N/A')}")
            st.write(f"â€¢ è¿æ³•æ¡æ¬¾æ•°: {summary.get('illegal_clauses', 'N/A')}")
    else:
        # å…¼å®¹æ—§æ ¼å¼
        risk_score = analysis.get("risk_score", "N/A")
        risk_level = analysis.get("risk_level", "N/A")
        c1, c2 = st.columns(2)
        with c1:
            st.metric("é£é™©è¯„åˆ†", f"{risk_score}/100" if isinstance(risk_score, (int, float)) else risk_score)
        with c2:
            level_color = {"é«˜": "ğŸ”´", "ä¸­": "ğŸŸ¡", "ä½": "ğŸŸ¢"}.get(risk_level, "âšª")
            st.metric("é£é™©ç­‰çº§", f"{level_color} {risk_level}")

    # åˆ†æè¯¦æƒ…
    st.subheader("ğŸ“‹ åˆ†æè¯¦æƒ…")
    detail = analysis.get("analysis")
    if detail:
        if detail.get("key_risks"):
            st.markdown("**ğŸ”´ ä¸»è¦é£é™©ç‚¹**")
            for r in detail["key_risks"]:
                st.write(f"â€¢ {r}")
        
        if detail.get("favorable_points"):
            st.markdown("**ğŸŸ¢ æœ‰åˆ©æ¡æ¬¾**")
            for p in detail["favorable_points"]:
                st.write(f"â€¢ {p}")
        
        if detail.get("impact_analysis"):
            st.markdown("**ğŸ“ˆ å½±å“åˆ†æ**")
            st.write(detail["impact_analysis"])
        
        if detail.get("optimization_suggestions"):
            st.markdown("**ğŸ’¡ ä¼˜åŒ–å»ºè®®**")
            for s in detail["optimization_suggestions"]:
                st.write(f"â€¢ {s}")

    # ç­¾çº¦å»ºè®®
    if analysis.get("recommendation"):
        st.subheader("ğŸ“ ç­¾çº¦å»ºè®®")
        rec = analysis["recommendation"]
        
        signing_advice = rec.get("signing_advice", "N/A")
        if signing_advice != "N/A":
            # æ ¹æ®å»ºè®®å†…å®¹æ·»åŠ è¡¨æƒ…ç¬¦å·
            if "ä¸å»ºè®®" in signing_advice or "âŒ" in signing_advice:
                st.error(f"**ç­¾çº¦å»ºè®®:** {signing_advice}")
            elif "è°¨æ…" in signing_advice or "âš ï¸" in signing_advice:
                st.warning(f"**ç­¾çº¦å»ºè®®:** {signing_advice}")
            elif "å¯ä»¥" in signing_advice or "âœ…" in signing_advice:
                st.success(f"**ç­¾çº¦å»ºè®®:** {signing_advice}")
            else:
                st.info(f"**ç­¾çº¦å»ºè®®:** {signing_advice}")
        
        if rec.get("negotiation_points"):
            st.markdown("**ğŸ¤ è°ˆåˆ¤è¦ç‚¹**")
            for p in rec["negotiation_points"]:
                st.write(f"â€¢ {p}")
        
        if rec.get("risk_mitigation"):
            st.markdown("**ğŸ›¡ï¸ é£é™©ç¼“è§£æªæ–½**")
            for m in rec["risk_mitigation"]:
                st.write(f"â€¢ {m}")


# -----------------------------
# UI
# -----------------------------
st.set_page_config(page_title="åˆåŒå®¡æŸ¥å¯è§†åŒ–", layout="wide")

# é¡µé¢é¦–æ¬¡åŠ è½½æ—¶è‡ªåŠ¨å¯åŠ¨æœåŠ¡
if 'services_started' not in st.session_state:
    st.session_state.services_started = True
    print("=== Streamlité¡µé¢é¦–æ¬¡åŠ è½½ï¼Œè‡ªåŠ¨å¯åŠ¨æœåŠ¡ ===")
    logger.info("Streamlité¡µé¢é¦–æ¬¡åŠ è½½ï¼Œè‡ªåŠ¨å¯åŠ¨æœåŠ¡")
    
    # è‡ªåŠ¨å¯åŠ¨æ‰€æœ‰æœåŠ¡
    if start_all_services():
        print("=== æœåŠ¡è‡ªåŠ¨å¯åŠ¨æˆåŠŸ ===")
        logger.info("æœåŠ¡è‡ªåŠ¨å¯åŠ¨æˆåŠŸ")
    else:
        print("=== æœåŠ¡è‡ªåŠ¨å¯åŠ¨å¤±è´¥ ===")
        logger.error("æœåŠ¡è‡ªåŠ¨å¯åŠ¨å¤±è´¥")

# é¡¶éƒ¨å·¥å…·æ 
col1, col2, col3, col4 = st.columns([2, 1, 1, 1])
with col1:
    st.title("ğŸ“„ åˆåŒå®¡æŸ¥ç³»ç»Ÿ")
with col2:
    if st.button("ğŸš€ å¯åŠ¨æœåŠ¡", help="å¯åŠ¨æ‰€æœ‰åå°æœåŠ¡"):
        if start_all_services():
            st.success("æ‰€æœ‰æœåŠ¡å¯åŠ¨æˆåŠŸï¼")
        else:
            st.error("æœåŠ¡å¯åŠ¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
with col3:
    if st.button("ğŸ”§ æœåŠ¡çŠ¶æ€", help="æ£€æŸ¥æœåŠ¡çŠ¶æ€"):
        status = check_services()
        for name, ok in status.items():
            st.write(f"{name.upper()}: {'âœ…' if ok else 'âŒ'}")
        if not all(status.values()):
            st.warning("éƒ¨åˆ†æœåŠ¡æœªå°±ç»ª")
with col4:
    if st.button("â¹ï¸ åœæ­¢æœåŠ¡", help="åœæ­¢æ‰€æœ‰åå°æœåŠ¡"):
        stop_all_services()
        st.info("æ‰€æœ‰æœåŠ¡å·²åœæ­¢")

# æ–‡ä»¶é€‰æ‹©åŒºåŸŸ
st.subheader("ğŸ“ é€‰æ‹©åˆåŒæ–‡ä»¶")

# åˆ›å»ºé€‰é¡¹å¡
tab1, tab2 = st.tabs(["ğŸ“¤ ä¸Šä¼ æ–‡ä»¶", "ğŸ“‹ é€‰æ‹©æ ·ä¾‹"])

with tab1:
    uploaded = st.file_uploader("ä¸Šä¼ åˆåŒæ–‡ä»¶ (PDF/DOCX/TXT/DOC)", type=["pdf", "docx", "txt", "doc"])

with tab2:
    sample_files = get_sample_files()
    if sample_files:
        st.write("ä»ä»¥ä¸‹æ ·ä¾‹æ–‡ä»¶ä¸­é€‰æ‹©ä¸€ä¸ªè¿›è¡Œæµ‹è¯•ï¼š")
        
        # æ˜¾ç¤ºæ ·ä¾‹æ–‡ä»¶åˆ—è¡¨
        for i, sample_path in enumerate(sample_files):
            file_name = os.path.basename(sample_path)
            col1, col2, col3 = st.columns([3, 1, 1])
            
            with col1:
                st.write(f"ğŸ“„ {file_name}")
            
            with col2:
                if st.button(f"é¢„è§ˆ", key=f"preview_{i}"):
                    preview_content = preview_file_content(sample_path)
                    st.session_state.sample_preview = preview_content
                    st.session_state.sample_file_name = file_name
            
            with col3:
                if st.button(f"é€‰æ‹©", key=f"select_{i}", type="primary"):
                    # å¤åˆ¶æ ·ä¾‹æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
                    temp_path = copy_sample_file(sample_path)
                    if temp_path:
                        st.session_state.saved_file_path = temp_path
                        st.session_state.file_name = file_name
                        st.session_state.preview_content = preview_file_content(temp_path)
                        st.session_state.selected_sample = sample_path
                        st.success(f"å·²é€‰æ‹©æ ·ä¾‹æ–‡ä»¶: {file_name}")
                        st.rerun()
                    else:
                        st.error("é€‰æ‹©æ ·ä¾‹æ–‡ä»¶å¤±è´¥")
        
        # æ˜¾ç¤ºé¢„è§ˆå†…å®¹
        if hasattr(st.session_state, 'sample_preview'):
            st.divider()
            st.write(f"**{st.session_state.sample_file_name} é¢„è§ˆ:**")
            st.text_area("æ–‡ä»¶å†…å®¹", st.session_state.sample_preview, height=300, disabled=True)
    else:
        st.info("contracts ç›®å½•ä¸‹æ²¡æœ‰æ‰¾åˆ°æ ·ä¾‹æ–‡ä»¶")
        st.write("è¯·å°†æ ·ä¾‹æ–‡ä»¶æ”¾åœ¨ `contracts/` ç›®å½•ä¸‹ï¼Œæ”¯æŒæ ¼å¼ï¼šPDF, DOCX, TXT, DOC")

# åˆå§‹åŒ–session state
if 'analysis_result' not in st.session_state:
    st.session_state.analysis_result = None
if 'selected_risk_level' not in st.session_state:
    st.session_state.selected_risk_level = "å…¨éƒ¨"

# æ–‡ä»¶é¢„è§ˆå’Œä¿å­˜
if uploaded:
    saved_path = save_uploaded_file(uploaded)
    if saved_path:
        st.session_state.saved_file_path = saved_path
        st.session_state.file_name = uploaded.name
        st.session_state.preview_content = preview_file_content(saved_path)
        # æ¸…é™¤æ ·ä¾‹é€‰æ‹©çŠ¶æ€
        if hasattr(st.session_state, 'selected_sample'):
            del st.session_state.selected_sample
    else:
        st.error("ä¿å­˜æ–‡ä»¶å¤±è´¥")

# è¿è¡Œåˆ†ææŒ‰é’®
has_file = uploaded or hasattr(st.session_state, 'saved_file_path')
if has_file and st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary", use_container_width=True):
    saved_path = st.session_state.get('saved_file_path')
    if not saved_path:
        st.error("æ–‡ä»¶è·¯å¾„ä¸¢å¤±ï¼Œè¯·é‡æ–°é€‰æ‹©æ–‡ä»¶")
        st.stop()

    with st.spinner("æ­£åœ¨åˆ†æï¼Œè¯·ç¨å€™..."):
        result = call_processor_pipeline(saved_path)
    
    if "error" in result:
        st.error(result["error"])
    else:
        st.session_state.analysis_result = result
        st.success("åˆ†æå®Œæˆï¼")

# ä¸»ç•Œé¢å¸ƒå±€
if st.session_state.analysis_result:
    result = st.session_state.analysis_result
    
    # å·¦å³åˆ†æ å¸ƒå±€
    col_left, col_right = st.columns([1, 1])
    
    with col_left:
        st.subheader(f"ğŸ“„ {st.session_state.file_name}")
        
        # æ˜¾ç¤ºåˆåŒå†…å®¹ï¼ˆå¸¦é«˜äº®ï¼‰
        contract_text = st.session_state.preview_content
        issues = result.get("issues", [])
        
        # ä¸ºé—®é¢˜æ·»åŠ é«˜äº®æ ‡è®°
        highlighted_text = add_highlights_to_text(contract_text, issues)
        
        # æ˜¾ç¤ºé«˜äº®åçš„æ–‡æœ¬
        st.markdown(highlighted_text, unsafe_allow_html=True)
    
    with col_right:
        st.subheader("ğŸ” å®¡æŸ¥ç»“æœ")
        
        # é£é™©ç­‰çº§ç­›é€‰
        risk_levels = ["å…¨éƒ¨", "é‡å¤§é£é™©", "ä¸€èˆ¬é£é™©", "ä½é£é™©"]
        selected_level = st.radio("é£é™©ç­‰çº§", risk_levels, horizontal=True, 
                                index=risk_levels.index(st.session_state.selected_risk_level))
        st.session_state.selected_risk_level = selected_level
        
        # æ˜¾ç¤ºé—®é¢˜åˆ—è¡¨
        filtered_issues = filter_issues_by_risk(issues, selected_level)
        
        if filtered_issues:
            for i, issue in enumerate(filtered_issues):
                risk_level = issue.get("é£é™©ç­‰çº§", "ä½")
                risk_color = {"é«˜": "ğŸ”´", "ä¸­": "ğŸŸ¡", "ä½": "ğŸŸ¢"}.get(risk_level, "âšª")
                
                with st.expander(f"{risk_color} {issue.get('ç±»å‹', 'æœªçŸ¥ç±»å‹')} - {risk_level}é£é™©", expanded=False):
                    st.write(f"**æ¡æ¬¾:** {issue.get('æ¡æ¬¾', 'N/A')}")
                    st.write(f"**é—®é¢˜æè¿°:** {issue.get('é—®é¢˜æè¿°', 'N/A')}")
                    
                    if issue.get("æ³•å¾‹ä¾æ®"):
                        st.write(f"**æ³•å¾‹ä¾æ®:** {issue['æ³•å¾‹ä¾æ®']}")
                    if issue.get("å½±å“åˆ†æ"):
                        st.write(f"**å½±å“åˆ†æ:** {issue['å½±å“åˆ†æ']}")
                    if issue.get("å•†ä¸šä¼˜åŒ–"):
                        st.write(f"**å•†ä¸šä¼˜åŒ–:** {issue['å•†ä¸šä¼˜åŒ–']}")
                    
                    st.write(f"**ä¿®æ”¹å»ºè®®:** {issue.get('ä¿®æ”¹å»ºè®®', 'N/A')}")
        else:
            st.info("æœªå‘ç°é—®é¢˜")
        
        # ä¸‹è½½æŒ‰é’®
        st.divider()
        json_bytes = json.dumps(result, ensure_ascii=False, indent=2).encode("utf-8")
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½ç»“æœ",
            data=json_bytes,
            file_name=f"contract_analysis_{int(time.time())}.json",
            mime="application/json",
            use_container_width=True,
        )
        
        # ç”Ÿæˆé«˜äº®æ–‡ä»¶
        if st.button("ğŸ¨ ç”Ÿæˆé«˜äº®æ–‡æ¡£", use_container_width=True):
            with st.spinner("æ­£åœ¨ç”Ÿæˆé«˜äº®æ–‡ä»¶..."):
                highlight = call_highlight(result["file_path"], result.get("issues", []))
            if not highlight or (isinstance(highlight, dict) and highlight.get("error")):
                st.error("é«˜äº®ç”Ÿæˆå¤±è´¥")
            else:
                file_type = highlight.get("file_type", "pdf")
                file_name = highlight.get("file_name", f"highlighted_contract.{file_type}")
                content_b64 = highlight.get("content", "")
                mime = "application/pdf" if file_type == "pdf" else "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                if content_b64:
                    b64_to_download(content_b64, file_name, mime)
                    st.success("é«˜äº®æ–‡æ¡£ç”ŸæˆæˆåŠŸï¼")

else:
    # æœªåˆ†ææ—¶çš„ç•Œé¢
    if has_file:
        st.info("è¯·ç‚¹å‡»'å¼€å§‹åˆ†æ'æŒ‰é’®è¿›è¡ŒåˆåŒå®¡æŸ¥")
        
        # æ˜¾ç¤ºæ–‡ä»¶é¢„è§ˆ
        with st.expander("ğŸ“„ æ–‡ä»¶é¢„è§ˆ", expanded=True):
            st.text_area("æ–‡ä»¶å†…å®¹", st.session_state.get('preview_content', ''), height=400, disabled=True)
    else:
        st.info("è¯·ä¸Šä¼ åˆåŒæ–‡ä»¶æˆ–é€‰æ‹©æ ·ä¾‹æ–‡ä»¶å¼€å§‹åˆ†æ")


