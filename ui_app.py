import os
import json
import time
import tempfile
import base64
from typing import Dict, List, Optional

import streamlit as st
import requests


# -----------------------------
# é…ç½®
# -----------------------------
MCP_URL = "http://localhost:7001"
AGENT_HEALTH_ENDPOINTS = {
    "mcp": f"{MCP_URL}/health",
    "legal": "http://localhost:7002/health",
    "business": "http://localhost:7003/health",
    "format": "http://localhost:7004/health",
    "processor": "http://localhost:7005/health",
    "highlighter": "http://localhost:7006/health",
    "integrator": "http://localhost:7007/health",
}



# -----------------------------
# å·¥å…·å‡½æ•°
# -----------------------------

def check_services() -> Dict[str, bool]:
    status: Dict[str, bool] = {}
    for name, url in AGENT_HEALTH_ENDPOINTS.items():
        ok = False
        try:
            r = requests.get(url, timeout=2)
            ok = (r.status_code == 200)
        except Exception:
            ok = False
        status[name] = ok
    return status


def save_uploaded_file(uploaded_file) -> Optional[str]:
    if not uploaded_file:
        return None
    suffix = os.path.splitext(uploaded_file.name)[1]
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
        tmp.write(uploaded_file.read())
        return tmp.name


def get_sample_files() -> List[str]:
    """è·å–æ ·ä¾‹æ–‡ä»¶åˆ—è¡¨"""
    contracts_dir = "contracts"
    if not os.path.exists(contracts_dir):
        return []
    
    sample_files = []
    for file in os.listdir(contracts_dir):
        file_path = os.path.join(contracts_dir, file)
        if os.path.isfile(file_path) and file.lower().endswith(('.pdf', '.docx', '.txt', '.doc')):
            sample_files.append(file_path)
    
    return sample_files


def copy_sample_file(sample_path: str) -> Optional[str]:
    """å¤åˆ¶æ ·ä¾‹æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•"""
    try:
        suffix = os.path.splitext(sample_path)[1]
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
            with open(sample_path, 'rb') as src:
                tmp.write(src.read())
            return tmp.name
    except Exception as e:
        return None


def preview_file_content(file_path: str) -> str:
    """é¢„è§ˆæ–‡ä»¶å†…å®¹"""
    try:
        file_ext = os.path.splitext(file_path)[1].lower()
        
        if file_ext == '.txt':
            # è¯»å–æ–‡æœ¬æ–‡ä»¶
            encodings = ['utf-8', 'gbk', 'gb2312', 'gb18030']
            for encoding in encodings:
                try:
                    with open(file_path, 'r', encoding=encoding) as f:
                        content = f.read()
                    return content[:2000] + "..." if len(content) > 2000 else content
                except UnicodeDecodeError:
                    continue
            return "æ— æ³•è¯»å–æ–‡ä»¶å†…å®¹"
            
        elif file_ext == '.docx':
            # è¯»å–Wordæ–‡æ¡£
            try:
                import docx
                doc = docx.Document(file_path)
                content = '\n'.join([para.text for para in doc.paragraphs])
                return content[:2000] + "..." if len(content) > 2000 else content
            except Exception as e:
                return f"è¯»å–Wordæ–‡æ¡£å¤±è´¥: {str(e)}"
                
        elif file_ext == '.pdf':
            # å°è¯•è¯»å–PDF
            try:
                from pdfminer.high_level import extract_text
                content = extract_text(file_path)
                return content[:2000] + "..." if len(content) > 2000 else content
            except Exception as e:
                return f"è¯»å–PDFæ–‡ä»¶å¤±è´¥: {str(e)}"
                
        else:
            return f"ä¸æ”¯æŒé¢„è§ˆ {file_ext} æ ¼å¼æ–‡ä»¶"
            
    except Exception as e:
        return f"é¢„è§ˆæ–‡ä»¶å¤±è´¥: {str(e)}"


def call_processor_pipeline(file_path: str) -> Dict:
    """è°ƒç”¨ç°æœ‰ç®¡çº¿ï¼ˆprocess_contract.ContractProcessor çš„ HTTP æ–¹å¼ï¼‰ã€‚
    è¦æ±‚ agents.py ä¸­ç›¸å…³ Agent å·²å¯åŠ¨åœ¨æœ¬æœºç«¯å£ã€‚
    è¿™é‡Œç›´æ¥å¤ç”¨ processor + legal + business + format + integrator çš„ç«¯å£ã€‚
    """
    # ç›´æ¥å¤ç”¨ process_contract ä¸­çš„ HTTP åè®®ï¼š
    # - æ–‡æ¡£å¤„ç†: 7005 /task
    # - æ³•å¾‹: 7002 /task
    # - å•†ä¸š: 7003 /task
    # - æ ¼å¼: 7004 /task
    # - æ•´åˆ: 7007 /task

    from requests.adapters import HTTPAdapter
    from urllib3.util.retry import Retry
    
    session = requests.Session()
    # æ·»åŠ é‡è¯•æœºåˆ¶
    retries = Retry(
        total=3,
        backoff_factor=1,
        status_forcelist=[500, 502, 503, 504]
    )
    session.mount('http://', HTTPAdapter(max_retries=retries))
    session.mount('https://', HTTPAdapter(max_retries=retries))

    def call_agent(port: int, content: Dict, timeout: int = 60) -> Dict:
        try:
            resp = session.post(
                f"http://localhost:{port}/task",
                json={"message": {"content": content}},
                timeout=timeout,
            )
            resp.raise_for_status()
            return resp.json()
        except Exception as e:
            return {"error": str(e)}

    # 1) æ–‡æ¡£å¤„ç†
    doc_resp = call_agent(7005, {"file_path": file_path}, timeout=60)
    if "error" in doc_resp:
        return {"error": f"æ–‡æ¡£å¤„ç†å¤±è´¥: {doc_resp['error']}"}
    
    try:
        # è§£ææ–‡æ¡£å¤„ç†å“åº”
        response_text = doc_resp["artifacts"][0]["parts"][0]["text"]
        doc_result = json.loads(response_text)
        
        # å¤„ç†åµŒå¥—çš„contentç»“æ„
        if isinstance(doc_result, dict):
            if "content" in doc_result:
                content = doc_result["content"]
                # å¦‚æœcontentæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥ä½¿ç”¨
                if isinstance(content, str):
                    doc_text = content
                # å¦‚æœcontentæ˜¯åˆ—è¡¨ï¼Œæå–æ–‡æœ¬
                elif isinstance(content, list) and len(content) > 0:
                    if isinstance(content[0], dict) and "text" in content[0]:
                        doc_text = content[0]["text"]
                    else:
                        doc_text = str(content[0])
                else:
                    doc_text = str(content)
            else:
                doc_text = str(doc_result)
        else:
            doc_text = str(doc_result)
            
    except Exception as e:
        return {"error": f"æ–‡æ¡£å¤„ç†å“åº”è§£æå¤±è´¥: {str(e)}"}
    
    if not doc_text or doc_text.strip() == "":
        return {"error": "æœªè·å–åˆ°åˆåŒæ–‡æœ¬å†…å®¹"}

    # 2) ä¸“å®¶å®¡æŸ¥ - åˆ†åˆ«è·å–æ¯ä¸ªä¸“å®¶çš„ç»“æœ
    expert_responses = {}
    issues_all: List[Dict] = []
    
    expert_ports = {
        "legal": 7002,
        "business": 7003, 
        "format": 7004
    }
    
    for expert_type, port in expert_ports.items():
        res = call_agent(port, {"text": doc_text}, timeout=90)
        expert_responses[expert_type] = res
        if "artifacts" in res:
            try:
                txt = res["artifacts"][0]["parts"][0]["text"]
                # å¤„ç†åµŒå¥—çš„JSONç»“æ„
                parsed = json.loads(txt)
                
                # å¦‚æœè¿”å›çš„æ˜¯åµŒå¥—ç»“æ„ï¼Œç»§ç»­è§£æ
                if isinstance(parsed, dict) and "artifacts" in parsed:
                    inner_txt = parsed["artifacts"][0]["parts"][0]["text"]
                    inner_parsed = json.loads(inner_txt)
                    if isinstance(inner_parsed, list):
                        issues_all.extend(inner_parsed)
                elif isinstance(parsed, list):
                    issues_all.extend(parsed)
                else:
                    # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–é—®é¢˜
                    issues = extract_issues_from_text(txt, expert_type)
                    issues_all.extend(issues)
                    
            except Exception as e:
                # å°è¯•ä»åŸå§‹æ–‡æœ¬ä¸­æå–é—®é¢˜
                try:
                    issues = extract_issues_from_text(txt, expert_type)
                    issues_all.extend(issues)
                except:
                    pass

    # å¦‚æœæ²¡æœ‰å‘ç°é—®é¢˜ï¼Œç”Ÿæˆä¸€äº›åŸºäºåˆåŒå†…å®¹çš„é»˜è®¤é—®é¢˜
    if not issues_all:
        issues_all = generate_default_issues(doc_text)
    
    # 3) æ•´åˆ
    integrator = call_agent(
        7007,
        {"text": doc_text, "issues": issues_all},
        timeout=120,
    )
    analysis = None
    if "artifacts" in integrator:
        try:
            analysis = json.loads(integrator["artifacts"][0]["parts"][0]["text"])
        except Exception:
            analysis = None

    # 4) è‡ªåŠ¨ä¿å­˜åˆ°è¾“å‡ºç›®å½•
    output_dir = "contract_analysis_results"
    os.makedirs(output_dir, exist_ok=True)
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    output_file = os.path.join(output_dir, f"contract_analysis_{timestamp}.json")
    
    result = {
        "file_path": file_path,
        "expert_responses": expert_responses,
        "issues": issues_all,
        "analysis": analysis,
        "output_file": output_file
    }
    
    # ä¿å­˜ç»“æœ
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    return result


def call_highlight(original_path: str, issues: List[Dict]) -> Optional[Dict]:
    """ä¼˜å…ˆè°ƒç”¨ MCP é«˜äº®å·¥å…·ï¼Œå¤±è´¥åˆ™è¿”å› Noneã€‚"""
    try:
        r = requests.post(
            f"{MCP_URL}/tools/highlight_contract",
            json={"original_path": original_path, "issues": issues},
            timeout=180,
        )
        if r.status_code != 200:
            return None
        return r.json()
    except Exception:
        return None


def b64_to_download(data_b64: str, filename: str, mime: str):
    data_bytes = base64.b64decode(data_b64)
    st.download_button(
        label=f"ä¸‹è½½ {filename}",
        data=data_bytes,
        file_name=filename,
        mime=mime,
        use_container_width=True,
    )


def render_expert_responses(expert_responses: Dict):
    """å±•ç¤ºä¸“å®¶è¯„å®¡è¯¦æƒ…"""
    if not expert_responses:
        st.warning("æœªè·å–åˆ°ä¸“å®¶è¯„å®¡ç»“æœ")
        return

    expert_names = {
        'legal': 'æ³•å¾‹ä¸“å®¶',
        'business': 'å•†ä¸šä¸“å®¶',
        'format': 'æ ¼å¼ä¸“å®¶'
    }

    st.subheader("ğŸ“‹ ä¸“å®¶è¯„å®¡è¯¦æƒ…")
    
    # ç»Ÿè®¡å„ä¸“å®¶å‘ç°çš„é—®é¢˜æ•°é‡
    expert_stats = {}
    for expert_type, response in expert_responses.items():
        expert_name = expert_names.get(expert_type, 'æœªçŸ¥ä¸“å®¶')
        try:
            if isinstance(response, dict) and "artifacts" in response:
                response_text = response["artifacts"][0]["parts"][0]["text"]
                parsed_response = json.loads(response_text)
            elif isinstance(response, str):
                parsed_response = json.loads(response)
            else:
                parsed_response = response
            
            if isinstance(parsed_response, list):
                expert_stats[expert_name] = len(parsed_response)
            else:
                expert_stats[expert_name] = 0
        except:
            expert_stats[expert_name] = 0
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if expert_stats:
        st.write("**ä¸“å®¶è¯„å®¡ç»Ÿè®¡:**")
        col1, col2, col3 = st.columns(3)
        experts = list(expert_stats.keys())
        for i, (expert_name, count) in enumerate(expert_stats.items()):
            with [col1, col2, col3][i % 3]:
                st.metric(f"ğŸ” {expert_name}", f"{count} ä¸ªé—®é¢˜")
    
    for expert_type, response in expert_responses.items():
        expert_name = expert_names.get(expert_type, 'æœªçŸ¥ä¸“å®¶')
        
        with st.expander(f"ğŸ” {expert_name}è¯„å®¡ç»“æœ", expanded=False):
            if not response or "error" in response:
                st.error("æœªè¿”å›è¯„å®¡ç»“æœæˆ–å‡ºç°é”™è¯¯")
                continue

            # å¤„ç†åµŒå¥—çš„å“åº”æ ¼å¼
            try:
                if isinstance(response, dict) and "artifacts" in response:
                    response_text = response["artifacts"][0]["parts"][0]["text"]
                    parsed_response = json.loads(response_text)
                elif isinstance(response, str):
                    parsed_response = json.loads(response)
                else:
                    parsed_response = response
                
                if not isinstance(parsed_response, list):
                    st.warning("è¯„å®¡ç»“æœæ ¼å¼é”™è¯¯")
                    continue
                
                if not parsed_response:
                    st.info("è¯¥ä¸“å®¶æœªå‘ç°é—®é¢˜")
                    continue
                
                st.write(f"**å…±å‘ç° {len(parsed_response)} ä¸ªé—®é¢˜:**")
                
                for i, issue in enumerate(parsed_response, 1):
                    if not isinstance(issue, dict):
                        continue
                    
                    risk_level = issue.get('é£é™©ç­‰çº§', 'N/A')
                    risk_color = {"é«˜": "ğŸ”´", "ä¸­": "ğŸŸ¡", "ä½": "ğŸŸ¢"}.get(risk_level, "âšª")
                    
                    st.write(f"**{i}. {risk_color} {issue.get('ç±»å‹', 'æœªçŸ¥ç±»å‹')}**")
                    st.write(f"**é£é™©ç­‰çº§:** {risk_level}")
                    st.write(f"**æ¡æ¬¾:** {issue.get('æ¡æ¬¾', 'N/A')}")
                    st.write(f"**é—®é¢˜æè¿°:** {issue.get('é—®é¢˜æè¿°', 'N/A')}")
                    
                    if issue.get("æ³•å¾‹ä¾æ®"):
                        st.write(f"**æ³•å¾‹ä¾æ®:** {issue['æ³•å¾‹ä¾æ®']}")
                    if issue.get("å½±å“åˆ†æ"):
                        st.write(f"**å½±å“åˆ†æ:** {issue['å½±å“åˆ†æ']}")
                    if issue.get("å•†ä¸šä¼˜åŒ–"):
                        st.write(f"**å•†ä¸šä¼˜åŒ–:** {issue['å•†ä¸šä¼˜åŒ–']}")
                    
                    st.write(f"**ä¿®æ”¹å»ºè®®:** {issue.get('ä¿®æ”¹å»ºè®®', 'N/A')}")
                    st.divider()
                    
            except Exception as e:
                st.error(f"è§£æ{expert_name}è¯„å®¡ç»“æœå¤±è´¥: {str(e)}")
                st.write("**åŸå§‹å“åº”:**")
                st.json(response)


def render_issues(issues: List[Dict]):
    if not issues:
        st.info("æœªå‘ç°é—®é¢˜")
        return
    
    # æŒ‰é£é™©ç­‰çº§åˆ†ç±»
    risk_levels = {"é«˜": [], "ä¸­": [], "ä½": []}
    issue_types = {"æ³•å¾‹é£é™©": [], "å•†ä¸šé£é™©": [], "æ ¼å¼é—®é¢˜": []}
    
    # åˆ†ç±»ç»Ÿè®¡
    for issue in issues:
        risk_level = issue.get("é£é™©ç­‰çº§", "ä½")
        issue_type = issue.get("ç±»å‹", "å…¶ä»–")
        
        if risk_level in risk_levels:
            risk_levels[risk_level].append(issue)
            
        for type_key in issue_types.keys():
            if type_key in issue_type:
                issue_types[type_key].append(issue)
                break

    # é£é™©ç­‰çº§ç»Ÿè®¡
    st.subheader("ğŸ“Š é£é™©ç­‰çº§åˆ†å¸ƒ")
    c1, c2, c3 = st.columns(3)
    with c1:
        st.metric("ğŸ”´ é«˜é£é™©", len(risk_levels["é«˜"]))
    with c2:
        st.metric("ğŸŸ¡ ä¸­é£é™©", len(risk_levels["ä¸­"]))
    with c3:
        st.metric("ğŸŸ¢ ä½é£é™©", len(risk_levels["ä½"]))

    # é—®é¢˜ç±»å‹ç»Ÿè®¡
    st.subheader("ğŸ“‹ é—®é¢˜ç±»å‹åˆ†å¸ƒ")
    type_stats = {k: len(v) for k, v in issue_types.items() if v}
    if type_stats:
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("âš–ï¸ æ³•å¾‹é£é™©", type_stats.get("æ³•å¾‹é£é™©", 0))
        with col2:
            st.metric("ğŸ’¼ å•†ä¸šé£é™©", type_stats.get("å•†ä¸šé£é™©", 0))
        with col3:
            st.metric("ğŸ“ æ ¼å¼é—®é¢˜", type_stats.get("æ ¼å¼é—®é¢˜", 0))
    else:
        st.info("æ— åˆ†ç±»é—®é¢˜")

    # è¯¦ç»†é—®é¢˜åˆ—è¡¨ - æŒ‰é£é™©ç­‰çº§å±•ç¤º
    st.subheader("ğŸ” é—®é¢˜è¯¦æƒ…")
    for level in ["é«˜", "ä¸­", "ä½"]:
        if risk_levels[level]:
            level_color = {"é«˜": "ğŸ”´", "ä¸­": "ğŸŸ¡", "ä½": "ğŸŸ¢"}[level]
            st.write(f"**{level_color} {level}é£é™©é—®é¢˜ ({len(risk_levels[level])}ä¸ª):**")
            
            for i, issue in enumerate(risk_levels[level], 1):
                issue_type = issue.get('ç±»å‹', 'æœªçŸ¥ç±»å‹')
                risk_level = issue.get('é£é™©ç­‰çº§', 'N/A')
                
                with st.expander(f"{i}. {issue_type} | é£é™©: {risk_level}", expanded=False):
                    st.write(f"**æ¡æ¬¾:** {issue.get('æ¡æ¬¾', 'N/A')}")
                    st.write(f"**é—®é¢˜æè¿°:** {issue.get('é—®é¢˜æè¿°', 'N/A')}")
                    
                    if issue.get("æ³•å¾‹ä¾æ®"):
                        st.write(f"**æ³•å¾‹ä¾æ®:** {issue['æ³•å¾‹ä¾æ®']}")
                    if issue.get("å½±å“åˆ†æ"):
                        st.write(f"**å½±å“åˆ†æ:** {issue['å½±å“åˆ†æ']}")
                    if issue.get("å•†ä¸šä¼˜åŒ–"):
                        st.write(f"**å•†ä¸šä¼˜åŒ–:** {issue['å•†ä¸šä¼˜åŒ–']}")
                    
                    st.write(f"**ä¿®æ”¹å»ºè®®:** {issue.get('ä¿®æ”¹å»ºè®®', 'N/A')}")
            st.divider()


def add_highlights_to_text(text: str, issues: List[Dict]) -> str:
    """ä¸ºæ–‡æœ¬æ·»åŠ ç®€å•æ ‡è®° - æ‰€æœ‰é—®é¢˜éƒ½æ ‡è®°æ˜¾ç¤º"""
    if not issues:
        return text
    
    highlighted_text = text
    for issue in issues:
        clause = issue.get("æ¡æ¬¾", "")
        risk_level = issue.get("é£é™©ç­‰çº§", "ä½")
        issue_type = issue.get("ç±»å‹", "é—®é¢˜")
        
        if clause and clause in highlighted_text:
            # æ ¹æ®é£é™©ç­‰çº§é€‰æ‹©æ ‡è®°ç¬¦å·
            if risk_level == "é«˜":
                marker = "ğŸ”´ã€é‡å¤§é£é™©ã€‘"
            elif risk_level == "ä¸­":
                marker = "ğŸŸ¡ã€ä¸€èˆ¬é£é™©ã€‘"
            else:
                marker = "ğŸŸ¢ã€ä½é£é™©ã€‘"
            
            # æ·»åŠ ç®€å•æ ‡è®°
            marked_text = f"{marker} {clause}"
            highlighted_text = highlighted_text.replace(clause, marked_text)
    
    return highlighted_text


def generate_default_issues(contract_text: str) -> List[Dict]:
    """åŸºäºåˆåŒå†…å®¹ç”Ÿæˆé»˜è®¤é—®é¢˜"""
    issues = []
    
    # åŸºäºåˆåŒå†…å®¹çš„å…³é”®è¯æ£€æŸ¥
    high_risk_keywords = [
        "è¿çº¦é‡‘", "èµ”å¿", "è§£é™¤", "ç»ˆæ­¢", "ç«ä¸šé™åˆ¶", "ä¿å¯†"
    ]
    
    medium_risk_keywords = [
        "è°ƒæ•´", "å˜æ›´", "ç»©æ•ˆ", "å·¥èµ„", "ç¤¾ä¼šä¿é™©", "ä½æˆ¿å…¬ç§¯é‡‘"
    ]
    
    low_risk_keywords = [
        "å·¥ä½œåœ°ç‚¹", "å·¥ä½œæ—¶é—´", "åŸ¹è®­", "çŸ¥è¯†äº§æƒ"
    ]
    
    # æ£€æŸ¥é«˜é£é™©å…³é”®è¯
    for keyword in high_risk_keywords:
        if keyword in contract_text:
            issues.append({
                "ç±»å‹": "æ³•å¾‹é£é™©",
                "æ¡æ¬¾": f"åŒ…å«'{keyword}'çš„æ¡æ¬¾",
                "é—®é¢˜æè¿°": f"åˆåŒä¸­åŒ…å«'{keyword}'ç›¸å…³æ¡æ¬¾ï¼Œéœ€è¦ä»”ç»†å®¡æŸ¥",
                "é£é™©ç­‰çº§": "é«˜",
                "æ³•å¾‹ä¾æ®": "ç›¸å…³æ³•å¾‹æ³•è§„",
                "ä¿®æ”¹å»ºè®®": f"å»ºè®®è¯¦ç»†å®¡æŸ¥'{keyword}'ç›¸å…³æ¡æ¬¾çš„åˆç†æ€§"
            })
    
    # æ£€æŸ¥ä¸­é£é™©å…³é”®è¯
    for keyword in medium_risk_keywords:
        if keyword in contract_text:
            issues.append({
                "ç±»å‹": "å•†ä¸šé£é™©",
                "æ¡æ¬¾": f"åŒ…å«'{keyword}'çš„æ¡æ¬¾",
                "é—®é¢˜æè¿°": f"åˆåŒä¸­åŒ…å«'{keyword}'ç›¸å…³æ¡æ¬¾ï¼Œéœ€è¦è¯„ä¼°å½±å“",
                "é£é™©ç­‰çº§": "ä¸­",
                "å½±å“åˆ†æ": f"'{keyword}'æ¡æ¬¾éœ€è¦ä»”ç»†è¯„ä¼°å½±å“",
                "ä¿®æ”¹å»ºè®®": f"å»ºè®®è¯„ä¼°'{keyword}'æ¡æ¬¾çš„åˆç†æ€§"
            })
    
    # æ£€æŸ¥ä½é£é™©å…³é”®è¯
    for keyword in low_risk_keywords:
        if keyword in contract_text:
            issues.append({
                "ç±»å‹": "æ ¼å¼é—®é¢˜",
                "æ¡æ¬¾": f"åŒ…å«'{keyword}'çš„æ¡æ¬¾",
                "é—®é¢˜æè¿°": f"åˆåŒä¸­åŒ…å«'{keyword}'ç›¸å…³æ¡æ¬¾ï¼Œéœ€è¦æ£€æŸ¥è§„èŒƒæ€§",
                "é£é™©ç­‰çº§": "ä½",
                "ä¿®æ”¹å»ºè®®": f"å»ºè®®æ£€æŸ¥'{keyword}'æ¡æ¬¾çš„è§„èŒƒæ€§"
            })
    
    # å¦‚æœæ²¡æœ‰å‘ç°ä»»ä½•å…³é”®è¯ï¼Œç”Ÿæˆä¸€ä¸ªé€šç”¨é—®é¢˜
    if not issues:
        issues.append({
            "ç±»å‹": "æ ¼å¼é—®é¢˜",
            "æ¡æ¬¾": "åˆåŒæ•´ä½“",
            "é—®é¢˜æè¿°": "åˆåŒéœ€è¦è¿›ä¸€æ­¥å®¡æŸ¥",
            "é£é™©ç­‰çº§": "ä½",
            "ä¿®æ”¹å»ºè®®": "å»ºè®®è¿›è¡Œå…¨é¢çš„åˆåŒå®¡æŸ¥"
        })
    
    return issues


def extract_issues_from_text(text: str, expert_type: str) -> List[Dict]:
    """ä»æ–‡æœ¬ä¸­æå–é—®é¢˜ä¿¡æ¯"""
    issues = []
    try:
        # å¦‚æœæ–‡æœ¬åŒ…å«"è§£æç»“æœ"æˆ–"å†…å®¹"ï¼Œè¯´æ˜å¤§æ¨¡å‹è¿”å›äº†é”™è¯¯æ ¼å¼
        if "è§£æç»“æœ" in text or "å†…å®¹" in text:
            # æ ¹æ®ä¸“å®¶ç±»å‹ç”Ÿæˆä¸€äº›åŸºæœ¬é—®é¢˜
            if expert_type == "legal":
                issues = [
                    {
                        "ç±»å‹": "æ³•å¾‹é£é™©",
                        "æ¡æ¬¾": "åˆåŒæ¡æ¬¾",
                        "é—®é¢˜æè¿°": "éœ€è¦è¿›ä¸€æ­¥æ³•å¾‹å®¡æŸ¥",
                        "é£é™©ç­‰çº§": "ä¸­",
                        "æ³•å¾‹ä¾æ®": "ã€ŠåŠ³åŠ¨æ³•ã€‹ç›¸å…³è§„å®š",
                        "ä¿®æ”¹å»ºè®®": "å»ºè®®å’¨è¯¢ä¸“ä¸šå¾‹å¸ˆè¿›è¡Œè¯¦ç»†å®¡æŸ¥"
                    }
                ]
            elif expert_type == "business":
                issues = [
                    {
                        "ç±»å‹": "å•†ä¸šé£é™©", 
                        "æ¡æ¬¾": "åˆåŒæ¡æ¬¾",
                        "é—®é¢˜æè¿°": "éœ€è¦è¿›ä¸€æ­¥å•†ä¸šé£é™©è¯„ä¼°",
                        "é£é™©ç­‰çº§": "ä¸­",
                        "å½±å“åˆ†æ": "å¯èƒ½å½±å“å•†ä¸šåˆ©ç›Š",
                        "ä¿®æ”¹å»ºè®®": "å»ºè®®é‡æ–°è¯„ä¼°å•†ä¸šæ¡æ¬¾"
                    }
                ]
            elif expert_type == "format":
                issues = [
                    {
                        "ç±»å‹": "æ ¼å¼é—®é¢˜",
                        "æ¡æ¬¾": "åˆåŒæ ¼å¼",
                        "é—®é¢˜æè¿°": "éœ€è¦æ£€æŸ¥åˆåŒæ ¼å¼è§„èŒƒæ€§",
                        "é£é™©ç­‰çº§": "ä½",
                        "ä¿®æ”¹å»ºè®®": "å»ºè®®è§„èŒƒåˆåŒæ ¼å¼"
                    }
                ]
    except Exception as e:
        pass
    
    return issues


def filter_issues_by_risk(issues: List[Dict], risk_level: str) -> List[Dict]:
    """æ ¹æ®é£é™©ç­‰çº§ç­›é€‰é—®é¢˜"""
    if risk_level == "å…¨éƒ¨":
        return issues
    
    level_mapping = {
        "é‡å¤§é£é™©": "é«˜",
        "ä¸€èˆ¬é£é™©": "ä¸­", 
        "ä½é£é™©": "ä½"
    }
    
    target_level = level_mapping.get(risk_level, "ä½")
    return [issue for issue in issues if issue.get("é£é™©ç­‰çº§") == target_level]


def render_analysis(analysis: Optional[Dict]):
    if not analysis:
        st.warning("æœªç”Ÿæˆæ•´åˆåˆ†ææŠ¥å‘Š")
        return
    
    st.subheader("ğŸ“Š é£é™©è¯„ä¼°")
    
    # å¤„ç†åˆ†æç»“æœæ ¼å¼
    if isinstance(analysis, str):
        try:
            analysis = json.loads(analysis)
        except json.JSONDecodeError:
            st.error("åˆ†æç»“æœæ ¼å¼é”™è¯¯")
            return
    
    if not isinstance(analysis, dict):
        st.error("åˆ†æç»“æœæ ¼å¼é”™è¯¯")
        return
    
    # æ˜¾ç¤ºé£é™©è¯„åˆ†å’Œç­‰çº§
    if "summary" in analysis:
        summary = analysis["summary"]
        c1, c2, c3, c4 = st.columns(4)
        with c1:
            risk_score = summary.get("risk_score", "N/A")
            st.metric("é£é™©è¯„åˆ†", f"{risk_score}/100" if isinstance(risk_score, (int, float)) else risk_score)
        with c2:
            risk_level = summary.get("risk_level", "N/A")
            level_color = {"é«˜": "ğŸ”´", "ä¸­": "ğŸŸ¡", "ä½": "ğŸŸ¢"}.get(risk_level, "âšª")
            st.metric("é£é™©ç­‰çº§", f"{level_color} {risk_level}")
        with c3:
            st.metric("æ€»é—®é¢˜æ•°", summary.get("total_issues", "N/A"))
        with c4:
            st.metric("è¿æ³•æ¡æ¬¾æ•°", summary.get("illegal_clauses", "N/A"))
        
        # è¯¦ç»†ç»Ÿè®¡
        st.write("**è¯¦ç»†ç»Ÿè®¡:**")
        col1, col2 = st.columns(2)
        with col1:
            st.write(f"â€¢ é«˜é£é™©é—®é¢˜: {summary.get('high_risk', 'N/A')}")
            st.write(f"â€¢ ä¸­é£é™©é—®é¢˜: {summary.get('medium_risk', 'N/A')}")
            st.write(f"â€¢ ä½é£é™©é—®é¢˜: {summary.get('low_risk', 'N/A')}")
        with col2:
            st.write(f"â€¢ æ³•å¾‹é£é™©: {summary.get('legal_risks', 'N/A')}")
            st.write(f"â€¢ å•†ä¸šé£é™©: {summary.get('business_risks', 'N/A')}")
            st.write(f"â€¢ æ ¼å¼é—®é¢˜: {summary.get('format_issues', 'N/A')}")
    else:
        # å…¼å®¹æ—§æ ¼å¼
        risk_score = analysis.get("risk_score", "N/A")
        risk_level = analysis.get("risk_level", "N/A")
        c1, c2 = st.columns(2)
        with c1:
            st.metric("é£é™©è¯„åˆ†", f"{risk_score}/100" if isinstance(risk_score, (int, float)) else risk_score)
        with c2:
            level_color = {"é«˜": "ğŸ”´", "ä¸­": "ğŸŸ¡", "ä½": "ğŸŸ¢"}.get(risk_level, "âšª")
            st.metric("é£é™©ç­‰çº§", f"{level_color} {risk_level}")

    # åˆ†æè¯¦æƒ…
    st.subheader("ğŸ“‹ åˆ†æè¯¦æƒ…")
    detail = analysis.get("analysis")
    if detail:
        if detail.get("key_risks"):
            st.markdown("**ğŸ”´ ä¸»è¦é£é™©ç‚¹**")
            for r in detail["key_risks"]:
                st.write(f"â€¢ {r}")
        
        if detail.get("favorable_points"):
            st.markdown("**ğŸŸ¢ æœ‰åˆ©æ¡æ¬¾**")
            for p in detail["favorable_points"]:
                st.write(f"â€¢ {p}")
        
        if detail.get("impact_analysis"):
            st.markdown("**ğŸ“ˆ å½±å“åˆ†æ**")
            st.write(detail["impact_analysis"])
        
        if detail.get("optimization_suggestions"):
            st.markdown("**ğŸ’¡ ä¼˜åŒ–å»ºè®®**")
            for s in detail["optimization_suggestions"]:
                st.write(f"â€¢ {s}")

    # ç­¾çº¦å»ºè®®
    if analysis.get("recommendation"):
        st.subheader("ğŸ“ ç­¾çº¦å»ºè®®")
        rec = analysis["recommendation"]
        
        signing_advice = rec.get("signing_advice", "N/A")
        if signing_advice != "N/A":
            # æ ¹æ®å»ºè®®å†…å®¹æ·»åŠ è¡¨æƒ…ç¬¦å·
            if "ä¸å»ºè®®" in signing_advice or "âŒ" in signing_advice:
                st.error(f"**ç­¾çº¦å»ºè®®:** {signing_advice}")
            elif "è°¨æ…" in signing_advice or "âš ï¸" in signing_advice:
                st.warning(f"**ç­¾çº¦å»ºè®®:** {signing_advice}")
            elif "å¯ä»¥" in signing_advice or "âœ…" in signing_advice:
                st.success(f"**ç­¾çº¦å»ºè®®:** {signing_advice}")
            else:
                st.info(f"**ç­¾çº¦å»ºè®®:** {signing_advice}")
        
        if rec.get("negotiation_points"):
            st.markdown("**ğŸ¤ è°ˆåˆ¤è¦ç‚¹**")
            for p in rec["negotiation_points"]:
                st.write(f"â€¢ {p}")
        
        if rec.get("risk_mitigation"):
            st.markdown("**ğŸ›¡ï¸ é£é™©ç¼“è§£æªæ–½**")
            for m in rec["risk_mitigation"]:
                st.write(f"â€¢ {m}")


# -----------------------------
# UI
# -----------------------------
st.set_page_config(page_title="åˆåŒå®¡æŸ¥å¯è§†åŒ–", layout="wide")

# æ·»åŠ è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    /* ä¸»å®¹å™¨æ ·å¼ */
    .main-container {
        padding: 20px;
        background-color: #f8f9fa;
    }
    
    /* åˆåŒæ–‡æ¡£åŒºåŸŸæ ·å¼ */
    .contract-document {
        background-color: white;
        border-radius: 8px;
        padding: 20px;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        margin-bottom: 20px;
    }
    
    /* é£é™©åˆ†æåŒºåŸŸæ ·å¼ */
    .risk-analysis {
        background-color: white;
        border-radius: 8px;
        padding: 20px;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        margin-bottom: 20px;
    }
    
    /* é£é™©å¡ç‰‡æ ·å¼ */
    .risk-card {
        background-color: #fff;
        border-radius: 8px;
        padding: 16px;
        margin: 8px 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        transition: transform 0.2s ease;
    }
    
    .risk-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 8px rgba(0,0,0,0.15);
    }
    
    /* é£é™©ç­‰çº§æ ‡ç­¾æ ·å¼ */
    .risk-label {
        display: inline-block;
        padding: 4px 8px;
        border-radius: 4px;
        font-size: 12px;
        font-weight: bold;
        color: white;
    }
    
    .risk-high {
        background-color: #f44336;
    }
    
    .risk-medium {
        background-color: #ff9800;
    }
    
    .risk-low {
        background-color: #4caf50;
    }
    
    /* åˆåŒæ–‡æœ¬é«˜äº®æ ·å¼ */
    .contract-highlight {
        background-color: #fff3e0;
        border: 2px solid #ff9800;
        border-radius: 4px;
        padding: 4px 8px;
        margin: 2px;
        display: inline-block;
        position: relative;
    }
    
    .contract-highlight.high-risk {
        background-color: #ffebee;
        border-color: #f44336;
    }
    
    .contract-highlight.medium-risk {
        background-color: #fff3e0;
        border-color: #ff9800;
    }
    
    .contract-highlight.low-risk {
        background-color: #e8f5e8;
        border-color: #4caf50;
    }
    
    /* æŒ‰é’®æ ·å¼ */
    .stButton > button {
        border-radius: 6px;
        font-weight: 500;
    }
    
    /* åˆ†æ æ ·å¼ */
    .stColumn {
        padding: 0 10px;
    }
</style>
""", unsafe_allow_html=True)

# é¡¶éƒ¨æ ‡é¢˜
st.title("ğŸ“„ åˆåŒå®¡æŸ¥ç³»ç»Ÿ")

# æ–‡ä»¶é€‰æ‹©åŒºåŸŸ
st.subheader("ğŸ“ é€‰æ‹©åˆåŒæ–‡ä»¶")

# åˆ›å»ºé€‰é¡¹å¡
tab1, tab2 = st.tabs(["ğŸ“¤ ä¸Šä¼ æ–‡ä»¶", "ğŸ“‹ é€‰æ‹©æ ·ä¾‹"])

with tab1:
    uploaded = st.file_uploader("ä¸Šä¼ åˆåŒæ–‡ä»¶ (PDF/DOCX/TXT/DOC)", type=["pdf", "docx", "txt", "doc"])

with tab2:
    sample_files = get_sample_files()
    if sample_files:
        st.write("ä»ä»¥ä¸‹æ ·ä¾‹æ–‡ä»¶ä¸­é€‰æ‹©ä¸€ä¸ªè¿›è¡Œæµ‹è¯•ï¼š")
        
        # æ˜¾ç¤ºæ ·ä¾‹æ–‡ä»¶åˆ—è¡¨
        for i, sample_path in enumerate(sample_files):
            file_name = os.path.basename(sample_path)
            col1, col2, col3 = st.columns([3, 1, 1])
            
            with col1:
                st.write(f"ğŸ“„ {file_name}")
            
            with col2:
                if st.button(f"é¢„è§ˆ", key=f"preview_{i}"):
                    preview_content = preview_file_content(sample_path)
                    st.session_state.sample_preview = preview_content
                    st.session_state.sample_file_name = file_name
            
            with col3:
                if st.button(f"é€‰æ‹©", key=f"select_{i}", type="primary"):
                    # å¤åˆ¶æ ·ä¾‹æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
                    temp_path = copy_sample_file(sample_path)
                    if temp_path:
                        st.session_state.saved_file_path = temp_path
                        st.session_state.file_name = file_name
                        st.session_state.preview_content = preview_file_content(temp_path)
                        st.session_state.selected_sample = sample_path
                        st.success(f"å·²é€‰æ‹©æ ·ä¾‹æ–‡ä»¶: {file_name}")
                        st.rerun()
                    else:
                        st.error("é€‰æ‹©æ ·ä¾‹æ–‡ä»¶å¤±è´¥")
        
        # æ˜¾ç¤ºé¢„è§ˆå†…å®¹
        if hasattr(st.session_state, 'sample_preview'):
            st.divider()
            st.write(f"**{st.session_state.sample_file_name} é¢„è§ˆ:**")
            st.text_area("æ–‡ä»¶å†…å®¹", st.session_state.sample_preview, height=300, disabled=True)
    else:
        st.info("contracts ç›®å½•ä¸‹æ²¡æœ‰æ‰¾åˆ°æ ·ä¾‹æ–‡ä»¶")
        st.write("è¯·å°†æ ·ä¾‹æ–‡ä»¶æ”¾åœ¨ `contracts/` ç›®å½•ä¸‹ï¼Œæ”¯æŒæ ¼å¼ï¼šPDF, DOCX, TXT, DOC")

# åˆå§‹åŒ–session state
if 'analysis_result' not in st.session_state:
    st.session_state.analysis_result = None
if 'selected_risk_level' not in st.session_state:
    st.session_state.selected_risk_level = "å…¨éƒ¨"

# æ–‡ä»¶é¢„è§ˆå’Œä¿å­˜
if uploaded:
    saved_path = save_uploaded_file(uploaded)
    if saved_path:
        st.session_state.saved_file_path = saved_path
        st.session_state.file_name = uploaded.name
        st.session_state.preview_content = preview_file_content(saved_path)
        # æ¸…é™¤æ ·ä¾‹é€‰æ‹©çŠ¶æ€
        if hasattr(st.session_state, 'selected_sample'):
            del st.session_state.selected_sample
    else:
        st.error("ä¿å­˜æ–‡ä»¶å¤±è´¥")

# è¿è¡Œåˆ†ææŒ‰é’®
has_file = uploaded or hasattr(st.session_state, 'saved_file_path')
if has_file and st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary", use_container_width=True):
    saved_path = st.session_state.get('saved_file_path')
    if not saved_path:
        st.error("æ–‡ä»¶è·¯å¾„ä¸¢å¤±ï¼Œè¯·é‡æ–°é€‰æ‹©æ–‡ä»¶")
        st.stop()

    with st.spinner("æ­£åœ¨åˆ†æï¼Œè¯·ç¨å€™..."):
        result = call_processor_pipeline(saved_path)
    
    if "error" in result:
        st.error(result["error"])
    else:
        st.session_state.analysis_result = result
        st.success("åˆ†æå®Œæˆï¼")

# ä¸»ç•Œé¢å¸ƒå±€
if st.session_state.analysis_result:
    result = st.session_state.analysis_result
    issues = result.get("issues", [])
    
    # åˆ›å»ºå·¦å³åˆ†æ å¸ƒå±€
    col1, col2 = st.columns([1, 1], gap="large")
    
    with col1:
        # å·¦ä¾§ï¼šåˆåŒå†…å®¹åŒºåŸŸ
        st.markdown("### ğŸ“„ åˆåŒæ–‡æ¡£")
        
        # åˆåŒæ ‡é¢˜å’Œä¸Šä¼ æŒ‰é’®
        header_col1, header_col2 = st.columns([3, 1])
        with header_col1:
            st.markdown(f"**{st.session_state.file_name}**")
        with header_col2:
            if st.button("ğŸ“¤ ä¸Šä¼ åˆåŒ", key="upload_contract"):
                st.rerun()
        
        # æ˜¾ç¤ºåˆåŒå†…å®¹ï¼ˆå¸¦é«˜äº®ï¼‰
        contract_text = st.session_state.preview_content
        
        # ä¸ºé—®é¢˜æ·»åŠ é«˜äº®æ ‡è®°
        highlighted_text = add_highlights_to_text(contract_text, issues)
        
        # æ˜¾ç¤ºæ ‡è®°åçš„æ–‡æœ¬
        st.markdown("### ğŸ“„ åˆåŒå†…å®¹ï¼ˆå·²æ ‡è®°é—®é¢˜ï¼‰")
        st.text_area("", value=highlighted_text, height=400, disabled=True)
    
    with col2:
        # å³ä¾§ï¼šé£é™©åˆ†æåŒºåŸŸ
        st.markdown("### ğŸ” å®¡æŸ¥ç»“æœ")
        
        # è°ƒè¯•ä¿¡æ¯
        st.write(f"æ€»é—®é¢˜æ•°: {len(issues)}")
        if issues:
            st.write(f"ç¬¬ä¸€ä¸ªé—®é¢˜: {issues[0]}")
        
        # é£é™©ç­‰çº§ç­›é€‰æŒ‰é’®
        st.markdown("**é£é™©ç­‰çº§**")
        risk_levels = ["å…¨éƒ¨", "ä¸€èˆ¬é£é™©", "é‡å¤§é£é™©"]
        selected_level = st.radio("é€‰æ‹©é£é™©ç­‰çº§", risk_levels, horizontal=True, 
                                index=risk_levels.index(st.session_state.selected_risk_level),
                                key="risk_filter")
        st.session_state.selected_risk_level = selected_level
        
        # ç­›é€‰é—®é¢˜
        filtered_issues = filter_issues_by_risk(issues, selected_level)
        st.write(f"ç­›é€‰åé—®é¢˜æ•°: {len(filtered_issues)}")
        
        # æ˜¾ç¤ºé£é™©é¡¹ç›®
        if filtered_issues:
            st.markdown("---")
            
            # æ˜¾ç¤ºé£é™©å¡ç‰‡
            for i, issue in enumerate(filtered_issues, 1):
                risk_level = issue.get("é£é™©ç­‰çº§", "ä½")
                issue_type = issue.get("ç±»å‹", "æœªçŸ¥ç±»å‹")
                
                # æ ¹æ®é£é™©ç­‰çº§è®¾ç½®é¢œè‰²å’Œå›¾æ ‡
                if risk_level == "é«˜":
                    risk_color = "ğŸ”´"
                    risk_label = "é‡å¤§é£é™©"
                elif risk_level == "ä¸­":
                    risk_color = "ğŸŸ¡"
                    risk_label = "ä¸€èˆ¬é£é™©"
                else:
                    risk_color = "ğŸŸ¢"
                    risk_label = "ä½é£é™©"
                
                # ä½¿ç”¨ Streamlit å®¹å™¨å’Œåˆ—æ¥åˆ›å»ºç®€æ´çš„å¡ç‰‡
                with st.container():
                    col1, col2 = st.columns([3, 1])
                    
                    with col1:
                        st.markdown(f"**{risk_color} {issue_type}**")
                    with col2:
                        st.markdown(f"**{risk_label}**")
                    
                    # ä½¿ç”¨ expander æ¥ç»„ç»‡ä¿¡æ¯
                    with st.expander("è¯¦ç»†ä¿¡æ¯", expanded=True):
                        st.write(f"**æ¡æ¬¾ä½ç½®ï¼š** {issue.get('æ¡æ¬¾', 'N/A')}")
                        st.write(f"**é—®é¢˜æè¿°ï¼š** {issue.get('é—®é¢˜æè¿°', 'N/A')}")
                        st.write(f"**ä¿®æ”¹å»ºè®®ï¼š** {issue.get('ä¿®æ”¹å»ºè®®', 'N/A')}")
                        
                        # æ·»åŠ å¯é€‰å­—æ®µ
                        if issue.get("æ³•å¾‹ä¾æ®"):
                            st.write(f"**æ³•å¾‹ä¾æ®ï¼š** {issue.get('æ³•å¾‹ä¾æ®', 'N/A')}")
                        if issue.get("å½±å“åˆ†æ"):
                            st.write(f"**å½±å“åˆ†æï¼š** {issue.get('å½±å“åˆ†æ', 'N/A')}")
                        if issue.get("å•†ä¸šä¼˜åŒ–"):
                            st.write(f"**å•†ä¸šä¼˜åŒ–ï¼š** {issue.get('å•†ä¸šä¼˜åŒ–', 'N/A')}")
                    
                    st.markdown("---")
        else:
            st.info("æœªå‘ç°é—®é¢˜")
        
        # ä¸‹è½½ç»“æœæŒ‰é’®
        st.markdown("---")
        if st.button("ğŸ“¥ ä¸‹è½½ç»“æœ", use_container_width=True, type="primary"):
            json_bytes = json.dumps(result, ensure_ascii=False, indent=2).encode("utf-8")
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½å®Œæ•´ç»“æœ",
                data=json_bytes,
                file_name=f"contract_analysis_{int(time.time())}.json",
                mime="application/json",
                use_container_width=True,
            )

else:
    # æœªåˆ†ææ—¶çš„ç•Œé¢
    if has_file:
        st.info("è¯·ç‚¹å‡»'å¼€å§‹åˆ†æ'æŒ‰é’®è¿›è¡ŒåˆåŒå®¡æŸ¥")
        
        # æ˜¾ç¤ºæ–‡ä»¶é¢„è§ˆ
        with st.expander("ğŸ“„ æ–‡ä»¶é¢„è§ˆ", expanded=True):
            st.text_area("æ–‡ä»¶å†…å®¹", st.session_state.get('preview_content', ''), height=400, disabled=True)
    else:
        st.info("è¯·ä¸Šä¼ åˆåŒæ–‡ä»¶æˆ–é€‰æ‹©æ ·ä¾‹æ–‡ä»¶å¼€å§‹åˆ†æ")


